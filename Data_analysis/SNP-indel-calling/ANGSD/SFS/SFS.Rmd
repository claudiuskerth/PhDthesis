---
title: "SFS"
author: "Claudius"
date: "21/12/2016"
output: 
  html_document:
    self_contained: yes
    theme: cosmo
    toc: yes
bibliography: Literature.bib
---

```{r setup options, cache=FALSE, include=TRUE}
library(knitr)
opts_chunk$set(dev=c("png", "pdf"), eval=TRUE, fig.width=12, fig.height=12)
options(digits=10)
setwd("/data3/claudius/Big_Data/ANGSD/SFS")
```

----------

```{r, eval=FALSE, echo=FALSE}
N=1000
m = seq(0, 1/N, len=10000)
G = 1/(1+4*N*m)
plot(4*N*m, G, ylim=c(0,1), type="l")
```

```{r, eval=FALSE, echo=FALSE}
p = c(.637, .661, .701, .746, .724, .942, .556, .880)
q = 1 - p
# equal population sizes:
ci = 1/8
p_mean = sum(ci*p)
q_mean = 1 - p_mean
var_p = sum(ci*p^2) - p_mean^2
Gt = p_mean^2 + q_mean^2
Fst = 2*var_p/(1-Gt)
Fst
# very unequal population sizes:
ci = c(rep(.2, 4), rep(.05, 4))
p_mean = sum(ci*p)
q_mean = 1 - p_mean
var_p = sum(ci*p^2) - p_mean^2
Gt = p_mean^2 + q_mean^2
Fst = 2*var_p/(1-Gt)
Fst
```

-----------

I have run `realSFS` with a _tolerance_ (`-tole`) of 1e-6, which means that the EM iteration is stopped if the likelihoods of the last two iterations differed by less than 1e-6.
I specified a maximum number of EM iterations of 50000 (`-maxIter`) after examining the speed at which both ERY and PAR reach the *tolerance* stopping criterium. I have also turned off the accelerated EM algorithm with `-m 0`. This guarantees that a good ML estimate of the SFS is found, but much more slowly. The ML estimate of the folded SFS in ERY is found within 8 minutes, the one of PAR within 26 minutes.


```{r, eval=TRUE}
ery.sfs = scan("ERY/ERY.FOLDED.sfs")
par.sfs = scan("PAR/PAR.FOLDED.sfs")
ery.sfs = ery.sfs[-1]
par.sfs = par.sfs[-1]
```

---- 

I am trying to fit eq. 4.21 of @Wakeley2009 to the oberseved 1D folded spectra:

$$
E[\eta_i] = \theta \frac{\frac{1}{i} + \frac{1}{n-i}}{1+\delta_{i,n-i}} \qquad 1 \le i \le \big[n/2\big]
$$

This formula gives the neutral expectation of counts in each frequency class ($i$) in a folded spectrum. The count in each frequency class, $\eta_i$, provides an estimate of $\theta$. However, I would like to find the value of $\theta$ that minimizes the deviation of the above equation from all observed counts $\eta_i$.

```{r, eval=TRUE}
# define function to optimise

f = function (theta, eta, n){ 
  #
  # theta: parameter to optimize
  # eta: will get the observed SFS
  # n: number of gene copies sampled per diploid locus
  #
  # returns sum of squared deviations (residuals) between observed counts
  # and a candidate model
  #
  sumofsq = numeric(length(ery.sfs))
  i = seq(1, length(eta))
  delta = ifelse(i == n-i, 1, 0)
  expected = theta * 1/i + 1/(n-i) / (1 + delta)
  sumofsq = sum( (expected - eta)^2 )
  return(sumofsq)
}
```

```{r, eval=TRUE}
# fit optimizal theta to ery and par SFS

ery_thetaOpt = optimize(f, interval=c(0, sum(ery.sfs)),  eta=ery.sfs, n=36, maximum=FALSE, tol=0.001)
par_thetaOpt = optimize(f, interval=c(0, sum(par.sfs)),  eta=par.sfs, n=36, maximum=FALSE, tol=0.001)
```

The optimal $\theta$ for the spectrum of _ery_ is `r format(ery_thetaOpt$min, scientific=F, digits=6)`. The optimal $\theta$ for the spectrum of _par_ is `r format(par_thetaOpt$min, scient=F, digits=6)`. These are almost exactly the same values I estimated with the `scipy.optimize` functions `curve_fit` and `minimize_scalar` in `First_Steps_with_dadi.ipynb`.

```{r, eval=TRUE}
# define a function that returns expected counts given a theta under the assumption of
# the standard neutral model

snm = function(theta, len=0, n=36){
  #
  # theta: should be optimized theta
  # len: should be the length of the folded SFS, i. e. highest freq. class
  # n: should be number of gene copies sampled per locus, i. e. 2*N for diploid loci
  #
  # returns expected SFS
  #
  i = seq(1, len)
  delta = ifelse(i == n-i, 1, 0)
  expected = theta * 1/i + 1/(n-i) / (1 + delta)
  return(expected)
}
```


```{r, eval=TRUE, fig.height=16}
# plot observed spectra and expected neutral fit for ery and par

par(mfrow=c(2,1))
# standard neutral model expectation:
plot(snm(ery_thetaOpt$min, len=length(ery.sfs), n=36), 
     xlab="minor allele count", 
     ylab="number of sites",
     pch=18, col="black", type="b",
     main="folded SFS of ery")
# observed:
lines(ery.sfs, pch=20, col="red", type="b")
legend("topright", legend=c("ery", "neutral fit"), pch=c(20, 18), col=c("red", "black"), bty="n")
#
# standard neutral model expectation:
plot(snm(par_thetaOpt$min, len=length(par.sfs), n=36), 
     xlab="minor allele count", 
     ylab="number of sites",
     pch=18, col="black", type="b",
     main="folded SFS of par")
# observed:
lines(par.sfs, pch=20, col="green", type="b")
legend("topright", legend=c("par", "neutral fit"), pch=c(20, 18), col=c("green", "black"), bty="n")
```

The deviation, especially in the first two count classes, is astonishing and certainly cannot be explained just by violations of assumptions of standard neutral model.

Let's get confidence intervals for SNM expected counts. According to @Fu1995, p. 192, the counts in neutral spectra can be approximated by a Poisson distribution for large sample sizes (i. e. large $n$).

```{r, eval=TRUE, fig.height=7, fig.width=7}
par(mfrow=c(1,1))
# get neutral model expectation
snm.expect = snm(ery_thetaOpt$min, len=length(ery.sfs), n=36)
# expected:
plot(snm.expect, 
     xlab="minor allele count", 
     ylab="number of sites",
     pch=18, col="black", type="b",
     main="folded SFS of ery")
# observed:
lines(ery.sfs, pch=20, col="red", type="b")
legend("topright", legend=c("ery", "neutral fit"), pch=c(20, 18), col=c("red", "black"), bty="n")
# get lower and upper 95% quantiles:
low = qpois(p=0.025, lambda=snm.expect)
high = qpois(p=0.975, lambda=snm.expect)
# add 95% CI bars:
arrows(1:length(snm.expect), snm.expect, 
       1:length(snm.expect), high,
       angle=90,
       length=.05
       )
arrows(1:length(snm.expect), snm.expect, 
       1:length(snm.expect), low,
       angle=90,
       length=.05
       )
```





----


```{r ML}
barplot(rbind(ery.sfs, par.sfs), 
        names.arg=1:length(ery.sfs),
        beside=TRUE,
        xlab="minor allele count",
        ylab="number of sites",
        main="ML folded site frequency spectrum"
        )
legend("topright",
        legend=c("erythropus", "parallelus"),
        fill=c(gray(.3), gray(.7))
        )
```


I have rerun the exhaustive ML search from above:

```{r}
ery.sfs1 = scan("ERY/ERY.FOLDED.sfs1")
par.sfs1 = scan("PAR/PAR.FOLDED.sfs1")
ery.sfs1 = ery.sfs1[-1]
par.sfs1 = par.sfs1[-1]
```


## Variability in the ML estimate of folded SFS

I have repeated the ML estimation of per-population folded SFS with `realSFS` 100 times.
Other than specifying the number of threads, I left all other parameters for `realSFS` at the default. These default values are not documented. With the accelerated EM algorithm (turned on by default), `realSFS` reaches a ML estimate very fast (<1min).

```{r}
ery.SFS.repeated = read.table("ERY/ERY.FOLDED.sfs.ml", header=F)
par.SFS.repeated = read.table("PAR/PAR.FOLDED.sfs.ml", header=F)
```

```{r var-ML-SFS-ery}
matplot(1:18, 
        t(ery.SFS.repeated[,2:length(ery.SFS.repeated)]), 
        #type="l",
        #lty=1,
        pch=16,
        col=gray(.1, alpha=.1),
        ylab="number of sites",
        xlab="minor allele count",
        main="variability in the ML estimate of the global folded SFS"
        )
# add the first exhaustive ML SFS:
points(1:18, ery.sfs, pch=4, cex=2, col="red", type="b")
# add the second exhaustive ML SFS:
points(1:18, ery.sfs1, pch=3, cex=2, col="blue", type="b")
#text(15, 6000, labels=paste(nrow(ery.SFS.repeated), " repetitions"))
text(9, max(ery.sfs), labels="ERY")
legend("right", legend=c("ERY.FOLDED.sfs", "ERY.FOLDED.sfs1"), title="exhaustive ML searches", pch=c(4,3), pt.cex=2, col=c("red", "blue"))
legend("topright", legend=paste(nrow(ery.SFS.repeated), " repetitions"), title="accelerated EM", pch=16, pt.cex=1.5, col=gray(.5))
```

The EM algorithm doesn't seem to be converging well for the minor allele count categories 10 onwards. However, the two exhaustive EM searches are matching perfectly. So, I assume they have converged.


```{r var-ML-SFS-par}
matplot(1:18, 
        t(par.SFS.repeated[,2:length(par.SFS.repeated)]), 
        #type="l",
        #lty=1,
        pch=16,
        col=gray(.1, alpha=.1),
        ylab="number of sites",
        xlab="minor allele count",
        main="variability in the ML estimate of the global folded SFS"
        )
points(1:18, par.sfs, pch=4, cex=2, col="green", type="b")
points(1:18, par.sfs1, pch=3, cex=2, col="orange", type="b")
#text(15, 10000, labels=paste(nrow(par.SFS.repeated), " repetitions"))
text(9, max(par.sfs), labels="PAR")
legend("topright", legend=paste(nrow(par.SFS.repeated), " repetitions"), pch=16, pt.cex=1.5, col=gray(.5), title="accelerated EM")
legend("right", legend=c("PAR.FOLDED.sfs", "PAR.FOLDED.sfs1"), pch=c(4, 3), pt.cex=2, col=c("green", "orange"), title="exhaustive ML searches")
```

The EM algorithm doesn't seem to be able to resolve the _parallelus_ SFS very well. There is a clear lack of convergence. However, the two exhaustive searches are matching perfectly. So I assume that they have converged.




## Bootstrapping the ML estimate of SFS

I have run 1000 bootstrap resamples of the ML SFS with `realSFS`. That should mean that sites are resampled with replacement. I have run `realSFS` with default parameters, i. e. accelerated EM algorithm and no specification of _tolerance_. That means that the bootstrap resampled SFS's also comprise the variability from the non-convergent EM algorithm.

```{r}
ery.sfs.boot = read.table("ERY/ERY.FOLDED.sfs.boot", header=F)
dim(ery.sfs.boot)
head(ery.sfs.boot)
ery.sfs.boot = ery.sfs.boot[,2:ncol(ery.sfs.boot)]
#
par.sfs.boot = read.table("PAR/PAR.FOLDED.sfs.boot", header=F)
dim(par.sfs.boot)
head(par.sfs.boot)
par.sfs.boot = par.sfs.boot[,2:ncol(par.sfs.boot)]
```


```{r}
matplot(1:18, 
        t(ery.sfs.boot), 
        #type="l",
        #lty=1,
        pch=16,
        col=gray(0, alpha=.1),
        ylab="number of sites",
        xlab="minor allele count",
        main="global folded SFS of ERY"
        )
# adding the real sample ML estimate to the plot:
points(1:18, ery.sfs, pch=4, cex=2, col="red", type="b", lwd=2)
#text(15, 6000, labels=paste(nrow(ery.SFS.repeated), " repetitions"))
legend("topright", 
       legend=c("ERY.FOLDED.sfs", "1,000 bootstrap resamples"), 
       pch=c(4,16), 
       pt.cex=1, 
       col=c("red", gray(.2, alpha=1)),
       bty="n"
       )
```

```{r}
matplot(1:18, 
        t(par.sfs.boot), 
        #type="l",
        #lty=1,
        pch=16,
        col=gray(0, alpha=.05),
        ylab="number of sites",
        xlab="minor allele count",
        main="global folded SFS of PAR"
        )
# adding the real sample ML estimate to the plot:
points(1:18, par.sfs, pch=4, cex=2, col="green", type="b", lwd=2)
#text(15, 6000, labels=paste(nrow(ery.SFS.repeated), " repetitions"))
legend("topright", 
       legend=c("PAR.FOLDED.sfs", "1,000 bootstrap resamples"), 
       pch=c(4,16),
       pt.cex=1, 
       col=c("green", gray(.2, alpha=1)),
       bty="n"
       )
```



```{r}
ery.sfs.CI95 = data.frame(
  low=vector("double", ncol(ery.sfs.boot)), 
  med=vector("double", ncol(ery.sfs.boot)), 
  high=vector("double", ncol(ery.sfs.boot))
  )
#
for(i in 1:ncol(ery.sfs.boot)){
  ery.sfs.CI95[i,] = quantile(ery.sfs.boot[,i], probs=c(0.25, 0.5, 0.975))
}
#
par.sfs.CI95 = data.frame(
  low=vector("double", ncol(par.sfs.boot)), 
  med=vector("double", ncol(par.sfs.boot)), 
  high=vector("double", ncol(par.sfs.boot))
  )
#
for(i in 1:ncol(par.sfs.boot)){
  par.sfs.CI95[i,] = quantile(par.sfs.boot[,i], probs=c(0.25, 0.5, 0.975))
}
```

```{r}
plot(1:nrow(ery.sfs.CI95), ery.sfs.CI95$med, 
     ylim=c(0, max(ery.sfs.CI95)),
     pch=20,
     xlab="minor allele count",
     ylab="number of sites",
     main="global folded SFS of ERY"
     )
arrows(1:nrow(ery.sfs.CI95), ery.sfs.CI95$med, 
       1:nrow(ery.sfs.CI95), ery.sfs.CI95$high,
       angle=90,
       length=.05
       )
arrows(1:nrow(ery.sfs.CI95), ery.sfs.CI95$med, 
       1:nrow(ery.sfs.CI95), ery.sfs.CI95$low,
       angle=90,
       length=.05
       )
points(1:18, ery.sfs, pch=4, cex=1, col="red", type="b", lwd=2)
legend("topright", legend="exhaustive search ML SFS", bty="n", col="red", pch=4, lwd=2, cex=.9)
#
points(10.5, 7100, pch=20)
arrows(10.5, 7100, 
       10.5, 7400,
       angle=90,
       length=.05
       )
arrows(10.5, 7100, 
       10.5, 6800,
       angle=90,
       length=.05
       )
#
text(11, 7000, 
     labels="median and 95% CI limits\nof 1,000 bootstrap resamples", 
     cex=.9, pos=4)
```

```{r}
plot(1:nrow(par.sfs.CI95), par.sfs.CI95$med, 
     ylim=c(0, max(par.sfs.CI95)),
     pch=20,
     xlab="minor allele count",
     ylab="number of sites",
     main="global folded SFS of PAR"
     )
arrows(1:nrow(par.sfs.CI95), par.sfs.CI95$med, 
       1:nrow(par.sfs.CI95), par.sfs.CI95$high,
       angle=90,
       length=.05
       )
arrows(1:nrow(par.sfs.CI95), par.sfs.CI95$med, 
       1:nrow(par.sfs.CI95), par.sfs.CI95$low,
       angle=90,
       length=.05
       )
points(1:18, par.sfs, pch=4, cex=1, col="green", type="b", lwd=2)
legend("topright", legend="exhaustive search ML SFS", bty="n", col="green", pch=4, lwd=2, cex=.9)
#
points(10.5, 11100, pch=20)
arrows(10.5, 11100, 
       10.5, 11500,
       angle=90,
       length=.05
       )
arrows(10.5, 11100, 
       10.5, 10700,
       angle=90,
       length=.05
       )
#
text(11, 11000, 
     labels="median and 95% CI limits\nof 1,000 bootstrap resamples", 
     cex=.9, pos=4)
```

Several frequency classes (11, 13, 15) have exhaustive search ML estimates outside the 95% CI from the 1000 bootstrap resamples that were run with accelerated EM. I wonder whether the exhaustive search ML SFS is significant or whether it is maximising the likelihood of insignificant noise in the data due to a lack of information in the higher count classes.


## Bootstraps with exhaustive ML search

```{r}
ery.sfs.boot.exh = read.table("ERY/ERY.FOLDED.sfs.boot.exh", header=F)
dim(ery.sfs.boot.exh)
matplot(1:18, 
        t(ery.sfs.boot.exh[2:ncol(ery.sfs.boot.exh)]), 
        #type="l",
        #lty=1,
        pch=16,
        col=gray(0, alpha=.1),
        ylab="number of sites",
        xlab="minor allele count",
        main="global folded SFS of ERY\nexhaustive EM search"
        )
# adding the real sample ML estimate to the plot:
points(1:18, ery.sfs, pch=4, cex=2, col="red", type="b", lwd=2)
#text(15, 6000, labels=paste(nrow(ery.SFS.repeated), " repetitions"))
legend("topright", 
       legend=c("ERY.FOLDED.sfs", "200 bootstrap resamples"), 
       pch=c(4,16), 
       pt.cex=1, 
       col=c("red", gray(.2, alpha=1)),
       bty="n"
       )
```

```{r}
par.sfs.boot.exh = read.table("PAR/PAR.FOLDED.sfs.boot.exh", header=F)
dim(par.sfs.boot.exh)
matplot(1:18, 
        t(par.sfs.boot.exh[2:ncol(par.sfs.boot.exh)]), 
        #type="l",
        #lty=1,
        pch=16,
        col=gray(0, alpha=.1),
        ylab="number of sites",
        xlab="minor allele count",
        main="global folded SFS of PAR\nexhaustive EM search"
        )
# adding the real sample ML estimate to the plot:
points(1:18, par.sfs, pch=4, cex=2, col="green", type="b", lwd=2)
#text(15, 6000, labels=paste(nrow(ery.SFS.repeated), " repetitions"))
legend("topright", 
       legend=c("PAR.FOLDED.sfs", "200 bootstrap resamples"), 
       pch=c(4,16), 
       pt.cex=1, 
       col=c("green", gray(.2, alpha=1)),
       bty="n"
       )
```


```{r}
names(ery.sfs.boot.exh) = as.character(0:18)
ery.sfs.boot.exh.CI95 = as.data.frame(t( apply(ery.sfs.boot.exh, 2, quantile, probs=c(0.25, 0.5, 0.975)) ))
#
names(par.sfs.boot.exh) = as.character(0:18)
par.sfs.boot.exh.CI95 = as.data.frame(t( apply(par.sfs.boot.exh, 2, quantile, probs=c(0.25, 0.5, 0.975)) ))
```

```{r}
plot_ery_boot = function(...){
  points(1:18, 
       ery.sfs.boot.exh.CI95[2:19,2], 
       ylim=c(0, max(ery.sfs.boot.exh.CI95[2:19,])),
       pch=20,
       xlab="minor allele count",
       ylab="number of sites",
       main="global folded SFS of ERY",
       ...
       )
  arrows(1:18, ery.sfs.boot.exh.CI95[2:19,2], 
         1:18, ery.sfs.boot.exh.CI95[2:19,3],
         angle=90,
         length=.05,
         ...
         )
  arrows(1:18, ery.sfs.boot.exh.CI95[2:19,2], 
         1:18, ery.sfs.boot.exh.CI95[2:19,1],
         angle=90,
         length=.05,
         ...
         )
  }
# set up plot device:
plot(1:18, 
     ery.sfs.boot.exh.CI95[2:19,2], 
     ylim=c(0, max(ery.sfs.boot.exh.CI95[2:19,])),
     pch=20,
     xlab="minor allele count",
     ylab="number of sites",
     main="global folded SFS of ERY",
     type="n"
     )
plot_ery_boot()
points(1:18, ery.sfs, pch=4, cex=1, col="red", type="b", lwd=2)
legend("topright", legend="real sample SFS from exhaustive EM search", bty="n", col="red", pch=4, lwd=2, cex=.9)
#
points(10.5, 7100, pch=20)
arrows(10.5, 7100, 
       10.5, 7400,
       angle=90,
       length=.05
       )
arrows(10.5, 7100, 
       10.5, 6800,
       angle=90,
       length=.05
       )
#
text(11, 7000, 
     labels="median and 95% CI limits\nof 200 bootstrap resamples", 
     cex=.9, pos=4)
```

```{r, warning=FALSE}
plot_par_boot = function(...){
  # plot medians of bootstrap samples:
  points(1:18, 
       par.sfs.boot.exh.CI95[2:19,2], 
       ylim=c(0, max(par.sfs.boot.exh.CI95[2:19,])),
       pch=20,
       xlab="minor allele count",
       ylab="number of sites",
       main="global folded SFS of PAR",
       ...
       )
  # plot CI bars:
  arrows(1:18, par.sfs.boot.exh.CI95[2:19,2], 
         1:18, par.sfs.boot.exh.CI95[2:19,3],
         angle=90,
         length=.05,
         ...
         )
  arrows(1:18, par.sfs.boot.exh.CI95[2:19,2], 
         1:18, par.sfs.boot.exh.CI95[2:19,1],
         angle=90,
         length=.05,
         ...
         )
  }
# set up plot device:
plot(1:18, 
     par.sfs.boot.exh.CI95[2:19,2], 
     ylim=c(0, max(par.sfs.boot.exh.CI95[2:19,])),
     pch=20,
     xlab="minor allele count",
     ylab="number of sites",
     main="global folded SFS of PAR",
     type="n"
     )
plot_par_boot()
points(1:18, par.sfs, pch=4, cex=1, col="green", type="b", lwd=2)
legend("topright", legend="real sample SFS from exhaustive EM search", bty="n", col="green", pch=4, lwd=2, cex=.9)
#
points(10.5, 11100, pch=20)
arrows(10.5, 11100, 
       10.5, 11500,
       angle=90,
       length=.05
       )
arrows(10.5, 11100, 
       10.5, 10700,
       angle=90,
       length=.05
       )
#
text(11, 11000, 
     labels="median and 95% CI limits\nof 200 bootstrap resamples", 
     cex=.9, pos=4)
```

The SFS's estimated from the real samples (also with exhaustive EM search) match the medians of the frequency classes from bootstrap resampled sites very well for each population.



-----------

## Fitting an expected neutral SFS

I have run `realSFS` with a _tolerance_ (`-tole`) of 1e-6, which means that the EM iteration is stopped if the likelihoods of the last two iterations differed by less than 1e-6.
I specified a maximum number of EM iterations of 50000 (`-maxIter`) after examining the speed at which both ERY and PAR reach the *tolerance* stopping criterium. I have also turned off the accelerated EM algorithm with `-m 0`. This guarantees that a good ML estimate of the SFS is found, but much more slowly. The ML estimate of the folded SFS in ERY is found within 8 minutes, the one of PAR within 26 minutes.


```{r, eval=TRUE}
# read in the spectra again

ery.sfs = scan("ERY/ERY.FOLDED.sfs")
par.sfs = scan("PAR/PAR.FOLDED.sfs")
ery.sfs = ery.sfs[-1]
par.sfs = par.sfs[-1]
```

I am trying to fit eq. 4.21 of @Wakeley2009 to the oberseved 1D folded spectra:

$$
E[\eta_i] = \theta \frac{\frac{1}{i} + \frac{1}{n-i}}{1+\delta_{i,n-i}} \qquad 1 \le i \le \big[n/2\big]
$$

This formula gives the neutral expectation of counts in each frequency class ($i$) in a folded spectrum. The count in each frequency class, $\eta_i$, provides an estimate of $\theta$. However, I would like to find the value of $\theta$ that minimizes the deviation of the above equation from all observed counts $\eta_i$.

```{r, eval=TRUE}
# define function to optimise

f = function (theta, eta, n){ 
  #
  # theta: parameter to optimize
  # eta: will get the observed SFS
  # n: number of gene copies sampled per diploid locus
  #
  # returns sum of squared deviations (residuals) between observed counts
  # and a candidate model
  #
  sumofsq = numeric(length(ery.sfs))
  i = seq(1, length(eta))
  delta = ifelse(i == n-i, 1, 0)
  expected = theta * 1/i + 1/(n-i) / (1 + delta)
  sumofsq = sum( (expected - eta)^2 )
  return(sumofsq)
}
```

```{r, eval=TRUE}
# fit optimizal theta to ery and par SFS

ery_thetaOpt = optimize(f, interval=c(0, sum(ery.sfs)),  eta=ery.sfs, n=36, maximum=FALSE, tol=0.001)
par_thetaOpt = optimize(f, interval=c(0, sum(par.sfs)),  eta=par.sfs, n=36, maximum=FALSE, tol=0.001)
```

The optimal $\theta$ for the spectrum of _ery_ is `r format(ery_thetaOpt$min, scientific=F, digits=6)`. The optimal $\theta$ for the spectrum of _par_ is `r format(par_thetaOpt$min, scient=F, digits=6)`. These are almost exactly the same values I estimated with the `scipy.optimize` functions `curve_fit` and `minimize_scalar` in `First_Steps_with_dadi.ipynb`.

```{r, eval=TRUE}
# define a function that returns expected counts given a theta under the assumption of
# the standard neutral model

snm = function(theta, len=0, n=36){
  #
  # theta: should be optimized theta
  # len: should be the length of the folded SFS, i. e. highest freq. class
  # n: should be number of gene copies sampled per locus, i. e. 2*N for diploid loci
  #
  # returns expected SFS
  #
  i = seq(1, len)
  delta = ifelse(i == n-i, 1, 0)
  expected = theta * 1/i + 1/(n-i) / (1 + delta)
  return(expected)
}
```


```{r, eval=TRUE, fig.height=16}
# plot observed spectra and expected neutral fit for ery and par

par(mfrow=c(2,1))
# standard neutral model expectation:
ery_expected = snm(ery_thetaOpt$min, len=length(ery.sfs), n=36)
plot(ery_expected, 
     xlab="minor allele count", 
     ylab="number of sites",
     pch=18, col="black", type="b",
     main="folded SFS of ery")
# observed:
lines(ery.sfs, pch=20, col="red", type="b")
legend("topright", legend=c("ery", "neutral fit"), pch=c(20, 18), col=c("red", "black"), bty="n")
#
# standard neutral model expectation:
par_expected = snm(par_thetaOpt$min, len=length(par.sfs), n=36)
plot(par_expected, 
     xlab="minor allele count", 
     ylab="number of sites",
     ylim=c(0, max(par_expected)*1.1),
     pch=18, col="black", type="b",
     main="folded SFS of par")
# observed:
lines(par.sfs, pch=20, col="green", type="b")
legend("topright", legend=c("par", "neutral fit"), pch=c(20, 18), col=c("green", "black"), bty="n")
```

The deviation, especially in the first two count classes, is astonishing and certainly cannot be explained just by violations of assumptions of standard neutral model.

Let's get confidence intervals for SNM expected counts. According to @Fu1995, p. 192, the counts in neutral spectra can be approximated by a Poisson distribution for large sample sizes (i. e. large $n$).

```{r, eval=TRUE, fig.height=7, fig.width=7}
par(mfrow=c(1,1))

plot_ery_snm = function(...){
  # get neutral model expectation
  snm.expect = snm(ery_thetaOpt$min, len=length(ery.sfs), n=36)
  # expected:
  points(snm.expect, 
       xlab="minor allele count", 
       ylab="number of sites",
       ylim=c(0, max(snm.expect)*1.1),
       pch=18, col="black", type="b",
       main="folded SFS of ery",
       ...
       )
  legend("topright", legend=c("ery", "neutral fit"), 
         pch=c(20, 18), col=c("red", "black"), bty="n")
  # get lower and upper 95% quantiles:
  low = qpois(p=0.025, lambda=snm.expect)
  high = qpois(p=0.975, lambda=snm.expect)
  # add 95% CI bars:
  arrows(1:length(snm.expect), snm.expect, 
         1:length(snm.expect), high,
         angle=90,
         length=.05,
         ...
         )
  arrows(1:length(snm.expect), snm.expect, 
         1:length(snm.expect), low,
         angle=90,
         length=.05,
         ...
         )
  }
# set up plot device (false design of R!):
plot(snm.expect, 
       xlab="minor allele count", 
       ylab="number of sites",
       ylim=c(0, max(snm.expect)*1.1),
       main="folded SFS of ery",
       type="n",
       )
plot_ery_snm()
# observed:
lines(ery.sfs, pch=20, col="red", type="b")
```


Now, let's combine the 95% CI from bootstraps over nucleotide sites with the 95% CI of the fitted neutral spectrum.


```{r, warning=FALSE, fig.width=7, fig.height=7}
# set up plot device (false design of R!):
plot(snm.expect, 
       xlab="minor allele count", 
       ylab="number of sites",
       ylim=c(0, max(snm.expect)*1.1),
       main="folded SFS of ery",
       type="n",
       )
plot_ery_boot(col="red", type="b")
plot_ery_snm(new=FALSE)
```

```{r, warning=FALSE, fig.width=7, fig.height=7}
# set up plot device (false design of R!):
# set up plot device:
plot(1:18, 
     par.sfs.boot.exh.CI95[2:19,2], 
     ylim=c(0, max(par.sfs.boot.exh.CI95[2:19,])),
     pch=20,
     xlab="minor allele count",
     ylab="number of sites",
     main="global folded SFS of PAR",
     type="n"
     )
plot_par_boot(col="green", type="b")
plot_ery_snm(new=FALSE)
```



----

## Diversity Estimates

### S and $\pi$

```{r}
ery.sfs.boot = read.table("ERY/ERY.FOLDED.sfs.boot.exh", header=F)
dim(ery.sfs.boot)
# number of segregating sites:
S.ery.boot = apply( ery.sfs.boot, c(1), function(x) sum(x[2:length(x)]) )
quantile(S.ery.boot, probs=c(.025, .975))
# average number of pairwise differences:
PI = function(sfs){
  n.half = 18
  n = 36
  1/(n*(n-1)/2) * sum( sapply(1:n.half, function(i) i*(n-i)*sfs[i]) )
}
pi.ery.boot = apply( ery.sfs.boot, c(1), function(x) PI( x[2:length(x)] ) )
head(pi.ery.boot)
quantile(pi.ery.boot, probs=c(.025, .975))
```



```{r}
par.sfs.boot = read.table("PAR/PAR.FOLDED.sfs.boot.exh", header=F)
# number of segregating sites:
S.par.boot = apply( par.sfs.boot, c(1), function(x) sum(x[2:length(x)]) )
quantile(S.par.boot, probs=c(.025, .975))
# average number of pairwise differences:
pi.par.boot = apply( par.sfs.boot, c(1), function(x) PI( x[2:length(x)] ) )
head(pi.par.boot)
quantile(pi.par.boot, probs=c(.025, .975))
```


```{r}
ery.sfs = read.table("ERY/ERY.FOLDED.sfs", header=F)
ery.nSites = sum(ery.sfs)
S.ery = apply( ery.sfs, c(1), function(x) sum(x[2:length(x)]) )
pi.ery = apply( ery.sfs, c(1), function(x) PI( x[2:length(x)] ) )
#
par.sfs = read.table("PAR/PAR.FOLDED.sfs", header=F)
par.nSites = sum(par.sfs)
S.par = apply( par.sfs, c(1), function(x) sum(x[2:length(x)]) )
pi.par = apply( par.sfs, c(1), function(x) PI( x[2:length(x)] ) )
```



```{r}
plot(density(S.ery.boot/ery.nSites),
     xlab=expression(S[prop]),
     xlim=range(S.ery.boot/ery.nSites, S.par.boot/par.nSites),
     main="Proportion of segregating sites\nfrom 200 bootstraps of the SFS")
lines(density(S.par.boot/par.nSites), lty=2, lwd=1.5)
points(c(S.ery/ery.nSites, S.par/par.nSites), c(0, 0), pch=3)
legend("topright", legend=c("erythropus", "parallelus", "real sample"), 
       lty=c(1, 2, NA), lwd=c(1, 1.5, NA), pch=c(NA, NA, 3), bty="n")
```

```{r}
plot(density(pi.ery.boot/ery.nSites),
     xlim=range(c(pi.ery.boot/ery.nSites, pi.par.boot/par.nSites)),
     xlab=expression(pi[site]),
     main="Average number of pairwise differences\nper nucleotide from 200 bootstraps of the SFS"
     )
lines(density(pi.par.boot/par.nSites), lty=2, lwd=1.5)
points(c(pi.ery/ery.nSites, pi.par/par.nSites), c(0, 0), pch=3)
legend("topright", legend=c("erythropus", "parallelus", "real sample"), lty=c(1, 2, NA), 
       lwd=c(1, 1.5, NA), pch=c(NA, NA, 3), bty="n")
```

Both $S_{site}$ and $\pi_{site}$ are considerably higher in _parallelus_ than in _erythropus_. If _parallelus_ is derived from a Balkan refuge, I would expect it to have undergone a series of founder events. These should have reduced diversity, at least $\pi$, in _parallelus_ more than  in _erythropus_ that comparitively would have had only a short distance to migrate from its glacial refuge. Subsequent population expansion would have allowed $S$ to recover quickly. 



### Global Tajima's D

```{r}
# 1. calculate constant (see p. 45 in Gillespie)
# ery
n = 36
a1 = sum(sapply(1:(n-1), function(x) x^(-1)))
a1
a2 = sum(sapply(1:(n-1), function(x) x^(-2)))
b1 = (n+1)/(3*(n-1))
b2 = 2*(n^2+n+3)/(9*n*(n-1))
c1 = b1 - (1/a1)
c2 = b2 - (n+2)/(a1*n)+a2/a1^2
C = sqrt( c1/a1*S.ery + (c2/(a1^2+a2))*S.ery*(S.ery-1) )
C
( ery.TajimasD.global = (pi.ery - S.ery/a1)/C )
```

```{r}
# 1. calculate constant (see p. 45 in Gillespie)
# par
n = 36
a1 = sum(sapply(1:(n-1), function(x) x^(-1)))
a2 = sum(sapply(1:(n-1), function(x) x^(-2)))
b1 = (n+1)/(3*(n-1))
b2 = 2*(n^2+n+3)/(9*n*(n-1))
c1 = b1 - (1/a1)
c2 = b2 - (n+2)/(a1*n)+a2/a1^2
C = sqrt( c1/a1*S.par + (c2/(a1^2+a2))*S.par*(S.par-1) )
( par.TajimasD.global = (pi.par - S.par/a1)/C )
```

Both global Tajima's D values are significantly different from 0 and negative. I think this means that there is an excess of low frequency variants, which might be an expansion signal, i. e. many variable sites are recent. However, the magnitude of Tajima's D seems supicious to me.

```{r}
C.boot = sqrt( c1/a1*S.ery.boot + (c2/(a1^2+a2))*S.ery.boot*(S.ery.boot-1) )
ery.TajimasD.global.boot = (pi.ery.boot - S.ery.boot/a1)/C.boot
#
C.boot = sqrt( c1/a1*S.par.boot + (c2/(a1^2+a2))*S.par.boot*(S.par.boot-1) )
par.TajimasD.global.boot = (pi.par.boot - S.par.boot/a1)/C.boot
#
plot(density(ery.TajimasD.global.boot),
     xlim=range(ery.TajimasD.global.boot, par.TajimasD.global.boot),
     type="l",
     xlab="Tajima's D",
     main="global Tajima's D\nfrom 200 bootstraps of SFS"
     )
lines(density(par.TajimasD.global.boot), lty=2, lwd=1.5)
points(c(ery.TajimasD.global, par.TajimasD.global), c(0, 0), pch=3)
legend("top", legend=c("erythropus", "parallelus", "real sample"), lty=c(1, 2, NA), 
       lwd=c(1, 1.5, NA), pch=c(NA, NA, 3), bty="n")
```


### Tajima's D per contig

I have estimated per-contig Tajima's D values with the empirical Bayes method described in Korneliussen2013. This uses the ML global SFS as prior for posterior SAF's that are summed across sites to get the SFS for a region/contig. From this local SFS, local $S$, $\pi$ and Tajima's D can be derived.


```{r}
pp = pipe("cut -f 2,4,5,9,14 /data3/claudius/Big_Data/ANGSD/THETASTAT/ERY/ERY.thetas.gz.pestPG", 
          open="r"
          )
thetas.ery = read.table(pp, header=TRUE)
close(pp)
head(thetas.ery)
nrow(thetas.ery)
#
pp = pipe("cut -f 2,4,5,9,14 /data3/claudius/Big_Data/ANGSD/THETASTAT/PAR/PAR.thetas.gz.pestPG", 
          open="r"
          )
thetas.par = read.table(pp, header=TRUE)
close(pp)
head(thetas.par)
nrow(thetas.par)
save(thetas.ery, thetas.par, file="thetas.RData")
```

```{r, fig.height=10, fig.width=10}
par(mfrow=c(2,1))
hist(thetas.ery$Tajima, breaks=40, 
     main=paste("Distributions of Tajima's D over ", nrow(thetas.ery), " contigs"),
     xlab="Tajima's D"
     )
legend("topright", legend=c("erythropus"), bty="n")
hist(thetas.par$Tajima, breaks=40,
     main=paste("Distributions of Tajima's D over ", nrow(thetas.par), " contigs"),
     xlab="Tajima's D"
     )
legend("topright", legend=c("parallelus"), bty="n")
```

Why are the per-contig Tajima's D estimates so much higher than the global estimate?




```{r, eval=FALSE, echo=FALSE}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

```{r, eval=FALSE, echo=FALSE}
library(ggplot2)
#
sfs = data.frame(minor_allele_frequency=1:length(ery.sfs), number_of_sites=ery.sfs)
spectrum = ggplot(sfs, aes(minor_allele_frequency))
p1 = spectrum + geom_ribbon(aes(ymax=ery.sfs.CI95$high, ymin=ery.sfs.CI95$low), fill="grey70") + geom_line(aes(y=number_of_sites))
#
sfs = data.frame(minor_allele_frequency=1:length(par.sfs), number_of_sites=par.sfs)
spectrum = ggplot(sfs, aes(minor_allele_frequency))
p2 = spectrum + geom_ribbon(aes(ymax=par.sfs.CI95$high, ymin=par.sfs.CI95$low), fill="grey70") + geom_line(aes(y=number_of_sites))
#
multiplot(p1, p2, cols=1)
```

```{r, eval=FALSE, echo=FALSE}
ery.sfs.range = data.frame(min=vector("double", ncol(ery.sfs.boot)), max=vector("double", ncol(ery.sfs.boot)))
for(i in 1:ncol(ery.sfs.boot)){
  ery.sfs.range[i,] = range(ery.sfs.boot[,i])
}
#
par.sfs.range = data.frame(min=vector("double", ncol(par.sfs.boot)), max=vector("double", ncol(par.sfs.boot)))
for(i in 1:ncol(par.sfs.boot)){
  par.sfs.range[i,] = range(par.sfs.boot[,i])
}
#
sfs = data.frame(minor_allele_frequency=1:length(ery.sfs), number_of_sites=ery.sfs)
spectrum = ggplot(sfs, aes(minor_allele_frequency))
p1 = spectrum + geom_ribbon(aes(ymax=ery.sfs.range$max, ymin=ery.sfs.range$min), fill="grey70") + geom_line(aes(y=number_of_sites))
#
sfs = data.frame(minor_allele_frequency=1:length(par.sfs), number_of_sites=par.sfs)
spectrum = ggplot(sfs, aes(minor_allele_frequency))
p2 = spectrum + geom_ribbon(aes(ymax=par.sfs.range$max, ymin=par.sfs.range$min), fill="grey70") + geom_line(aes(y=number_of_sites))
#
multiplot(p1, p2, cols=1)
```

```{r, eval=FALSE, echo=FALSE}
sfs = data.frame(minor_allele_frequency=1:length(par.sfs), number_of_sites=par.sfs)
spectrum = ggplot(sfs, aes(minor_allele_frequency))
p1 = spectrum + geom_ribbon(aes(ymax=par.sfs.CI95$high, ymin=par.sfs.CI95$low), fill="grey70") + geom_line(aes(y=number_of_sites))
#
sfs = data.frame(minor_allele_frequency=1:length(par.sfs), number_of_sites=par.sfs)
spectrum = ggplot(sfs, aes(minor_allele_frequency))
p2 = spectrum + geom_ribbon(aes(ymax=par.sfs.range$max, ymin=par.sfs.range$min), fill="grey70") + geom_line(aes(y=number_of_sites))
#
multiplot(p1, p2, cols=1)
```



## References
