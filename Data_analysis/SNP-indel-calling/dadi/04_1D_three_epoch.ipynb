{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"erythropus-1\" href=\"#erythropus\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>erythropus</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"parallelus-2\" href=\"#parallelus\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>parallelus</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"retry-two_epoch-model-with-PAR-spectrum-21\" href=\"#retry-two_epoch-model-with-PAR-spectrum\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>retry two_epoch model with PAR spectrum</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"retry-two_epoch-model-with-ery-spectrum-3\" href=\"#retry-two_epoch-model-with-ery-spectrum\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>retry two_epoch model with ery spectrum</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# erythropus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to use the same parallel framework as used for the `bottlegrowth` model, i. e. using the `subprocess` module to spawn different processes for different optimisations and using `pgrep` together with `kill` to abort jobs that run too long. For smaller optimisations, I am going to use `ipyparallel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a python script called `run_dadi.py`, which can take many command line arguments and in the following parallel framework is the replacement for the `run_dadi` function used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%less run_dadi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_dadi.py [-h] [-p PATH_TO_SPECTRUM_FILE] [-m DADI_MODEL] [-u UPPER]\r\n",
      "                   [-l LOWER] [-i P_INIT] [-d DADI_OPT_FUNC] [-s STUB]\r\n",
      "                   [--maxiter MAXITER]\r\n",
      "\r\n",
      "runs dadi optimisation of parameters for given model\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -p PATH_TO_SPECTRUM_FILE, --path_to_spectrum_file PATH_TO_SPECTRUM_FILE\r\n",
      "                        file path to site frequency data\r\n",
      "  -m DADI_MODEL, --dadi_model DADI_MODEL\r\n",
      "                        model function to use\r\n",
      "  -u UPPER, --upper UPPER\r\n",
      "                        upper parameter bound\r\n",
      "  -l LOWER, --lower LOWER\r\n",
      "                        lower parameter bound\r\n",
      "  -i P_INIT, --p_init P_INIT\r\n",
      "                        initial parameter values\r\n",
      "  -d DADI_OPT_FUNC, --dadi_opt_func DADI_OPT_FUNC\r\n",
      "                        dadi optimisation function to use\r\n",
      "  -s STUB, --stub STUB  file name stub for output files\r\n",
      "  --maxiter MAXITER     maximum number of iterations allowed\r\n"
     ]
    }
   ],
   "source": [
    "! ./run_dadi.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import subprocess32 as subprocess\n",
    "import time, signal, os, pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/claudius/Downloads/dadi')\n",
    "\n",
    "import dadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?dadi.Demographics1D.three_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The built-in `three_epoch` model specifies a piecewise history (with only instantaneous population size changes instead of gradual changes). At time $TF+TB$ the ancient population underwent a size change, stayed at this size for $TB \\times 2N_{ref}$ generations and then underwent a second size size change $TF \\times 2N_{ref}$ generations in the past to the contemporary population size. The model has therefore two population size parameters, $\\nu_B$ and $\\nu_F$ as well as two time parameters, $TB$ and $TF$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set lower and upper bounds to nuB, nuF and T\n",
    "upper_bound = [1e4, 1e4, 4, 4]\n",
    "lower_bound = [1e-4, 1e-4, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create range of starting values evenly distributed in log space\n",
    "p0_nuB = np.logspace(-3, 3, base=10.0, num=6)\n",
    "p0_nuF = np.logspace(-3, 3, base=10.0, num=6)\n",
    "p0_TF = np.logspace(-4, np.log10(4), base=10, num=6)\n",
    "p0_TB = np.logspace(-4, np.log10(4), base=10, num=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1296 starting parameter values\n"
     ]
    }
   ],
   "source": [
    "print \"There are %d starting parameter values\" % (6**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are already an enormous amount of parameter combinations. I think I will need to keep `maxiter` low so that optimisations that do not converge early end more quickly when they hit the maximum number of iterations. I will also frequently have to prune the available cores of optimisation runs that have already taken a considerable amount of time. This can be done with the following command:\n",
    "\n",
    "    pgrep -of \"python ./run_dadi.py\" | xargs kill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variables will be passed as string values to `run_dadi.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_spectrum_file = \"dadiExercises/ERY.FOLDED.sfs.dadi_format\"\n",
    "dadi_model = \"dadi.Demographics1D.three_epoch\"\n",
    "upper = str(upper_bound)\n",
    "lower = str(lower_bound)\n",
    "dadi_opt_func = \"dadi.Inference.optimize_log_fmin\" # Nelder-Mead\n",
    "stub = \"ERY_three_epoch_NM\"\n",
    "maxiter = 10 # keep maxiter low, but not too low to allow convergence of some optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_dadi.py [-h] [-p PATH_TO_SPECTRUM_FILE] [-m DADI_MODEL] [-u UPPER]\n",
      "                   [-l LOWER] [-i P_INIT] [-d DADI_OPT_FUNC] [-s STUB]\n",
      "                   [--maxiter MAXITER]\n",
      "\n",
      "runs dadi optimisation of parameters for given model\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p PATH_TO_SPECTRUM_FILE, --path_to_spectrum_file PATH_TO_SPECTRUM_FILE\n",
      "                        file path to site frequency data\n",
      "  -m DADI_MODEL, --dadi_model DADI_MODEL\n",
      "                        model function to use\n",
      "  -u UPPER, --upper UPPER\n",
      "                        upper parameter bound\n",
      "  -l LOWER, --lower LOWER\n",
      "                        lower parameter bound\n",
      "  -i P_INIT, --p_init P_INIT\n",
      "                        initial parameter values\n",
      "  -d DADI_OPT_FUNC, --dadi_opt_func DADI_OPT_FUNC\n",
      "                        dadi optimisation function to use\n",
      "  -s STUB, --stub STUB  file name stub for output files\n",
      "  --maxiter MAXITER     maximum number of iterations allowed\n"
     ]
    }
   ],
   "source": [
    "%run run_dadi.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_dadi.py -p dadiExercises/ERY.FOLDED.sfs.dadi_format -m dadi.Demographics1D.three_epoch -u '[10000.0, 10000.0, 4, 4]' -l '[0.0001, 0.0001, 0, 0]' -d dadi.Inference.optimize_log_fmin -s ERY_three_epoch_NM --maxiter 10 -i '(0.001, 0.001, 0.0001, 0.0001)'\n"
     ]
    }
   ],
   "source": [
    "# check creation of command line\n",
    "\n",
    "for i, p_init in enumerate(product(p0_nuB, p0_nuF, p0_TF, p0_TB)):\n",
    "    cmd = \"./run_dadi.py -p %s -m %s -u '%s' -l '%s' -d %s -s %s --maxiter %s -i '%s'\" \\\n",
    "                % (path_to_spectrum_file, dadi_model, upper, lower, dadi_opt_func, stub, str(maxiter), str(p_init))\n",
    "    print cmd\n",
    "    if i >= 0: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need to define an executor class that takes care of submiting jobs as slots become available. This is taken from [Tiago Antao's Cookbook](http://tiago.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class executor:\n",
    "    def __init__(self, limit):\n",
    "        self.limit = limit\n",
    "        self.ncores = multiprocessing.cpu_count()\n",
    "        self.running = []\n",
    "        self.finished = 0\n",
    "\n",
    "    def submit(self, cmd, p_init):\n",
    "        self.wait() \n",
    "        if hasattr(self, 'out'):\n",
    "            out = self.out\n",
    "        else:\n",
    "            out = '/dev/null'\n",
    "        if hasattr(self, 'err'):\n",
    "            err = self.err\n",
    "        else:\n",
    "            err = '/dev/null'\n",
    "        if err == 'stderr':\n",
    "            errSt = ''\n",
    "        else:\n",
    "            errSt = '2> ' + err\n",
    "        # this is where the magic happens:\n",
    "        proc = subprocess.Popen('%s > %s %s' % (cmd, out, errSt), shell=True)\n",
    "        self.running.append(proc)\n",
    "        #\n",
    "        if hasattr(self, 'out'):\n",
    "            del self.out\n",
    "        if hasattr(self, 'err'):\n",
    "            del self.err\n",
    "            \n",
    "    def wait(self, for_all=False):\n",
    "        self.clean_done()\n",
    "        #numWaits = 0\n",
    "        if self.limit > 0 and type(self.limit) == int:\n",
    "            cond = 'len(self.running) >= self.ncores - self.limit'\n",
    "        elif self.limit < 0:\n",
    "            cond = 'len(self.running) >= - self.limit'\n",
    "        else:\n",
    "            cond = 'len(self.running) >= self.ncores * self.limit'\n",
    "        while eval(cond) or (for_all and len(self.running) > 0):\n",
    "            time.sleep(1)\n",
    "            self.clean_done() # updates self.running, removes finished jobs from the running queue\n",
    "            #numWaits += 1\n",
    "            \n",
    "    def clean_done(self):\n",
    "        terminated = []\n",
    "        for i, p in enumerate(self.running):\n",
    "            if p.poll() is not None: # None means it's still running\n",
    "                terminated.append(i)\n",
    "        for idx in reversed(terminated):\n",
    "            del self.running[idx]\n",
    "            self.finished += 1\n",
    "            \n",
    "    def progress(self):\n",
    "        self.clean_done()\n",
    "        print self.finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E = executor(limit=-18) # use up to 18 cores\n",
    "\n",
    "# this will block\n",
    "for i, p_init in enumerate(product(p0_nuB, p0_nuF, p0_TF, p0_TB)):\n",
    "    cmd = \"./run_dadi.py -p %s -m %s -u '%s' -l '%s' -d %s -s %s --maxiter %s -i '%s'\" \\\n",
    "                % (path_to_spectrum_file, dadi_model, upper, lower, dadi_opt_func, stub, str(maxiter), str(p_init))\n",
    "    E.err = \"stderr\"\n",
    "    E.submit(cmd, p_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After 191 output file had been created, I loaded those pickle files into another notebook (because the upper command blocks the current session). A check of the returned optimisation flags showed that all 191 optimisations had reached the maximum number of iterations, i. e. none had converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 414 optimisations without a single successful optimisation, I have decided to abort this sweep through the parameter space. Due to the size of the parameter space, even with just 6 samples per parameter, increasing the maximum number of allowed iterations per optimisation is not an option due to prohibitive running time given this is still an exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think my only option of finding optimal parameter values for this model is to start at some reasonable combination of parameters, perturb them and run optimisations with those slightly perturbed initial parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try to do this with `ipyparallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "cl = Client()\n",
    "\n",
    "cl.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# run whole cell on all engines a well as in the local IPython session\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/claudius/Downloads/dadi')\n",
    "\n",
    "import dadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2300\r\n",
      "-rw-rw-r-- 1 claudius 671626 Apr 22 08:22 01_dadi_1D_exp_growth.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 248481 Apr 22 11:27 02_dadi_1D_two_epoch.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 148443 Apr 22 12:25 03_1D_bottlegrowth.ipynb\r\n",
      "-rw-rw-r-- 1 claudius  97634 Apr 22 15:54 04_1D_three_epoch.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 297053 Apr 22 15:51 05_1D_model_synthesis.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 118564 Apr 20 16:47 05_2D.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 444729 Apr 21 10:05 1D_models.ipynb\r\n",
      "-rw-rw-r-- 1 claudius  33125 Apr  8 18:15 1D_two_epoch_opt_res_ERY.dill\r\n",
      "-rw-rw-r-- 1 claudius  16613 Apr  8 19:18 1D_two_epoch_opt_res_PAR.dill\r\n",
      "drwxrwxr-x 4 claudius   4096 Apr 20 10:19 \u001b[0m\u001b[01;34mdadiExercises\u001b[0m/\r\n",
      "-rw-rw-r-- 1 claudius  36308 Apr  3 20:33 \u001b[01;35mery_fold_comp.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 claudius   3560 Mar 25 08:40 EryPar.FOLDED.2dsfs\r\n",
      "-rw-rw-r-- 1 claudius    433 Mar 24 20:15 ERY.unfolded.sfs\r\n",
      "-rw-rw-r-- 1 claudius    421 Mar 24 20:14 ERY.unfolded.sfs~\r\n",
      "-rw-rw-r-- 1 claudius  13913 Apr  6 15:03 exp_growth_optim_res_ERY.pickle\r\n",
      "-rw-rw-r-- 1 claudius  13913 Apr  6 19:21 exp_growth_optim_res_PAR.pickle\r\n",
      "drwxrwxr-x 2 claudius   4096 Apr 22 11:55 \u001b[01;34mOUT_bottlegrowth\u001b[0m/\r\n",
      "drwxrwxr-x 2 claudius  24576 Apr 21 20:19 \u001b[01;34mOUT_exp_growth_model\u001b[0m/\r\n",
      "drwxrwxr-x 2 claudius  73728 Apr 19 17:00 \u001b[01;34mOUT_run_dadi\u001b[0m/\r\n",
      "-rw-rw-r-- 1 claudius  37242 Apr  3 20:35 \u001b[01;35mpar_fold_comp.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 claudius    421 Mar 24 20:16 PAR.unfolded.sfs\r\n",
      "-rw-rw-r-- 1 claudius    409 Mar 24 20:15 PAR.unfolded.sfs~\r\n",
      "-rwxrwxr-x 1 claudius   2790 Apr 17 22:18 \u001b[01;32mrun_dadi.py\u001b[0m*\r\n",
      "-rwxrwxr-x 1 claudius   2790 Apr 17 22:05 \u001b[01;32mrun_dadi.py~\u001b[0m*\r\n",
      "-rw-rw-r-- 1 claudius  12387 Apr 19 16:57 test.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 unfolded\r\n",
      "1592046.636125 7148.627587 6831.828430 3473.268669 3417.591990 2249.932322 1980.824357 1011.763357 2262.489617 557.169754 1049.858226 1159.694611 768.373223 1125.393799 448.462048 544.635916 1014.348661 147.731786 975.251801 233.415985 851.137519 12.642136 803.134099 0.128476 567.179523 446.009983 158.967094 484.096759 372.705620 540.860079 95.276852 808.290844 234.084809 614.920896 625.008059 890.804592 2515.454396 \r\n"
     ]
    }
   ],
   "source": [
    "! cat ERY.unfolded.sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_ery = dadi.Spectrum.from_file('ERY.unfolded.sfs').fold()\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_par = dadi.Spectrum.from_file('PAR.unfolded.sfs').fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "ns = fs_ery.sample_sizes # both populations have the same sample size\n",
    "\n",
    "fs_ery.pop_ids = ['ery']\n",
    "fs_par.pop_ids = ['par']\n",
    "\n",
    "# setting the smallest grid size slightly larger than the largest population sample size (36)\n",
    "pts_l = [50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# create link to function that specifies the model\n",
    "func = dadi.Demographics1D.three_epoch\n",
    "\n",
    "# create extrapolating version of the model function\n",
    "func_ex = dadi.Numerics.make_extrap_log_func(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set lower and upper bounds to nuB, nuF and T\n",
    "upper_bound = [1e4, 1e4, 4, 4]\n",
    "lower_bound = [1e-4, 1e-4, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create load balanced view of engines\n",
    "\n",
    "lbview = cl.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dadi(p_init): # for the function to be called with map, it needs to have one input variable\n",
    "    \"\"\"\n",
    "    p_init: initial parameter values to run optimisation from\n",
    "    \"\"\"\n",
    "    if perturb == True:\n",
    "        p_init = dadi.Misc.perturb_params(p_init, fold=fold, \n",
    "                                      upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "        # note upper_bound and lower_bound variables are expected to be in the namespace of each engine\n",
    "    # run optimisation of paramters\n",
    "    popt = dadi_opt_func(p0=p_init, data=sfs, model_func=func_ex, pts=pts_l, \\\n",
    "                                   lower_bound=lower_bound, upper_bound=upper_bound, \\\n",
    "                                   verbose=verbose, maxiter=maxiter, full_output=full_output)\n",
    "    return p_init, popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set up global variables on engines required for run_dadi function call\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log_fmin # uses Nelder-Mead algorithm\n",
    "sfs = fs_ery # use ERY spectrum\n",
    "perturb = True\n",
    "fold = 2\n",
    "maxiter = 20 # run a maximum of 20 iterations\n",
    "verbose = 0\n",
    "full_output = True # need to have full output to get the warnflags (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 2\n",
    "p0 = [1, 1, 1, 1]\n",
    "# these parameters indicate no size changes at times 1 and 2 (x 2N) generations in the past\n",
    "\n",
    "ar_ery = lbview.map(run_dadi, repeat([1, 1, 1, 1], 40), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.650946"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery.wall_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_flag_count(out, NM=True):\n",
    "    \"\"\"\n",
    "    out: list of tuples, each containing p_init and popt + additional info, including warnflags\n",
    "    as produced by run_dadi.py\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    if NM: # if ar from Nelder-Mead\n",
    "        i = 4 # the warnflag is reported at index position 4 in the output array\n",
    "    else: # ar from BFGS optimisation\n",
    "        i = 6\n",
    "    \n",
    "    warnflag = defaultdict(int)\n",
    "\n",
    "    for res in out:\n",
    "        if res[1][i] == 1: # notice the change in indexing\n",
    "            warnflag[1] +=1\n",
    "        elif res[1][i] == 2:\n",
    "            warnflag[2] += 1\n",
    "        elif res[1][i] == 0:\n",
    "            warnflag[0] += 1\n",
    "        else:\n",
    "            warnflag[999] +=1\n",
    "    if NM:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of function evaluations made.\", warnflag[1]\n",
    "        print \"Maximum number of iterations reached.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]\n",
    "    else:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of iterations exceeded.\", warnflag[1]\n",
    "        print \"Gradient and/or function calls not changing.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 0\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 40\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_ery, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, I obviously need to increase the number of iterations. Since the upper run was extremely fast, I am bold enough to increase `maxiter` to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "maxiter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl[0]['maxiter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run 40 optimisations with perturbed p0 and maxiter=100\n",
    "\n",
    "ar_ery = lbview.map(run_dadi, repeat(p0, 40), block=False, order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.171281"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery.wall_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 7\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 33\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_ery, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.85654414  0.24992367  2.21238517  1.25368939] 2168.11186438\n",
      "[ 1.55644243  0.26882739  0.18443449  1.18648075] 2168.11186793\n",
      "[ 5.54171522  0.85587957  2.14281429  3.38509467] 2168.11188321\n",
      "[ 0.32211174  0.22622996  0.15448801  0.94006958] 2168.11186656\n",
      "[ 0.95664403  0.33589903  0.15976201  1.34434968] 2168.11187225\n",
      "[ 2.41036662  0.21918639  0.16579024  1.03361692] 2168.11186581\n",
      "[ 0.03328397  0.11515687  3.99449464  3.37126089] 2173.46212955\n"
     ]
    }
   ],
   "source": [
    "for out in ar_ery:\n",
    "    if out[1][4] == 0:\n",
    "        print out[1][0], out[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save optimisation results to file\n",
    "\n",
    "dill.dump(list(ar_ery.get()), open(\"OUT_three_epoch/ERY_perturb_ar_ery.dill\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    \"\"\"\n",
    "        Returns a list of flattened elements of every inner lists (or tuples)\n",
    "        ****RECURSIVE****\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    res = []\n",
    "    for el in array:\n",
    "        if isinstance(el, (list, tuple, numpy.ndarray)):\n",
    "            res.extend(flatten(el))\n",
    "            continue\n",
    "        res.append(el)\n",
    "    return list( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "successfull_popt = [flatten(out)[:9] for out in ar_ery if out[1][4] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>-logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.555383</td>\n",
       "      <td>0.293791</td>\n",
       "      <td>1.935427</td>\n",
       "      <td>0.293656</td>\n",
       "      <td>1.856544</td>\n",
       "      <td>0.249924</td>\n",
       "      <td>2.212385</td>\n",
       "      <td>1.253689</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.361740</td>\n",
       "      <td>0.396505</td>\n",
       "      <td>0.305203</td>\n",
       "      <td>0.715585</td>\n",
       "      <td>2.410367</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>0.165790</td>\n",
       "      <td>1.033617</td>\n",
       "      <td>2168.111866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308729</td>\n",
       "      <td>2.380386</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.322112</td>\n",
       "      <td>0.226230</td>\n",
       "      <td>0.154488</td>\n",
       "      <td>0.940070</td>\n",
       "      <td>2168.111867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.374368</td>\n",
       "      <td>0.309479</td>\n",
       "      <td>0.322377</td>\n",
       "      <td>0.356217</td>\n",
       "      <td>1.556442</td>\n",
       "      <td>0.268827</td>\n",
       "      <td>0.184434</td>\n",
       "      <td>1.186481</td>\n",
       "      <td>2168.111868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973349</td>\n",
       "      <td>0.396776</td>\n",
       "      <td>0.298970</td>\n",
       "      <td>0.582019</td>\n",
       "      <td>0.956644</td>\n",
       "      <td>0.335899</td>\n",
       "      <td>0.159762</td>\n",
       "      <td>1.344350</td>\n",
       "      <td>2168.111872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583930</td>\n",
       "      <td>0.930936</td>\n",
       "      <td>1.184826</td>\n",
       "      <td>3.432361</td>\n",
       "      <td>5.541715</td>\n",
       "      <td>0.855880</td>\n",
       "      <td>2.142814</td>\n",
       "      <td>3.385095</td>\n",
       "      <td>2168.111883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.259739</td>\n",
       "      <td>3.858553</td>\n",
       "      <td>3.172399</td>\n",
       "      <td>3.006089</td>\n",
       "      <td>0.033284</td>\n",
       "      <td>0.115157</td>\n",
       "      <td>3.994495</td>\n",
       "      <td>3.371261</td>\n",
       "      <td>2173.462130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nuB_0     nuF_0      TB_0      TF_0   nuB_opt   nuF_opt    TB_opt  \\\n",
       "0  1.555383  0.293791  1.935427  0.293656  1.856544  0.249924  2.212385   \n",
       "5  2.361740  0.396505  0.305203  0.715585  2.410367  0.219186  0.165790   \n",
       "3  0.308729  2.380386  0.499412  0.948869  0.322112  0.226230  0.154488   \n",
       "1  1.374368  0.309479  0.322377  0.356217  1.556442  0.268827  0.184434   \n",
       "4  0.973349  0.396776  0.298970  0.582019  0.956644  0.335899  0.159762   \n",
       "2  0.583930  0.930936  1.184826  3.432361  5.541715  0.855880  2.142814   \n",
       "6  0.259739  3.858553  3.172399  3.006089  0.033284  0.115157  3.994495   \n",
       "\n",
       "     TF_opt        -logL  \n",
       "0  1.253689  2168.111864  \n",
       "5  1.033617  2168.111866  \n",
       "3  0.940070  2168.111867  \n",
       "1  1.186481  2168.111868  \n",
       "4  1.344350  2168.111872  \n",
       "2  3.385095  2168.111883  \n",
       "6  3.371261  2173.462130  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', '-logL'])\n",
    "\n",
    "df.sort_values(by='-logL', ascending=True) # smaller is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly different parameter combinations have practically identical likelihood. A reduction of the contemporary population size to 1/4 of the ancient population size is quite conistently inferred ($\\nu_F$). The ancient population size change is not inferred consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to try one more p0. In the two epoch model fitting, _erythropus_ had shown an ancient increase in population size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 2\n",
    "p0 = [40, 0.4, 0.5, 0.5]\n",
    "\n",
    "ar_ery_1 = lbview.map(run_dadi, repeat(p0, 40), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery_1.ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 15\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 25\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_ery_1, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>-logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.392331</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>1.702540</td>\n",
       "      <td>0.215492</td>\n",
       "      <td>17.358511</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>1.751921</td>\n",
       "      <td>0.391672</td>\n",
       "      <td>2168.111862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>71.979569</td>\n",
       "      <td>0.113046</td>\n",
       "      <td>0.331147</td>\n",
       "      <td>0.319804</td>\n",
       "      <td>82.969982</td>\n",
       "      <td>0.071288</td>\n",
       "      <td>0.298778</td>\n",
       "      <td>0.440360</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.252442</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.363293</td>\n",
       "      <td>0.315070</td>\n",
       "      <td>17.776575</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>0.317333</td>\n",
       "      <td>0.488813</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.352276</td>\n",
       "      <td>0.157910</td>\n",
       "      <td>0.181752</td>\n",
       "      <td>0.367491</td>\n",
       "      <td>65.505369</td>\n",
       "      <td>0.094434</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>0.542281</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.983834</td>\n",
       "      <td>0.246236</td>\n",
       "      <td>1.010640</td>\n",
       "      <td>0.540040</td>\n",
       "      <td>14.930735</td>\n",
       "      <td>0.130152</td>\n",
       "      <td>1.010041</td>\n",
       "      <td>0.774382</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.335137</td>\n",
       "      <td>0.174836</td>\n",
       "      <td>0.340843</td>\n",
       "      <td>0.434766</td>\n",
       "      <td>27.042723</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>0.296612</td>\n",
       "      <td>0.609153</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.267625</td>\n",
       "      <td>0.147428</td>\n",
       "      <td>0.620736</td>\n",
       "      <td>0.681960</td>\n",
       "      <td>13.975804</td>\n",
       "      <td>0.118970</td>\n",
       "      <td>0.608653</td>\n",
       "      <td>0.692754</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.452932</td>\n",
       "      <td>0.144727</td>\n",
       "      <td>0.249397</td>\n",
       "      <td>0.135380</td>\n",
       "      <td>180.518767</td>\n",
       "      <td>0.116126</td>\n",
       "      <td>0.170522</td>\n",
       "      <td>0.643191</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>121.895028</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.553528</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>186.363472</td>\n",
       "      <td>0.136292</td>\n",
       "      <td>0.505059</td>\n",
       "      <td>0.768389</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.193921</td>\n",
       "      <td>0.330266</td>\n",
       "      <td>1.077031</td>\n",
       "      <td>0.456888</td>\n",
       "      <td>25.926112</td>\n",
       "      <td>0.192458</td>\n",
       "      <td>1.111311</td>\n",
       "      <td>1.077319</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.459448</td>\n",
       "      <td>0.243839</td>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.261546</td>\n",
       "      <td>34.999661</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.845499</td>\n",
       "      <td>1.084962</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.102430</td>\n",
       "      <td>0.268245</td>\n",
       "      <td>0.328126</td>\n",
       "      <td>0.716259</td>\n",
       "      <td>101.661654</td>\n",
       "      <td>0.161491</td>\n",
       "      <td>0.273926</td>\n",
       "      <td>0.849436</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.580333</td>\n",
       "      <td>0.240737</td>\n",
       "      <td>0.852438</td>\n",
       "      <td>0.266042</td>\n",
       "      <td>116.171135</td>\n",
       "      <td>0.200126</td>\n",
       "      <td>0.792436</td>\n",
       "      <td>1.080803</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.867122</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.946355</td>\n",
       "      <td>1.228667</td>\n",
       "      <td>15.668847</td>\n",
       "      <td>0.235957</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>1.240931</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42.524388</td>\n",
       "      <td>0.168468</td>\n",
       "      <td>0.943558</td>\n",
       "      <td>1.667497</td>\n",
       "      <td>92.763715</td>\n",
       "      <td>0.356487</td>\n",
       "      <td>0.935848</td>\n",
       "      <td>1.714824</td>\n",
       "      <td>2168.111867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nuB_0     nuF_0      TB_0      TF_0     nuB_opt   nuF_opt    TB_opt  \\\n",
       "0    18.392331  0.101597  1.702540  0.215492   17.358511  0.054665  1.751921   \n",
       "14   71.979569  0.113046  0.331147  0.319804   82.969982  0.071288  0.298778   \n",
       "1    15.252442  0.138945  0.363293  0.315070   17.776575  0.080865  0.317333   \n",
       "3    51.352276  0.157910  0.181752  0.367491   65.505369  0.094434  0.146645   \n",
       "4    11.983834  0.246236  1.010640  0.540040   14.930735  0.130152  1.010041   \n",
       "5    22.335137  0.174836  0.340843  0.434766   27.042723  0.106110  0.296612   \n",
       "13   15.267625  0.147428  0.620736  0.681960   13.975804  0.118970  0.608653   \n",
       "6    56.452932  0.144727  0.249397  0.135380  180.518767  0.116126  0.170522   \n",
       "12  121.895028  0.256218  0.553528  0.512424  186.363472  0.136292  0.505059   \n",
       "2    21.193921  0.330266  1.077031  0.456888   25.926112  0.192458  1.111311   \n",
       "11   14.459448  0.243839  0.890411  0.261546   34.999661  0.200264  0.845499   \n",
       "8    82.102430  0.268245  0.328126  0.716259  101.661654  0.161491  0.273926   \n",
       "9    36.580333  0.240737  0.852438  0.266042  116.171135  0.200126  0.792436   \n",
       "10   10.867122  0.147365  0.946355  1.228667   15.668847  0.235957  0.942984   \n",
       "7    42.524388  0.168468  0.943558  1.667497   92.763715  0.356487  0.935848   \n",
       "\n",
       "      TF_opt        -logL  \n",
       "0   0.391672  2168.111862  \n",
       "14  0.440360  2168.111863  \n",
       "1   0.488813  2168.111863  \n",
       "3   0.542281  2168.111863  \n",
       "4   0.774382  2168.111863  \n",
       "5   0.609153  2168.111863  \n",
       "13  0.692754  2168.111863  \n",
       "6   0.643191  2168.111863  \n",
       "12  0.768389  2168.111863  \n",
       "2   1.077319  2168.111864  \n",
       "11  1.084962  2168.111864  \n",
       "8   0.849436  2168.111864  \n",
       "9   1.080803  2168.111864  \n",
       "10  1.240931  2168.111864  \n",
       "7   1.714824  2168.111867  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successfull_popt = [flatten(out)[:9] for out in ar_ery_1 if out[1][4] == 0]\n",
    "\n",
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', '-logL'])\n",
    "\n",
    "df.sort_values(by='-logL', ascending=True) # smaller is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this looks like several quite different population histories are equally likely. These parameter values seem to suggest that _erythropus_ first underwent a population increase to a $\\nu_B$ fold of the ancient population size (ranging from 23$\\times$ to $\\gt$7000$\\times$!) and stayed at this size for $TB$ (x2N) generations upon which it dramatically reduced its population size to a fraction $\\nu_F$ of the ancient size and stayed at this size the remaining TF (x2N) generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.dump(list(ar_ery_1.get()), open(\"OUT_three_epoch/ERY_perturb_ar_ery_1.dill\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would be good to visualise these different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>-logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.392331</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>1.702540</td>\n",
       "      <td>0.215492</td>\n",
       "      <td>17.358511</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>1.751921</td>\n",
       "      <td>0.391672</td>\n",
       "      <td>2168.111862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>71.979569</td>\n",
       "      <td>0.113046</td>\n",
       "      <td>0.331147</td>\n",
       "      <td>0.319804</td>\n",
       "      <td>82.969982</td>\n",
       "      <td>0.071288</td>\n",
       "      <td>0.298778</td>\n",
       "      <td>0.440360</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.252442</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.363293</td>\n",
       "      <td>0.315070</td>\n",
       "      <td>17.776575</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>0.317333</td>\n",
       "      <td>0.488813</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.352276</td>\n",
       "      <td>0.157910</td>\n",
       "      <td>0.181752</td>\n",
       "      <td>0.367491</td>\n",
       "      <td>65.505369</td>\n",
       "      <td>0.094434</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>0.542281</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.983834</td>\n",
       "      <td>0.246236</td>\n",
       "      <td>1.010640</td>\n",
       "      <td>0.540040</td>\n",
       "      <td>14.930735</td>\n",
       "      <td>0.130152</td>\n",
       "      <td>1.010041</td>\n",
       "      <td>0.774382</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.335137</td>\n",
       "      <td>0.174836</td>\n",
       "      <td>0.340843</td>\n",
       "      <td>0.434766</td>\n",
       "      <td>27.042723</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>0.296612</td>\n",
       "      <td>0.609153</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.267625</td>\n",
       "      <td>0.147428</td>\n",
       "      <td>0.620736</td>\n",
       "      <td>0.681960</td>\n",
       "      <td>13.975804</td>\n",
       "      <td>0.118970</td>\n",
       "      <td>0.608653</td>\n",
       "      <td>0.692754</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.452932</td>\n",
       "      <td>0.144727</td>\n",
       "      <td>0.249397</td>\n",
       "      <td>0.135380</td>\n",
       "      <td>180.518767</td>\n",
       "      <td>0.116126</td>\n",
       "      <td>0.170522</td>\n",
       "      <td>0.643191</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>121.895028</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.553528</td>\n",
       "      <td>0.512424</td>\n",
       "      <td>186.363472</td>\n",
       "      <td>0.136292</td>\n",
       "      <td>0.505059</td>\n",
       "      <td>0.768389</td>\n",
       "      <td>2168.111863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.193921</td>\n",
       "      <td>0.330266</td>\n",
       "      <td>1.077031</td>\n",
       "      <td>0.456888</td>\n",
       "      <td>25.926112</td>\n",
       "      <td>0.192458</td>\n",
       "      <td>1.111311</td>\n",
       "      <td>1.077319</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.459448</td>\n",
       "      <td>0.243839</td>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.261546</td>\n",
       "      <td>34.999661</td>\n",
       "      <td>0.200264</td>\n",
       "      <td>0.845499</td>\n",
       "      <td>1.084962</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.102430</td>\n",
       "      <td>0.268245</td>\n",
       "      <td>0.328126</td>\n",
       "      <td>0.716259</td>\n",
       "      <td>101.661654</td>\n",
       "      <td>0.161491</td>\n",
       "      <td>0.273926</td>\n",
       "      <td>0.849436</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.580333</td>\n",
       "      <td>0.240737</td>\n",
       "      <td>0.852438</td>\n",
       "      <td>0.266042</td>\n",
       "      <td>116.171135</td>\n",
       "      <td>0.200126</td>\n",
       "      <td>0.792436</td>\n",
       "      <td>1.080803</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.555383</td>\n",
       "      <td>0.293791</td>\n",
       "      <td>1.935427</td>\n",
       "      <td>0.293656</td>\n",
       "      <td>1.856544</td>\n",
       "      <td>0.249924</td>\n",
       "      <td>2.212385</td>\n",
       "      <td>1.253689</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.867122</td>\n",
       "      <td>0.147365</td>\n",
       "      <td>0.946355</td>\n",
       "      <td>1.228667</td>\n",
       "      <td>15.668847</td>\n",
       "      <td>0.235957</td>\n",
       "      <td>0.942984</td>\n",
       "      <td>1.240931</td>\n",
       "      <td>2168.111864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.361740</td>\n",
       "      <td>0.396505</td>\n",
       "      <td>0.305203</td>\n",
       "      <td>0.715585</td>\n",
       "      <td>2.410367</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>0.165790</td>\n",
       "      <td>1.033617</td>\n",
       "      <td>2168.111866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308729</td>\n",
       "      <td>2.380386</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.322112</td>\n",
       "      <td>0.226230</td>\n",
       "      <td>0.154488</td>\n",
       "      <td>0.940070</td>\n",
       "      <td>2168.111867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42.524388</td>\n",
       "      <td>0.168468</td>\n",
       "      <td>0.943558</td>\n",
       "      <td>1.667497</td>\n",
       "      <td>92.763715</td>\n",
       "      <td>0.356487</td>\n",
       "      <td>0.935848</td>\n",
       "      <td>1.714824</td>\n",
       "      <td>2168.111867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.374368</td>\n",
       "      <td>0.309479</td>\n",
       "      <td>0.322377</td>\n",
       "      <td>0.356217</td>\n",
       "      <td>1.556442</td>\n",
       "      <td>0.268827</td>\n",
       "      <td>0.184434</td>\n",
       "      <td>1.186481</td>\n",
       "      <td>2168.111868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973349</td>\n",
       "      <td>0.396776</td>\n",
       "      <td>0.298970</td>\n",
       "      <td>0.582019</td>\n",
       "      <td>0.956644</td>\n",
       "      <td>0.335899</td>\n",
       "      <td>0.159762</td>\n",
       "      <td>1.344350</td>\n",
       "      <td>2168.111872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583930</td>\n",
       "      <td>0.930936</td>\n",
       "      <td>1.184826</td>\n",
       "      <td>3.432361</td>\n",
       "      <td>5.541715</td>\n",
       "      <td>0.855880</td>\n",
       "      <td>2.142814</td>\n",
       "      <td>3.385095</td>\n",
       "      <td>2168.111883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.259739</td>\n",
       "      <td>3.858553</td>\n",
       "      <td>3.172399</td>\n",
       "      <td>3.006089</td>\n",
       "      <td>0.033284</td>\n",
       "      <td>0.115157</td>\n",
       "      <td>3.994495</td>\n",
       "      <td>3.371261</td>\n",
       "      <td>2173.462130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nuB_0     nuF_0      TB_0      TF_0     nuB_opt   nuF_opt    TB_opt  \\\n",
       "0    18.392331  0.101597  1.702540  0.215492   17.358511  0.054665  1.751921   \n",
       "14   71.979569  0.113046  0.331147  0.319804   82.969982  0.071288  0.298778   \n",
       "1    15.252442  0.138945  0.363293  0.315070   17.776575  0.080865  0.317333   \n",
       "3    51.352276  0.157910  0.181752  0.367491   65.505369  0.094434  0.146645   \n",
       "4    11.983834  0.246236  1.010640  0.540040   14.930735  0.130152  1.010041   \n",
       "5    22.335137  0.174836  0.340843  0.434766   27.042723  0.106110  0.296612   \n",
       "13   15.267625  0.147428  0.620736  0.681960   13.975804  0.118970  0.608653   \n",
       "6    56.452932  0.144727  0.249397  0.135380  180.518767  0.116126  0.170522   \n",
       "12  121.895028  0.256218  0.553528  0.512424  186.363472  0.136292  0.505059   \n",
       "2    21.193921  0.330266  1.077031  0.456888   25.926112  0.192458  1.111311   \n",
       "11   14.459448  0.243839  0.890411  0.261546   34.999661  0.200264  0.845499   \n",
       "8    82.102430  0.268245  0.328126  0.716259  101.661654  0.161491  0.273926   \n",
       "9    36.580333  0.240737  0.852438  0.266042  116.171135  0.200126  0.792436   \n",
       "0     1.555383  0.293791  1.935427  0.293656    1.856544  0.249924  2.212385   \n",
       "10   10.867122  0.147365  0.946355  1.228667   15.668847  0.235957  0.942984   \n",
       "5     2.361740  0.396505  0.305203  0.715585    2.410367  0.219186  0.165790   \n",
       "3     0.308729  2.380386  0.499412  0.948869    0.322112  0.226230  0.154488   \n",
       "7    42.524388  0.168468  0.943558  1.667497   92.763715  0.356487  0.935848   \n",
       "1     1.374368  0.309479  0.322377  0.356217    1.556442  0.268827  0.184434   \n",
       "4     0.973349  0.396776  0.298970  0.582019    0.956644  0.335899  0.159762   \n",
       "2     0.583930  0.930936  1.184826  3.432361    5.541715  0.855880  2.142814   \n",
       "6     0.259739  3.858553  3.172399  3.006089    0.033284  0.115157  3.994495   \n",
       "\n",
       "      TF_opt        -logL  \n",
       "0   0.391672  2168.111862  \n",
       "14  0.440360  2168.111863  \n",
       "1   0.488813  2168.111863  \n",
       "3   0.542281  2168.111863  \n",
       "4   0.774382  2168.111863  \n",
       "5   0.609153  2168.111863  \n",
       "13  0.692754  2168.111863  \n",
       "6   0.643191  2168.111863  \n",
       "12  0.768389  2168.111863  \n",
       "2   1.077319  2168.111864  \n",
       "11  1.084962  2168.111864  \n",
       "8   0.849436  2168.111864  \n",
       "9   1.080803  2168.111864  \n",
       "0   1.253689  2168.111864  \n",
       "10  1.240931  2168.111864  \n",
       "5   1.033617  2168.111866  \n",
       "3   0.940070  2168.111867  \n",
       "7   1.714824  2168.111867  \n",
       "1   1.186481  2168.111868  \n",
       "4   1.344350  2168.111872  \n",
       "2   3.385095  2168.111883  \n",
       "6   3.371261  2173.462130  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successfull_popt = [flatten(out)[:9] for out in ar_ery if out[1][4] == 0]\n",
    "\n",
    "df_1 = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', '-logL'])\n",
    "\n",
    "successfull_popt = [flatten(out)[:9] for out in ar_ery_1 if out[1][4] == 0]\n",
    "\n",
    "df_2 = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', '-logL'])\n",
    "\n",
    "df = df_1.append(df_2)\n",
    "df.sort_values(by='-logL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove one parameter combination with slightly lower logL than the others\n",
    "\n",
    "df = df.sort_values(by='-logL').head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['TB+TF'] = pd.Series(df['TB_opt']+df['TF_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>-logL</th>\n",
       "      <th>TB+TF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.392331</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>1.70254</td>\n",
       "      <td>0.215492</td>\n",
       "      <td>17.358511</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>1.751921</td>\n",
       "      <td>0.391672</td>\n",
       "      <td>2168.111862</td>\n",
       "      <td>2.143593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nuB_0     nuF_0     TB_0      TF_0    nuB_opt   nuF_opt    TB_opt  \\\n",
       "0  18.392331  0.101597  1.70254  0.215492  17.358511  0.054665  1.751921   \n",
       "\n",
       "     TF_opt        -logL     TB+TF  \n",
       "0  0.391672  2168.111862  2.143593  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract columns from table\n",
    "nuB = df.loc[:,'nuB_opt']\n",
    "nuF = df.loc[:, 'nuF_opt']\n",
    "Tb_Tf = df.loc[:, 'TB+TF']\n",
    "TF = df.loc[:, 'TF_opt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sequence length for the ery spectrum is 1,638,467.\n"
     ]
    }
   ],
   "source": [
    "# calculate reference (ancient) population size from theta estimate (derived elsewhere by fitting a neutral spectrum)\n",
    "\n",
    "theta_ery = 10617.328085456724\n",
    "mu = 3e-9\n",
    "L = fs_ery.data.sum() # this sums over all entries in the spectrum, including masked ones, i. e. also contains invariable sites\n",
    "print \"The total sequence length for the ery spectrum is {0:,}.\".format(int(L))\n",
    "N_ref_ery = theta_ery/L/mu/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn nu into absolute Ne and T into generations\n",
    "\n",
    "nuB_n = nuB*N_ref_ery\n",
    "nuF_n = nuF*N_ref_ery\n",
    "Tb_Tf_g = Tb_Tf*2*N_ref_ery\n",
    "TF_g = TF*2*N_ref_ery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anc = [N_ref_ery] * len(nuB)\n",
    "pres = [1] * len(nuB)\n",
    "past = [max(Tb_Tf_g)+1000] * len(nuB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fedb3ede2d0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAJgCAYAAADYuZYlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fedb83c8650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [12.0, 10.0]\n",
    "\n",
    "for run in zip(past, Tb_Tf_g, Tb_Tf_g, TF_g, TF_g, pres, anc, anc, nuB_n, nuB_n, nuF_n, nuF_n):\n",
    "    plt.semilogy(run[:6], run[6:])\n",
    "plt.xlabel('generations in the past')\n",
    "plt.ylabel('effective population size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parallelus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set up global variables on engines required for run_dadi function call\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log_fmin # uses Nelder-Mead algorithm\n",
    "sfs = fs_par # use PAR spectrum\n",
    "perturb = True\n",
    "fold = 3 # perturb randomly up to 6-fold\n",
    "maxiter = 100 # run a maximum of 100 iterations\n",
    "verbose = 0\n",
    "full_output = True # need to have full output to get the warnflags (see below)\n",
    "outname = \"OUT_three_epoch/PAR_perturb\" # set file name stub for opt. result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dadi(p_init): # for the function to be called with map, it needs to have one input variable\n",
    "    \"\"\"\n",
    "    p_init: initial parameter values to run optimisation from\n",
    "    \"\"\"\n",
    "    if perturb == True:\n",
    "        p_init = dadi.Misc.perturb_params(p_init, fold=fold, \n",
    "                                      upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "        # note upper_bound and lower_bound variables are expected to be in the namespace of each engine\n",
    "    # run optimisation of paramters\n",
    "    popt = dadi_opt_func(p0=p_init, data=sfs, model_func=func_ex, pts=pts_l, \\\n",
    "                                   lower_bound=lower_bound, upper_bound=upper_bound, \\\n",
    "                                   verbose=verbose, maxiter=maxiter, full_output=full_output)\n",
    "    # pickle to file\n",
    "    import dill\n",
    "    name = outname[:] # make copy of file name stub!\n",
    "    for p in p_init:\n",
    "        name += \"_%.4f\" % (p)\n",
    "    with open(name + \".dill\", \"w\") as fh:\n",
    "        dill.dump((p_init, popt), fh)\n",
    "    \n",
    "    return p_init, popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 2 times `fold`\n",
    "p0 = [1, 1, 1, 1]\n",
    "\n",
    "ar_par = lbview.map(run_dadi, repeat(p0, 20), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.79563685"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par.elapsed/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to kill the last two long running jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_par = []\n",
    "\n",
    "for filename in glob.glob(\"OUT_three_epoch/PAR_perturb*.dill\"):\n",
    "    ar_par.append(dill.load(open(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 6\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 12\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_par, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Six optimisation converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.433394</td>\n",
       "      <td>0.438042</td>\n",
       "      <td>0.462081</td>\n",
       "      <td>2.612107</td>\n",
       "      <td>1.907850</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>1.426696</td>\n",
       "      <td>2.480729</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.638494</td>\n",
       "      <td>0.283054</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.212381</td>\n",
       "      <td>0.473253</td>\n",
       "      <td>0.027032</td>\n",
       "      <td>0.663347</td>\n",
       "      <td>1.317327</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.473569</td>\n",
       "      <td>0.361162</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.781917</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.204874</td>\n",
       "      <td>0.193839</td>\n",
       "      <td>0.141559</td>\n",
       "      <td>1.090908</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>2.189611</td>\n",
       "      <td>1.059457</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.186779</td>\n",
       "      <td>0.569927</td>\n",
       "      <td>2.567862</td>\n",
       "      <td>2.802733</td>\n",
       "      <td>0.641334</td>\n",
       "      <td>0.104038</td>\n",
       "      <td>0.190060</td>\n",
       "      <td>3.830696</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.548660</td>\n",
       "      <td>0.202542</td>\n",
       "      <td>0.135508</td>\n",
       "      <td>3.459914</td>\n",
       "      <td>2.507626</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>3.829503</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nuB_0     nuF_0      TB_0      TF_0   nuB_opt   nuF_opt    TB_opt  \\\n",
       "2  2.433394  0.438042  0.462081  2.612107  1.907850  0.038445  1.426696   \n",
       "0  0.638494  0.283054  3.960000  1.212381  0.473253  0.027032  0.663347   \n",
       "1  2.473569  0.361162  3.960000  0.920803  0.036822  0.001763  0.021552   \n",
       "5  0.204874  0.193839  0.141559  1.090908  0.039256  0.007885  2.189611   \n",
       "4  2.186779  0.569927  2.567862  2.802733  0.641334  0.104038  0.190060   \n",
       "3  2.548660  0.202542  0.135508  3.459914  2.507626  0.091869  0.155196   \n",
       "\n",
       "     TF_opt         logL  \n",
       "2  2.480729  6925.673757  \n",
       "0  1.317327  6925.673757  \n",
       "1  0.781917  6925.673757  \n",
       "5  1.059457  6925.673757  \n",
       "4  3.830696  6925.673757  \n",
       "3  3.829503  6925.673757  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4 # index of flag with NM algorithm\n",
    "\n",
    "successfull_popt = [flatten(out)[:9] for out in ar_par if out[1][i] == 0]\n",
    "\n",
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', 'logL'])\n",
    "\n",
    "df.sort_values(by='logL', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to get a few more replicates for these results. I am going to use these optimal parameter combinations, perturb them randomly and use them as starting values for new optimisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.473253</td>\n",
       "      <td>0.027032</td>\n",
       "      <td>0.663347</td>\n",
       "      <td>1.317327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.781917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.907850</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>1.426696</td>\n",
       "      <td>2.480729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.507626</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>3.829503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.641334</td>\n",
       "      <td>0.104038</td>\n",
       "      <td>0.190060</td>\n",
       "      <td>3.830696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039256</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>2.189611</td>\n",
       "      <td>1.059457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nuB_opt   nuF_opt    TB_opt    TF_opt\n",
       "0  0.473253  0.027032  0.663347  1.317327\n",
       "1  0.036822  0.001763  0.021552  0.781917\n",
       "2  1.907850  0.038445  1.426696  2.480729\n",
       "3  2.507626  0.091869  0.155196  3.829503\n",
       "4  0.641334  0.104038  0.190060  3.830696\n",
       "5  0.039256  0.007885  2.189611  1.059457"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.47325277,  0.0270319 ,  0.66334729,  1.31732675]),\n",
       " array([ 0.03682158,  0.00176323,  0.02155165,  0.78191672]),\n",
       " array([ 1.90784959,  0.03844487,  1.42669581,  2.48072912]),\n",
       " array([ 2.50762601,  0.09186928,  0.15519576,  3.82950266]),\n",
       " array([ 0.64133354,  0.10403757,  0.19006035,  3.83069627]),\n",
       " array([ 0.03925564,  0.00788456,  2.18961142,  1.05945703]),\n",
       " array([ 0.47325277,  0.0270319 ,  0.66334729,  1.31732675]),\n",
       " array([ 0.03682158,  0.00176323,  0.02155165,  0.78191672]),\n",
       " array([ 1.90784959,  0.03844487,  1.42669581,  2.48072912]),\n",
       " array([ 2.50762601,  0.09186928,  0.15519576,  3.82950266]),\n",
       " array([ 0.64133354,  0.10403757,  0.19006035,  3.83069627]),\n",
       " array([ 0.03925564,  0.00788456,  2.18961142,  1.05945703]),\n",
       " array([ 0.47325277,  0.0270319 ,  0.66334729,  1.31732675]),\n",
       " array([ 0.03682158,  0.00176323,  0.02155165,  0.78191672]),\n",
       " array([ 1.90784959,  0.03844487,  1.42669581,  2.48072912]),\n",
       " array([ 2.50762601,  0.09186928,  0.15519576,  3.82950266]),\n",
       " array([ 0.64133354,  0.10403757,  0.19006035,  3.83069627]),\n",
       " array([ 0.03925564,  0.00788456,  2.18961142,  1.05945703])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify new set initial parameter values (the optimal sets repeated 3 times)\n",
    "\n",
    "p0 = []\n",
    "\n",
    "for _ in range(3):\n",
    "    p0.extend(np.array(df.loc[:, ['nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt']]))\n",
    "\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "fold = 2 # perturb up to 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run optimisations\n",
    "\n",
    "ar_par_2 = lbview.map(run_dadi, p0, block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par_2.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 18\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 0\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_par_2, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! All 18 runs were successful?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034798</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.034582</td>\n",
       "      <td>0.378960</td>\n",
       "      <td>0.032141</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.032899</td>\n",
       "      <td>0.358150</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.034798</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.034582</td>\n",
       "      <td>0.378960</td>\n",
       "      <td>0.032141</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.032899</td>\n",
       "      <td>0.358150</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.021137</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.201532</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.021137</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.201532</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.473569</td>\n",
       "      <td>0.361162</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.781917</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.046882</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3.341567</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>3.913243</td>\n",
       "      <td>3.408379</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.046882</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3.341567</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>3.913243</td>\n",
       "      <td>3.408379</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.029536</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.560299</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.558054</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.029536</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.029136</td>\n",
       "      <td>0.560299</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.558054</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>1.005371</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.784020</td>\n",
       "      <td>1.005448</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>1.005371</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.784020</td>\n",
       "      <td>1.005448</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.204874</td>\n",
       "      <td>0.193839</td>\n",
       "      <td>0.141559</td>\n",
       "      <td>1.090908</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>2.189611</td>\n",
       "      <td>1.059457</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.317086</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>2.038538</td>\n",
       "      <td>1.510296</td>\n",
       "      <td>0.315879</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>2.043365</td>\n",
       "      <td>1.535930</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.317086</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>2.038538</td>\n",
       "      <td>1.510296</td>\n",
       "      <td>0.315879</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>2.043365</td>\n",
       "      <td>1.535930</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.024233</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>1.835750</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>1.856716</td>\n",
       "      <td>3.578219</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.024233</td>\n",
       "      <td>0.009914</td>\n",
       "      <td>1.835750</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>1.856716</td>\n",
       "      <td>3.578219</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.307762</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>1.046228</td>\n",
       "      <td>0.472231</td>\n",
       "      <td>0.302127</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>1.046629</td>\n",
       "      <td>0.492002</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.307762</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>1.046228</td>\n",
       "      <td>0.472231</td>\n",
       "      <td>0.302127</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>1.046629</td>\n",
       "      <td>0.492002</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.334913</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.809057</td>\n",
       "      <td>2.734837</td>\n",
       "      <td>1.347579</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.803359</td>\n",
       "      <td>2.492352</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.334913</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.809057</td>\n",
       "      <td>2.734837</td>\n",
       "      <td>1.347579</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.803359</td>\n",
       "      <td>2.492352</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.638494</td>\n",
       "      <td>0.283054</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.212381</td>\n",
       "      <td>0.473253</td>\n",
       "      <td>0.027032</td>\n",
       "      <td>0.663347</td>\n",
       "      <td>1.317327</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.769572</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.247868</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.764877</td>\n",
       "      <td>0.027528</td>\n",
       "      <td>0.252798</td>\n",
       "      <td>3.601468</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.769572</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.247868</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.764877</td>\n",
       "      <td>0.027528</td>\n",
       "      <td>0.252798</td>\n",
       "      <td>3.601468</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.433394</td>\n",
       "      <td>0.438042</td>\n",
       "      <td>0.462081</td>\n",
       "      <td>2.612107</td>\n",
       "      <td>1.907850</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>1.426696</td>\n",
       "      <td>2.480729</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.193470</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>0.224928</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.200351</td>\n",
       "      <td>0.040437</td>\n",
       "      <td>0.227508</td>\n",
       "      <td>3.677640</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.193470</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>0.224928</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>0.200351</td>\n",
       "      <td>0.040437</td>\n",
       "      <td>0.227508</td>\n",
       "      <td>3.677640</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.166914</td>\n",
       "      <td>0.048545</td>\n",
       "      <td>1.474589</td>\n",
       "      <td>1.333131</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>1.446743</td>\n",
       "      <td>1.347389</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.166914</td>\n",
       "      <td>0.048545</td>\n",
       "      <td>1.474589</td>\n",
       "      <td>1.333131</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>1.446743</td>\n",
       "      <td>1.347389</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.423076</td>\n",
       "      <td>0.059729</td>\n",
       "      <td>0.419554</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.435674</td>\n",
       "      <td>0.059927</td>\n",
       "      <td>0.417425</td>\n",
       "      <td>3.938768</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.423076</td>\n",
       "      <td>0.059729</td>\n",
       "      <td>0.419554</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.435674</td>\n",
       "      <td>0.059927</td>\n",
       "      <td>0.417425</td>\n",
       "      <td>3.938768</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.853563</td>\n",
       "      <td>0.115368</td>\n",
       "      <td>3.325237</td>\n",
       "      <td>2.930335</td>\n",
       "      <td>1.770115</td>\n",
       "      <td>0.084648</td>\n",
       "      <td>2.855704</td>\n",
       "      <td>3.272462</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.853563</td>\n",
       "      <td>0.115368</td>\n",
       "      <td>3.325237</td>\n",
       "      <td>2.930335</td>\n",
       "      <td>1.770115</td>\n",
       "      <td>0.084648</td>\n",
       "      <td>2.855704</td>\n",
       "      <td>3.272462</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.548660</td>\n",
       "      <td>0.202542</td>\n",
       "      <td>0.135508</td>\n",
       "      <td>3.459914</td>\n",
       "      <td>2.507626</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>3.829503</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.329169</td>\n",
       "      <td>0.204441</td>\n",
       "      <td>0.152604</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.245161</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.201465</td>\n",
       "      <td>3.859701</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.329169</td>\n",
       "      <td>0.204441</td>\n",
       "      <td>0.152604</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.245161</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.201465</td>\n",
       "      <td>3.859701</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.186779</td>\n",
       "      <td>0.569927</td>\n",
       "      <td>2.567862</td>\n",
       "      <td>2.802733</td>\n",
       "      <td>0.641334</td>\n",
       "      <td>0.104038</td>\n",
       "      <td>0.190060</td>\n",
       "      <td>3.830696</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.056074</td>\n",
       "      <td>0.139525</td>\n",
       "      <td>0.083480</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3.082088</td>\n",
       "      <td>0.113243</td>\n",
       "      <td>0.073635</td>\n",
       "      <td>3.827661</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.056074</td>\n",
       "      <td>0.139525</td>\n",
       "      <td>0.083480</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3.082088</td>\n",
       "      <td>0.113243</td>\n",
       "      <td>0.073635</td>\n",
       "      <td>3.827661</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.316761</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>2.202856</td>\n",
       "      <td>1.209182</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>0.179460</td>\n",
       "      <td>3.781351</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.316761</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>2.202856</td>\n",
       "      <td>1.209182</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>0.179460</td>\n",
       "      <td>3.781351</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.649948</td>\n",
       "      <td>0.116610</td>\n",
       "      <td>3.532943</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.671203</td>\n",
       "      <td>0.119777</td>\n",
       "      <td>3.654009</td>\n",
       "      <td>3.865415</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.649948</td>\n",
       "      <td>0.116610</td>\n",
       "      <td>3.532943</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>1.671203</td>\n",
       "      <td>0.119777</td>\n",
       "      <td>3.654009</td>\n",
       "      <td>3.865415</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nuB_0     nuF_0      TB_0      TF_0   nuB_opt   nuF_opt    TB_opt  \\\n",
       "25  0.034798  0.000622  0.034582  0.378960  0.032141  0.001058  0.032899   \n",
       "7   0.034798  0.000622  0.034582  0.378960  0.032141  0.001058  0.032899   \n",
       "31  0.021137  0.001603  0.035116  0.201532  0.021004  0.001120  0.036850   \n",
       "13  0.021137  0.001603  0.035116  0.201532  0.021004  0.001120  0.036850   \n",
       "1   2.473569  0.361162  3.960000  0.920803  0.036822  0.001763  0.021552   \n",
       "11  0.046882  0.005830  3.960000  3.341567  0.047762  0.004537  3.913243   \n",
       "29  0.046882  0.005830  3.960000  3.341567  0.047762  0.004537  3.913243   \n",
       "19  0.029536  0.006689  0.029136  0.560299  0.026678  0.006358  0.028909   \n",
       "37  0.029536  0.006689  0.029136  0.560299  0.026678  0.006358  0.028909   \n",
       "23  0.010834  0.006921  0.784781  1.005371  0.010929  0.006721  0.784020   \n",
       "41  0.010834  0.006921  0.784781  1.005371  0.010929  0.006721  0.784020   \n",
       "5   0.204874  0.193839  0.141559  1.090908  0.039256  0.007885  2.189611   \n",
       "24  0.317086  0.007937  2.038538  1.510296  0.315879  0.007967  2.043365   \n",
       "6   0.317086  0.007937  2.038538  1.510296  0.315879  0.007967  2.043365   \n",
       "35  0.024233  0.009914  1.835750  3.960000  0.019881  0.008062  1.856716   \n",
       "17  0.024233  0.009914  1.835750  3.960000  0.019881  0.008062  1.856716   \n",
       "18  0.307762  0.021357  1.046228  0.472231  0.302127  0.014132  1.046629   \n",
       "36  0.307762  0.021357  1.046228  0.472231  0.302127  0.014132  1.046629   \n",
       "8   1.334913  0.025802  0.809057  2.734837  1.347579  0.022027  0.803359   \n",
       "26  1.334913  0.025802  0.809057  2.734837  1.347579  0.022027  0.803359   \n",
       "0   0.638494  0.283054  3.960000  1.212381  0.473253  0.027032  0.663347   \n",
       "16  0.769572  0.033210  0.247868  3.960000  0.764877  0.027528  0.252798   \n",
       "34  0.769572  0.033210  0.247868  3.960000  0.764877  0.027528  0.252798   \n",
       "2   2.433394  0.438042  0.462081  2.612107  1.907850  0.038445  1.426696   \n",
       "22  0.193470  0.050057  0.224928  3.960000  0.200351  0.040437  0.227508   \n",
       "40  0.193470  0.050057  0.224928  3.960000  0.200351  0.040437  0.227508   \n",
       "12  0.166914  0.048545  1.474589  1.333131  0.157016  0.041328  1.446743   \n",
       "30  0.166914  0.048545  1.474589  1.333131  0.157016  0.041328  1.446743   \n",
       "21  2.423076  0.059729  0.419554  3.960000  2.435674  0.059927  0.417425   \n",
       "39  2.423076  0.059729  0.419554  3.960000  2.435674  0.059927  0.417425   \n",
       "38  1.853563  0.115368  3.325237  2.930335  1.770115  0.084648  2.855704   \n",
       "20  1.853563  0.115368  3.325237  2.930335  1.770115  0.084648  2.855704   \n",
       "3   2.548660  0.202542  0.135508  3.459914  2.507626  0.091869  0.155196   \n",
       "27  1.329169  0.204441  0.152604  3.960000  1.245161  0.096600  0.201465   \n",
       "9   1.329169  0.204441  0.152604  3.960000  1.245161  0.096600  0.201465   \n",
       "4   2.186779  0.569927  2.567862  2.802733  0.641334  0.104038  0.190060   \n",
       "33  3.056074  0.139525  0.083480  3.960000  3.082088  0.113243  0.073635   \n",
       "15  3.056074  0.139525  0.083480  3.960000  3.082088  0.113243  0.073635   \n",
       "28  1.316761  0.306616  0.135113  2.202856  1.209182  0.114317  0.179460   \n",
       "10  1.316761  0.306616  0.135113  2.202856  1.209182  0.114317  0.179460   \n",
       "32  1.649948  0.116610  3.532943  3.960000  1.671203  0.119777  3.654009   \n",
       "14  1.649948  0.116610  3.532943  3.960000  1.671203  0.119777  3.654009   \n",
       "\n",
       "      TF_opt         logL  \n",
       "25  0.358150  6925.673757  \n",
       "7   0.358150  6925.673757  \n",
       "31  0.197136  6925.673757  \n",
       "13  0.197136  6925.673757  \n",
       "1   0.781917  6925.673757  \n",
       "11  3.408379  6925.673757  \n",
       "29  3.408379  6925.673757  \n",
       "19  0.558054  6925.673757  \n",
       "37  0.558054  6925.673757  \n",
       "23  1.005448  6925.673757  \n",
       "41  1.005448  6925.673757  \n",
       "5   1.059457  6925.673757  \n",
       "24  1.535930  6925.673757  \n",
       "6   1.535930  6925.673757  \n",
       "35  3.578219  6925.673757  \n",
       "17  3.578219  6925.673757  \n",
       "18  0.492002  6925.673757  \n",
       "36  0.492002  6925.673757  \n",
       "8   2.492352  6925.673757  \n",
       "26  2.492352  6925.673757  \n",
       "0   1.317327  6925.673757  \n",
       "16  3.601468  6925.673757  \n",
       "34  3.601468  6925.673757  \n",
       "2   2.480729  6925.673757  \n",
       "22  3.677640  6925.673757  \n",
       "40  3.677640  6925.673757  \n",
       "12  1.347389  6925.673757  \n",
       "30  1.347389  6925.673757  \n",
       "21  3.938768  6925.673757  \n",
       "39  3.938768  6925.673757  \n",
       "38  3.272462  6925.673757  \n",
       "20  3.272462  6925.673757  \n",
       "3   3.829503  6925.673757  \n",
       "27  3.859701  6925.673757  \n",
       "9   3.859701  6925.673757  \n",
       "4   3.830696  6925.673757  \n",
       "33  3.827661  6925.673757  \n",
       "15  3.827661  6925.673757  \n",
       "28  3.781351  6925.673757  \n",
       "10  3.781351  6925.673757  \n",
       "32  3.865415  6925.673757  \n",
       "14  3.865415  6925.673757  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new output to previous output\n",
    "successfull_popt.extend( [flatten(out)[:9] for out in ar_par_2 if out[1][4] == 0] )\n",
    "\n",
    "# create data frame\n",
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', 'logL'])\n",
    "\n",
    "# sort data frame by negative log likelihood\n",
    "df.sort_values(by='nuF_opt', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to visualise these population size histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add time for ancient size change\n",
    "\n",
    "df['TB+TF'] = pd.Series(df['TB_opt']+df['TF_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract columns from table\n",
    "nuB = df.loc[:,'nuB_opt']\n",
    "nuF = df.loc[:, 'nuF_opt']\n",
    "Tb_Tf = df.loc[:, 'TB+TF']\n",
    "TF = df.loc[:, 'TF_opt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sequence length for the ery spectrum is 1,214,938.\n"
     ]
    }
   ],
   "source": [
    "# calculate reference (ancient) population size from theta estimate (derived elsewhere by fitting a neutral spectrum)\n",
    "\n",
    "theta_par = 10632.738922047551\n",
    "mu = 3e-9\n",
    "L = fs_par.data.sum() # this sums over all entries in the spectrum, including masked ones, i. e. also contains invariable sites\n",
    "print \"The total sequence length for the ery spectrum is {0:,}.\".format(int(L))\n",
    "N_ref_par = theta_par/L/mu/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn nu into absolute Ne and T into generations\n",
    "\n",
    "nuB_n = nuB*N_ref_par\n",
    "nuF_n = nuF*N_ref_par\n",
    "Tb_Tf_g = Tb_Tf*2*N_ref_par\n",
    "TF_g = TF*2*N_ref_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anc = [N_ref_par] * len(nuB)\n",
    "pres = [1] * len(nuB)\n",
    "past = [max(Tb_Tf_g)+1000] * len(nuB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fac72f3c290>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAJgCAYAAAC0v8QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB5Qm+42+qwIeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac77b80850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12.0, 10.0]\n",
    "\n",
    "for run in zip(past, Tb_Tf_g, Tb_Tf_g, TF_g, TF_g, pres, anc, anc, nuB_n, nuB_n, nuF_n, nuF_n):\n",
    "    plt.semilogy(run[:6], run[6:])\n",
    "plt.xlabel('generations in the past')\n",
    "plt.ylabel('effective population size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ancient size change is generally inferred to be more than 1 million generations ago (even up to 10 million)?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the strength of the first population size change, $(\\frac{1}{\\nu_B})^{TB}$, and the strength of the second population size change, $(\\frac{1}{\\nu_F})^{TF}$, correlated with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fac6e91f650>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAJsCAYAAABETO1dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac6f0b8a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 12.0\n",
    "\n",
    "plt.plot((1.0/df['nuB_opt'])**df['TB_opt'], (1.0/df['nuF_opt'])**df['TF_opt'], 'bo')\n",
    "plt.xlabel('strength of first size change')\n",
    "plt.ylabel('strength of second size change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no correlation between the strength of the two size changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "dump_this = ar_par\n",
    "dump_this.extend(list(ar_par_2.get()))\n",
    "\n",
    "dill.dump(dump_this, open(\"OUT_three_epoch/PAR_perturb_ar_par.dill\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0 = [100, 1e-2, 1, 2] # start from more extreme initial parameter values\n",
    "\n",
    "ar_par_3 = lbview.map(run_dadi, repeat(p0, 10), block = False, order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par_3.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 10\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 0\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_par_3, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.dump(list(ar_par_3.get()), open(\"OUT_three_epoch/PAR_perturb_extreme_ar_par.dill\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>TB_0</th>\n",
       "      <th>TF_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>TB_opt</th>\n",
       "      <th>TF_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268.347228</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>3.495306</td>\n",
       "      <td>2.235183</td>\n",
       "      <td>225.289543</td>\n",
       "      <td>0.032213</td>\n",
       "      <td>3.451690</td>\n",
       "      <td>2.183728</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.559230</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>1.235253</td>\n",
       "      <td>3.883301</td>\n",
       "      <td>41.390244</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>1.240099</td>\n",
       "      <td>3.769861</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.498147</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>1.088031</td>\n",
       "      <td>3.551166</td>\n",
       "      <td>63.945996</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>1.088717</td>\n",
       "      <td>3.584231</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.901243</td>\n",
       "      <td>0.028192</td>\n",
       "      <td>1.874433</td>\n",
       "      <td>1.116714</td>\n",
       "      <td>56.580841</td>\n",
       "      <td>0.030822</td>\n",
       "      <td>1.919122</td>\n",
       "      <td>1.112101</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.733009</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>3.201122</td>\n",
       "      <td>1.346019</td>\n",
       "      <td>30.203574</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>3.091384</td>\n",
       "      <td>1.362643</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>155.267088</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>1.982512</td>\n",
       "      <td>0.713019</td>\n",
       "      <td>155.438528</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>1.990211</td>\n",
       "      <td>0.713649</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53.472143</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>3.721429</td>\n",
       "      <td>3.367482</td>\n",
       "      <td>59.768349</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>3.747301</td>\n",
       "      <td>3.356914</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>261.612644</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.776384</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>290.395553</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.779946</td>\n",
       "      <td>3.904082</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.386654</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>1.411848</td>\n",
       "      <td>1.871907</td>\n",
       "      <td>44.738775</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>1.414354</td>\n",
       "      <td>1.917174</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>316.920444</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.612435</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>315.270535</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.615180</td>\n",
       "      <td>3.948950</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nuB_0     nuF_0      TB_0      TF_0     nuB_opt   nuF_opt    TB_opt  \\\n",
       "4  268.347228  0.036617  3.495306  2.235183  225.289543  0.032213  3.451690   \n",
       "3   38.559230  0.005461  1.235253  3.883301   41.390244  0.005079  1.240099   \n",
       "2   67.498147  0.015576  1.088031  3.551166   63.945996  0.014691  1.088717   \n",
       "5   48.901243  0.028192  1.874433  1.116714   56.580841  0.030822  1.919122   \n",
       "1   27.733009  0.003506  3.201122  1.346019   30.203574  0.003972  3.091384   \n",
       "9  155.267088  0.002844  1.982512  0.713019  155.438528  0.002252  1.990211   \n",
       "6   53.472143  0.007924  3.721429  3.367482   59.768349  0.007426  3.747301   \n",
       "8  261.612644  0.005875  0.776384  3.960000  290.395553  0.004657  0.779946   \n",
       "0   41.386654  0.004065  1.411848  1.871907   44.738775  0.005076  1.414354   \n",
       "7  316.920444  0.007079  0.612435  3.960000  315.270535  0.005561  0.615180   \n",
       "\n",
       "     TF_opt         logL  \n",
       "4  2.183728  6925.673757  \n",
       "3  3.769861  6925.673757  \n",
       "2  3.584231  6925.673757  \n",
       "5  1.112101  6925.673757  \n",
       "1  1.362643  6925.673757  \n",
       "9  0.713649  6925.673757  \n",
       "6  3.356914  6925.673757  \n",
       "8  3.904082  6925.673757  \n",
       "0  1.917174  6925.673757  \n",
       "7  3.948950  6925.673757  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new output to previous output\n",
    "successfull_popt_3 =  [flatten(out)[:9] for out in ar_par_3 if out[1][4] == 0]\n",
    "\n",
    "# create data frame\n",
    "df_3 = pd.DataFrame(data=successfull_popt_3, \\\n",
    "                  columns=['nuB_0', 'nuF_0', 'TB_0', 'TF_0', 'nuB_opt', 'nuF_opt', 'TB_opt', 'TF_opt', 'logL'])\n",
    "\n",
    "# sort data frame by negative log likelihood\n",
    "df_3.sort_values(by='logL', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fac6e7c94d0>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAJqCAYAAAA/lBbpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAA0/h/bELqmAAAABElEQVQd6keghctHGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac6f0b8d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_3['nuB_opt']**df_3['TB_opt'], (1.0/df_3['nuF_opt'])**df_3['TF_opt'], 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot see a correlation here either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All optimisations consistently show a reduction in the contemporary population size with respect to the ancient population size ($\\nu_F$). The ancient population size change is much less clear and ranges from a reduction by one half to a doubling. Also this event is inferred to have occurred quite distant in the past, at $(T_F + T_B) \\times 2N_{ref}$ generations in the past. This makes me think that this ancient size change cannot reliably be inferred. There only seems to be evidence for one size change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My attempts to fit a two epoch model (i. e. a single size change) to the _parallelus_ 1D SFS had previously failed due to inferred parameter values hitting ever more extreme parameter limits. Given that I was able to reasonably fit a 4 parameter model to the 1D SFS of _parallelus_ (that does not show strong evidence for two size changes), I would be surprised if it wasn't possible to fit the two epoch model to the _parallelus_ spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retry two_epoch model with PAR spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "cl = Client()\n",
    "\n",
    "cl.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# run whole cell on all engines a well as in the local IPython session\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/claudius/Downloads/dadi')\n",
    "\n",
    "import dadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# create link to function that specifies the model\n",
    "func = dadi.Demographics1D.two_epoch\n",
    "\n",
    "# create extrapolating version of the model function\n",
    "func_ex = dadi.Numerics.make_extrap_log_func(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_ery = dadi.Spectrum.from_file('ERY.unfolded.sfs').fold()\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_par = dadi.Spectrum.from_file('PAR.unfolded.sfs').fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set up global variables on engines required for run_dadi function call\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log_fmin # uses Nelder-Mead algorithm\n",
    "sfs = fs_par # use PAR spectrum\n",
    "perturb = True\n",
    "fold = 2 # perturb randomly up to 6-fold\n",
    "maxiter = 100 # run a maximum of 100 iterations\n",
    "verbose = 0\n",
    "full_output = True # need to have full output to get the warnflags (see below)\n",
    "outname = \"OUT_two_epoch/PAR_perturb\" # set file name stub for opt. result files\n",
    "\n",
    "# set lower and upper bounds to nu and T\n",
    "upper_bound = [1e4, 5]\n",
    "lower_bound = [1e-4, 0]\n",
    "\n",
    "ns = fs_ery.sample_sizes # both populations have the same sample size\n",
    "\n",
    "fs_ery.pop_ids = ['ery']\n",
    "fs_par.pop_ids = ['par']\n",
    "\n",
    "# setting the smallest grid size slightly larger than the largest population sample size (36)\n",
    "pts_l = [50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbview = cl.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dadi(p_init): # for the function to be called with map, it needs to have one input variable\n",
    "    \"\"\"\n",
    "    p_init: initial parameter values to run optimisation from\n",
    "    \"\"\"\n",
    "    if perturb == True:\n",
    "        p_init = dadi.Misc.perturb_params(p_init, fold=fold, \n",
    "                                      upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "        # note upper_bound and lower_bound variables are expected to be in the namespace of each engine\n",
    "    # run optimisation of paramters\n",
    "    popt = dadi_opt_func(p0=p_init, data=sfs, model_func=func_ex, pts=pts_l, \\\n",
    "                                   lower_bound=lower_bound, upper_bound=upper_bound, \\\n",
    "                                   verbose=verbose, maxiter=maxiter, full_output=full_output)\n",
    "    # pickle to file\n",
    "    import dill\n",
    "    name = outname[:] # make copy of file name stub!\n",
    "    for p in p_init:\n",
    "        name += \"_%.4f\" % (p)\n",
    "    with open(name + \".dill\", \"w\") as fh:\n",
    "        dill.dump((p_init, popt), fh)\n",
    "    \n",
    "    return p_init, popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 4\n",
    "p0 = [0.1, 2.5]\n",
    "\n",
    "ar_par_te = lbview.map(run_dadi, repeat(p0, 20), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par_te.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_flag_count(out, NM=True):\n",
    "    \"\"\"\n",
    "    out: list of tuples, each containing p_init and popt + additional info, including warnflags\n",
    "    as produced by run_dadi.py\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    if NM: # if ar from Nelder-Mead\n",
    "        i = 4 # the warnflag is reported at index position 4 in the output array\n",
    "    else: # ar from BFGS optimisation\n",
    "        i = 6\n",
    "    \n",
    "    warnflag = defaultdict(int)\n",
    "\n",
    "    for res in out:\n",
    "        if res[1][i] == 1: # notice the change in indexing\n",
    "            warnflag[1] +=1\n",
    "        elif res[1][i] == 2:\n",
    "            warnflag[2] += 1\n",
    "        elif res[1][i] == 0:\n",
    "            warnflag[0] += 1\n",
    "        else:\n",
    "            warnflag[999] +=1\n",
    "    if NM:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of function evaluations made.\", warnflag[1]\n",
    "        print \"Maximum number of iterations reached.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]\n",
    "    else:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of iterations exceeded.\", warnflag[1]\n",
    "        print \"Gradient and/or function calls not changing.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_par_te = []\n",
    "\n",
    "import glob, dill\n",
    "\n",
    "for filename in glob.glob(\"OUT_two_epoch/PAR_perturb*dill\"):\n",
    "    ar_par_te.append( dill.load(open(filename)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 21\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 0\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_par_te, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    \"\"\"\n",
    "        Returns a list of flattened elements of every inner lists (or tuples)\n",
    "        ****RECURSIVE****\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    res = []\n",
    "    for el in array:\n",
    "        if isinstance(el, (list, tuple, numpy.ndarray)):\n",
    "            res.extend(flatten(el))\n",
    "            continue\n",
    "        res.append(el)\n",
    "    return list( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nu_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nu_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.043733</td>\n",
       "      <td>0.843860</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.884924</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.031110</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>4.615473</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027317</td>\n",
       "      <td>3.411201</td>\n",
       "      <td>0.015919</td>\n",
       "      <td>3.747210</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.339826</td>\n",
       "      <td>3.022905</td>\n",
       "      <td>0.111238</td>\n",
       "      <td>4.938315</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.225660</td>\n",
       "      <td>2.139018</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>2.814009</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.046077</td>\n",
       "      <td>2.321844</td>\n",
       "      <td>0.039505</td>\n",
       "      <td>2.421725</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.043962</td>\n",
       "      <td>2.319764</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>2.464394</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035152</td>\n",
       "      <td>1.289873</td>\n",
       "      <td>0.032329</td>\n",
       "      <td>1.289937</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.227686</td>\n",
       "      <td>1.491931</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>1.933539</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.042434</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>4.175495</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.129524</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.113594</td>\n",
       "      <td>4.525529</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.704100</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.830649</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049946</td>\n",
       "      <td>3.078650</td>\n",
       "      <td>0.043235</td>\n",
       "      <td>2.919133</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.041984</td>\n",
       "      <td>1.046781</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>1.047991</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.209367</td>\n",
       "      <td>1.415120</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>1.536937</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.166116</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.138820</td>\n",
       "      <td>4.797762</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.056907</td>\n",
       "      <td>1.690728</td>\n",
       "      <td>0.037020</td>\n",
       "      <td>1.637142</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.211545</td>\n",
       "      <td>1.509448</td>\n",
       "      <td>0.011912</td>\n",
       "      <td>1.745096</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235730</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.120247</td>\n",
       "      <td>4.572422</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052986</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.046463</td>\n",
       "      <td>4.722051</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043338</td>\n",
       "      <td>2.200729</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>2.216722</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nu_0       T_0    nu_opt     T_opt         logL\n",
       "10  0.043733  0.843860  0.015968  0.884924  6925.673757\n",
       "7   0.031110  4.950000  0.021988  4.615473  6925.673757\n",
       "3   0.027317  3.411201  0.015919  3.747210  6925.673757\n",
       "12  0.339826  3.022905  0.111238  4.938315  6925.673757\n",
       "9   0.225660  2.139018  0.017545  2.814009  6925.673757\n",
       "17  0.046077  2.321844  0.039505  2.421725  6925.673757\n",
       "16  0.043962  2.319764  0.060086  2.464394  6925.673757\n",
       "4   0.035152  1.289873  0.032329  1.289937  6925.673757\n",
       "13  0.227686  1.491931  0.007004  1.933539  6925.673757\n",
       "18  0.042434  4.950000  0.033626  4.175495  6925.673757\n",
       "11  0.129524  4.950000  0.113594  4.525529  6925.673757\n",
       "0   0.034942  0.704100  0.007971  0.830649  6925.673757\n",
       "1   0.049946  3.078650  0.043235  2.919133  6925.673757\n",
       "19  0.041984  1.046781  0.014843  1.047991  6925.673757\n",
       "6   0.209367  1.415120  0.039470  1.536937  6925.673757\n",
       "14  0.166116  4.950000  0.138820  4.797762  6925.673757\n",
       "20  0.056907  1.690728  0.037020  1.637142  6925.673757\n",
       "5   0.211545  1.509448  0.011912  1.745096  6925.673757\n",
       "8   0.235730  4.950000  0.120247  4.572422  6925.673757\n",
       "15  0.052986  4.950000  0.046463  4.722051  6925.673757\n",
       "2   0.043338  2.200729  0.040116  2.216722  6925.673757"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4 # index of flag with NM algorithm\n",
    "\n",
    "successfull_popt = [flatten(out)[:5] for out in ar_par_te if out[1][i] == 0]\n",
    "\n",
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nu_0','T_0', 'nu_opt', 'T_opt', 'logL'])\n",
    "\n",
    "df.sort_values(by='logL', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these two epoch models have the same likelihood as the three epoch models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 4\n",
    "p0 = [10, 0.5]\n",
    "\n",
    "ar_par_te = lbview.map(run_dadi, repeat(p0, 20), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par_te.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 20\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 0\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_par_te, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nu_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nu_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.987489</td>\n",
       "      <td>1.642464</td>\n",
       "      <td>6.645270</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5504.381047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24.561703</td>\n",
       "      <td>0.229637</td>\n",
       "      <td>6.645150</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>5504.381050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.503846</td>\n",
       "      <td>0.197141</td>\n",
       "      <td>6.644959</td>\n",
       "      <td>4.999996</td>\n",
       "      <td>5504.381051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.107369</td>\n",
       "      <td>0.694274</td>\n",
       "      <td>6.644691</td>\n",
       "      <td>4.999998</td>\n",
       "      <td>5504.381051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.198500</td>\n",
       "      <td>1.480943</td>\n",
       "      <td>6.644962</td>\n",
       "      <td>4.999994</td>\n",
       "      <td>5504.381056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.315275</td>\n",
       "      <td>0.361328</td>\n",
       "      <td>6.644621</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>5504.381058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.502252</td>\n",
       "      <td>0.168670</td>\n",
       "      <td>6.644580</td>\n",
       "      <td>4.999996</td>\n",
       "      <td>5504.381061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.123402</td>\n",
       "      <td>1.026289</td>\n",
       "      <td>6.645491</td>\n",
       "      <td>4.999999</td>\n",
       "      <td>5504.381061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.232949</td>\n",
       "      <td>0.650673</td>\n",
       "      <td>6.644530</td>\n",
       "      <td>4.999996</td>\n",
       "      <td>5504.381063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.362184</td>\n",
       "      <td>1.272441</td>\n",
       "      <td>6.644494</td>\n",
       "      <td>4.999996</td>\n",
       "      <td>5504.381067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.763644</td>\n",
       "      <td>1.765466</td>\n",
       "      <td>6.644866</td>\n",
       "      <td>4.999990</td>\n",
       "      <td>5504.381068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.562575</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>6.645172</td>\n",
       "      <td>4.999990</td>\n",
       "      <td>5504.381069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.091669</td>\n",
       "      <td>1.067884</td>\n",
       "      <td>6.645485</td>\n",
       "      <td>4.999994</td>\n",
       "      <td>5504.381073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.846975</td>\n",
       "      <td>0.467682</td>\n",
       "      <td>6.645270</td>\n",
       "      <td>4.999989</td>\n",
       "      <td>5504.381076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.777280</td>\n",
       "      <td>0.347957</td>\n",
       "      <td>6.645409</td>\n",
       "      <td>4.999990</td>\n",
       "      <td>5504.381078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.145003</td>\n",
       "      <td>0.305677</td>\n",
       "      <td>6.644878</td>\n",
       "      <td>4.999985</td>\n",
       "      <td>5504.381081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.309461</td>\n",
       "      <td>1.853374</td>\n",
       "      <td>6.645314</td>\n",
       "      <td>4.999986</td>\n",
       "      <td>5504.381084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.848887</td>\n",
       "      <td>1.544497</td>\n",
       "      <td>6.645521</td>\n",
       "      <td>4.999982</td>\n",
       "      <td>5504.381106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.577249</td>\n",
       "      <td>1.832976</td>\n",
       "      <td>6.646996</td>\n",
       "      <td>4.999997</td>\n",
       "      <td>5504.381300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.226149</td>\n",
       "      <td>0.208820</td>\n",
       "      <td>6.650487</td>\n",
       "      <td>4.999987</td>\n",
       "      <td>5504.382564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nu_0       T_0    nu_opt     T_opt         logL\n",
       "1    6.987489  1.642464  6.645270  5.000000  5504.381047\n",
       "18  24.561703  0.229637  6.645150  4.999997  5504.381050\n",
       "16   3.503846  0.197141  6.644959  4.999996  5504.381051\n",
       "4    3.107369  0.694274  6.644691  4.999998  5504.381051\n",
       "12   4.198500  1.480943  6.644962  4.999994  5504.381056\n",
       "15  14.315275  0.361328  6.644621  4.999997  5504.381058\n",
       "7    4.502252  0.168670  6.644580  4.999996  5504.381061\n",
       "6    4.123402  1.026289  6.645491  4.999999  5504.381061\n",
       "13  11.232949  0.650673  6.644530  4.999996  5504.381063\n",
       "10  12.362184  1.272441  6.644494  4.999996  5504.381067\n",
       "19   7.763644  1.765466  6.644866  4.999990  5504.381068\n",
       "17  14.562575  0.518519  6.645172  4.999990  5504.381069\n",
       "8   20.091669  1.067884  6.645485  4.999994  5504.381073\n",
       "5    3.846975  0.467682  6.645270  4.999989  5504.381076\n",
       "11  35.777280  0.347957  6.645409  4.999990  5504.381078\n",
       "2    4.145003  0.305677  6.644878  4.999985  5504.381081\n",
       "0    7.309461  1.853374  6.645314  4.999986  5504.381084\n",
       "3    2.848887  1.544497  6.645521  4.999982  5504.381106\n",
       "14  20.577249  1.832976  6.646996  4.999997  5504.381300\n",
       "9    4.226149  0.208820  6.650487  4.999987  5504.382564"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4 # index of flag with NM algorithm\n",
    "\n",
    "successfull_popt = [flatten(out)[:5] for out in ar_par_te if out[1][i] == 0]\n",
    "\n",
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nu_0','T_0', 'nu_opt', 'T_opt', '-logL'])\n",
    "\n",
    "df.sort_values(by='-logL', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of these parameter values is much higher than the the ones above. However, the time parameter is hitting the upper boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "upper_bound = [1e4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 4\n",
    "p0 = [1, 1]\n",
    "\n",
    "ar_par_te = lbview.map(run_dadi, repeat(p0, 10), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ar_par_te = []\n",
    "\n",
    "#import glob, dill\n",
    "\n",
    "#for filename in glob.glob(\"OUT_two_epoch/PAR_perturb*dill\"):\n",
    "#    ar_par_te.append( dill.load(open(filename)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 10\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 0\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_par_te, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nu_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nu_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.809859</td>\n",
       "      <td>0.880742</td>\n",
       "      <td>7.723638</td>\n",
       "      <td>5.999997</td>\n",
       "      <td>5502.338651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.960114</td>\n",
       "      <td>0.730363</td>\n",
       "      <td>7.723791</td>\n",
       "      <td>5.999995</td>\n",
       "      <td>5502.338651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.946438</td>\n",
       "      <td>3.628840</td>\n",
       "      <td>7.724187</td>\n",
       "      <td>5.999994</td>\n",
       "      <td>5502.338653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.099448</td>\n",
       "      <td>1.424327</td>\n",
       "      <td>7.723607</td>\n",
       "      <td>5.999982</td>\n",
       "      <td>5502.338675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.268052</td>\n",
       "      <td>0.301753</td>\n",
       "      <td>7.724743</td>\n",
       "      <td>5.999970</td>\n",
       "      <td>5502.338719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.478007</td>\n",
       "      <td>0.297796</td>\n",
       "      <td>7.731477</td>\n",
       "      <td>5.999997</td>\n",
       "      <td>5502.341217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.163708</td>\n",
       "      <td>3.434724</td>\n",
       "      <td>7.690900</td>\n",
       "      <td>5.999987</td>\n",
       "      <td>5502.388130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.426545</td>\n",
       "      <td>2.386989</td>\n",
       "      <td>0.146739</td>\n",
       "      <td>5.883732</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.291222</td>\n",
       "      <td>0.328804</td>\n",
       "      <td>0.124747</td>\n",
       "      <td>5.466190</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.322324</td>\n",
       "      <td>0.444581</td>\n",
       "      <td>0.046371</td>\n",
       "      <td>3.658299</td>\n",
       "      <td>6925.673757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nu_0       T_0    nu_opt     T_opt         logL\n",
       "7  3.809859  0.880742  7.723638  5.999997  5502.338651\n",
       "6  3.960114  0.730363  7.723791  5.999995  5502.338651\n",
       "3  0.946438  3.628840  7.724187  5.999994  5502.338653\n",
       "1  1.099448  1.424327  7.723607  5.999982  5502.338675\n",
       "8  1.268052  0.301753  7.724743  5.999970  5502.338719\n",
       "5  0.478007  0.297796  7.731477  5.999997  5502.341217\n",
       "2  1.163708  3.434724  7.690900  5.999987  5502.388130\n",
       "0  0.426545  2.386989  0.146739  5.883732  6925.673757\n",
       "4  0.291222  0.328804  0.124747  5.466190  6925.673757\n",
       "9  0.322324  0.444581  0.046371  3.658299  6925.673757"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 4 # index of flag with NM algorithm\n",
    "\n",
    "successfull_popt = [flatten(out)[:5] for out in ar_par_te if out[1][i] == 0]\n",
    "\n",
    "df = pd.DataFrame(data=successfull_popt, \\\n",
    "                  columns=['nu_0','T_0', 'nu_opt', 'T_opt', 'logL'])\n",
    "\n",
    "df.sort_values(by='logL', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dill.dump(list(ar_par_te.get()), open(\"OUT_two_epoch/PAR_perturb_ar_par.dill\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very hard for me to believe that the log likelihood of all parameter combinations is almost exactly the same AND also the same as the likelihood for all parameter combinations of the three epoch model above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-9825.1799565799647,\n",
       " -9825.1799565806832,\n",
       " -9825.1799565812507,\n",
       " -9825.1799565812271,\n",
       " -9825.1799565805759,\n",
       " -9825.1799565808014,\n",
       " -9825.1799565800939,\n",
       " -9825.1799565815054,\n",
       " -9825.1799565804031,\n",
       " -9825.1799565808542,\n",
       " -9825.1799565807978,\n",
       " -9825.1799565798756,\n",
       " -9825.1799565810798,\n",
       " -9825.179956580927,\n",
       " -9825.179956580072,\n",
       " -9825.1799565812707,\n",
       " -9825.1799565804686,\n",
       " -9825.1799565797955,\n",
       " -9825.1799565801703,\n",
       " -9825.1799565808396]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_ll(out[1][0]) for out in ar_par_te if out[1][4] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.05486992,  1.99860381]),\n",
       "  (array([ 0.03180292,  1.95648193]), 9825.1799565799647, 24, 62, 0)),\n",
       " (array([ 0.07135217,  3.50371679]),\n",
       "  (array([ 0.06243178,  3.50071502]), 9825.1799565806832, 19, 52, 0)),\n",
       " (array([ 0.05054308,  2.05085516]),\n",
       "  (array([ 0.04690783,  2.05099452]), 9825.1799565812507, 14, 45, 0)),\n",
       " (array([ 0.08349208,  3.96      ]),\n",
       "  (array([ 0.08365293,  3.82117106]), 9825.1799565812271, 25, 59, 0)),\n",
       " (array([ 0.08232057,  3.2093796 ]),\n",
       "  (array([ 0.09182442,  3.43965861]), 9825.1799565805759, 20, 58, 0)),\n",
       " (array([ 0.06735758,  2.9487646 ]),\n",
       "  (array([ 0.07978079,  3.09333988]), 9825.1799565808014, 21, 54, 0)),\n",
       " (array([ 0.0727572,  3.96     ]),\n",
       "  (array([ 0.07595359,  3.85083138]), 9825.1799565800939, 18, 53, 0)),\n",
       " (array([ 0.14681914,  3.76597664]),\n",
       "  (array([ 0.10123876,  3.87681382]), 9825.1799565815054, 23, 65, 0)),\n",
       " (array([ 0.07298845,  3.60220333]),\n",
       "  (array([ 0.04928812,  3.3752426 ]), 9825.1799565804031, 18, 55, 0)),\n",
       " (array([ 0.06802161,  3.29320753]),\n",
       "  (array([ 0.05946744,  3.29320753]), 9825.1799565808542, 19, 56, 0)),\n",
       " (array([ 0.10640165,  3.92341386]),\n",
       "  (array([ 0.10904132,  3.51473602]), 9825.1799565807978, 22, 64, 0)),\n",
       " (array([ 0.07170782,  2.83808626]),\n",
       "  (array([ 0.07665994,  3.02473366]), 9825.1799565798756, 23, 64, 0)),\n",
       " (array([ 0.16242966,  3.96      ]),\n",
       "  (array([ 0.09350813,  3.87135071]), 9825.1799565810798, 25, 66, 0)),\n",
       " (array([ 0.17283649,  1.90122883]),\n",
       "  (array([ 0.03226069,  2.05199881]), 9825.179956580927, 31, 73, 0)),\n",
       " (array([ 0.07760091,  1.62901564]),\n",
       "  (array([ 0.03653264,  1.73395085]), 9825.179956580072, 23, 63, 0)),\n",
       " (array([ 0.06801678,  3.49657783]),\n",
       "  (array([ 0.06175374,  3.55519529]), 9825.1799565812707, 21, 58, 0)),\n",
       " (array([ 0.0550631 ,  2.90503535]),\n",
       "  (array([ 0.07358251,  3.31929116]), 9825.1799565804686, 23, 61, 0)),\n",
       " (array([ 0.07382876,  1.97189719]),\n",
       "  (array([ 0.05617572,  2.10243668]), 9825.1799565797955, 24, 61, 0)),\n",
       " (array([ 0.11070839,  3.49673412]),\n",
       "  (array([ 0.09857047,  3.56629877]), 9825.1799565801703, 25, 65, 0)),\n",
       " (array([ 0.10834875,  3.42092569]),\n",
       "  (array([ 0.10107928,  3.70848747]), 9825.1799565808396, 20, 60, 0))]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_par_te.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fopt` is the likelihood of the otimal parameter combination. I therefore don't need to calculate the likelihood with `get_ll`. It's already returned by the optimisation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. it may be that the likelihood values are correct and that there is a ridge in the likelihood surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retry two_epoch model with ery spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I previously also wasn't able to find reasonable optimal parameter values for the two epoch model with the _erythropus_ spectrum. I want to make another attempt here, given the apparently successful optimisation for the three epoch model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set up global variables on engines required for run_dadi function call\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log_fmin # uses Nelder-Mead algorithm\n",
    "sfs = fs_ery # use ERY spectrum\n",
    "perturb = True\n",
    "fold = 1\n",
    "maxiter = 100 # run a maximum of 100 iterations\n",
    "verbose = 0\n",
    "full_output = True # need to have full output to get the warnflags (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 2\n",
    "p0 = [1, 1]\n",
    "\n",
    "ar_ery_te = lbview.map(run_dadi, repeat(p0, 20), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.159561"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery_te.elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 5\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 15\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_ery_te, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.79926927,  1.68949312]),\n",
       " (array([  1.00492187e-04,   2.17110737e-06]),\n",
       "  2040.4927381782597,\n",
       "  100,\n",
       "  184,\n",
       "  2))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery_te.get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.008790</td>\n",
       "      <td>1.448122</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.863051</td>\n",
       "      <td>0.745958</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.974539</td>\n",
       "      <td>0.509961</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973070</td>\n",
       "      <td>1.668159</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.289495</td>\n",
       "      <td>0.638957</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nuB_0       T_0  nuB_opt     T_opt         logL\n",
       "0  1.008790  1.448122   0.0001  0.000002  2040.492674\n",
       "4  0.863051  0.745958   0.0001  0.000002  2040.492674\n",
       "3  0.974539  0.509961   0.0001  0.000002  2040.492674\n",
       "2  0.973070  1.668159   0.0001  0.000002  2040.492674\n",
       "1  1.289495  0.638957   0.0001  0.000002  2040.492674"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successfull_popt_ery_te = [flatten(out)[:5] for out in ar_ery_te if out[1][4] == 0]\n",
    "df = pd.DataFrame(data=successfull_popt_ery_te, \\\n",
    "                  columns=['nuB_0', 'T_0', 'nuB_opt', 'T_opt', 'logL'])\n",
    "df.sort_values(by='logL', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters are hitting the parameter limits set above and therefore cannot be regarded as converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the initial parameter values, they will be randomly perturbed by up to a factor of 2\n",
    "p0 = [0.1, 0.001]\n",
    "\n",
    "ar_ery_te = lbview.map(run_dadi, repeat(p0, 20), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 20\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 0\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_ery_te, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oho!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.123444</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156333</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.125851</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132941</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166737</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.096480</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.064284</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.124843</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.058069</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059941</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069211</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.106875</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.129957</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150734</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.098506</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.169902</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052018</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.130409</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055873</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2040.492673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nuB_0       T_0  nuB_opt     T_opt         logL\n",
       "15  0.123444  0.000651   0.0001  0.000002  2040.492742\n",
       "4   0.156333  0.001206   0.0001  0.000002  2040.492681\n",
       "16  0.125851  0.000929   0.0001  0.000002  2040.492674\n",
       "19  0.062718  0.001864   0.0001  0.000002  2040.492674\n",
       "0   0.132941  0.000502   0.0001  0.000002  2040.492674\n",
       "1   0.166737  0.001820   0.0001  0.000002  2040.492674\n",
       "10  0.096480  0.000572   0.0001  0.000002  2040.492674\n",
       "18  0.064284  0.000917   0.0001  0.000002  2040.492674\n",
       "9   0.124843  0.000887   0.0001  0.000002  2040.492674\n",
       "13  0.058069  0.000997   0.0001  0.000002  2040.492674\n",
       "5   0.059941  0.000673   0.0001  0.000002  2040.492674\n",
       "2   0.069211  0.001097   0.0001  0.000002  2040.492674\n",
       "17  0.106875  0.001976   0.0001  0.000002  2040.492674\n",
       "14  0.129957  0.001470   0.0001  0.000002  2040.492673\n",
       "6   0.150734  0.001445   0.0001  0.000002  2040.492673\n",
       "12  0.098506  0.001029   0.0001  0.000002  2040.492673\n",
       "11  0.169902  0.000518   0.0001  0.000002  2040.492673\n",
       "8   0.052018  0.001412   0.0001  0.000002  2040.492673\n",
       "7   0.130409  0.001819   0.0001  0.000002  2040.492673\n",
       "3   0.055873  0.000996   0.0001  0.000002  2040.492673"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successfull_popt_ery_te = [flatten(out)[:5] for out in ar_ery_te if out[1][4] == 0]\n",
    "df = pd.DataFrame(data=successfull_popt_ery_te, \\\n",
    "                  columns=['nuB_0', 'T_0', 'nuB_opt', 'T_opt', 'logL'])\n",
    "df.sort_values(by='logL', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no luck. It really looks as though the two epoch model cannot be fit to the _erythropus_ spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "691px",
    "left": "0px",
    "right": "1228px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
