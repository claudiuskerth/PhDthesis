{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"setting-boundaries-to-parameter-space-1\" href=\"#setting-boundaries-to-parameter-space\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>setting boundaries to parameter space</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"define-parallel-function-2\" href=\"#define-parallel-function\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>define parallel function</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"run-optimisation-3\" href=\"#run-optimisation\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>run optimisation</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"analyse-output-4\" href=\"#analyse-output\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>analyse output</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"check-warnflags-41\" href=\"#check-warnflags\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>check warnflags</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"change-optimsation-algorithm-5\" href=\"#change-optimsation-algorithm\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>change optimsation algorithm</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"rerun-optimsation-6\" href=\"#rerun-optimsation\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>rerun optimsation</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"check-warnflags-61\" href=\"#check-warnflags\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>check warnflags</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"increase-maxiter-7\" href=\"#increase-maxiter\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>increase <code>maxiter</code></a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"rerun-optimisation-8\" href=\"#rerun-optimisation\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>rerun optimisation</a></div><div class=\"lev1 toc-item\"><a data-toc-modified-id=\"concurrent-executor-9\" href=\"#concurrent-executor\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>concurrent executor</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"run-optimisations-91\" href=\"#run-optimisations\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>run optimisations</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"collect-output-92\" href=\"#collect-output\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>collect output</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"check-warnflags-93\" href=\"#check-warnflags\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>check warnflags</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"check-convergence-94\" href=\"#check-convergence\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>check convergence</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"Opt.-with-perturbed-nearly-optimal-p.-values-95\" href=\"#Opt.-with-perturbed-nearly-optimal-p.-values\"><span class=\"toc-item-num\">9.5&nbsp;&nbsp;</span>Opt. with perturbed nearly optimal p. values</a></div><div class=\"lev2 toc-item\"><a data-toc-modified-id=\"parallelus-96\" href=\"#parallelus\"><span class=\"toc-item-num\">9.6&nbsp;&nbsp;</span>parallelus</a></div><div class=\"lev3 toc-item\"><a data-toc-modified-id=\"collect-output-961\" href=\"#collect-output\"><span class=\"toc-item-num\">9.6.1&nbsp;&nbsp;</span>collect output</a></div><div class=\"lev3 toc-item\"><a data-toc-modified-id=\"check-warnflags-962\" href=\"#check-warnflags\"><span class=\"toc-item-num\">9.6.2&nbsp;&nbsp;</span>check warnflags</a></div><div class=\"lev3 toc-item\"><a data-toc-modified-id=\"masking-outliers-963\" href=\"#masking-outliers\"><span class=\"toc-item-num\">9.6.3&nbsp;&nbsp;</span>masking outliers</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "cl = Client()\n",
    "\n",
    "cl.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Interactive namespace is empty.\n",
      "[stdout:1] Interactive namespace is empty.\n",
      "[stdout:2] Interactive namespace is empty.\n",
      "[stdout:3] Interactive namespace is empty.\n",
      "[stdout:4] Interactive namespace is empty.\n",
      "[stdout:5] Interactive namespace is empty.\n",
      "[stdout:6] Interactive namespace is empty.\n",
      "[stdout:7] Interactive namespace is empty.\n",
      "[stdout:8] Interactive namespace is empty.\n",
      "[stdout:9] Interactive namespace is empty.\n",
      "[stdout:10] Interactive namespace is empty.\n",
      "[stdout:11] Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "# clear the namespace in engines\n",
    "cl.clear()\n",
    "\n",
    "%px %who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# run whole cell on all engines a well as in the local IPython session\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/claudius/Downloads/dadi')\n",
    "\n",
    "import dadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_ery = dadi.Spectrum.from_file('dadiExercises/ERY.FOLDED.sfs.dadi_format')\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_par = dadi.Spectrum.from_file('dadiExercises/PAR.FOLDED.sfs.dadi_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "ns = fs_ery.sample_sizes # both populations have the same sample size\n",
    "\n",
    "fs_ery.pop_ids = ['ery']\n",
    "fs_par.pop_ids = ['par']\n",
    "\n",
    "# setting the smallest grid size slightly larger than the largest population sample size (36)\n",
    "pts_l = [50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?dadi.Demographics1D.bottlegrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in `bottlegrowth` model specifies an instantaneous size change $T \\times 2N_{ref}$ generations in the past immediately followed by the start of exponential growth (or decline) toward the contemporary population size. The model has three parameters: \n",
    "- ratio of population size after instantaneous size change with respect to the ancient population size ($N_{ref}$)\n",
    "- time of instantaneous size change in $2N_{ref}$ generations in the past\n",
    "- ratio of contemporary to ancient population size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# create link to function that specifies the model\n",
    "func = dadi.Demographics1D.bottlegrowth\n",
    "\n",
    "# create extrapolating version of the model function\n",
    "func_ex = dadi.Numerics.make_extrap_log_func(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting boundaries to parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set lower and upper bounds to nuB, nuF and T\n",
    "upper_bound = [1e4, 1e4, 4]\n",
    "lower_bound = [1e-4, 1e-4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create range of starting values evenly distributed in log space\n",
    "p0_nuB = np.logspace(-3, 3, base=10.0, num=6)\n",
    "p0_nuF = np.logspace(-3, 3, base=10.0, num=6)\n",
    "p0_T = np.logspace(-4, np.log10(4), base=10, num=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of starting parameter combinations:\n",
    "\n",
    "6**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define parallel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create load balanced view of engines\n",
    "\n",
    "lbview = cl.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dadi(p_init): # for the function to be called with map, it needs to have one input variable\n",
    "    \"\"\"\n",
    "    p_init: initial parameter values to run optimisation from\n",
    "    \"\"\"\n",
    "    if perturb == True:\n",
    "        p_init = dadi.Misc.perturb_params(p_init, fold=fold, \n",
    "                                      upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "        # note upper_bound and lower_bound variables are expected to be in the namespace of each engine\n",
    "    # run optimisation of paramters\n",
    "    popt = dadi_opt_func(p0=p_init, data=sfs, model_func=func_ex, pts=pts_l, \\\n",
    "                                   lower_bound=lower_bound, upper_bound=upper_bound, \\\n",
    "                                   verbose=verbose, maxiter=maxiter, full_output=full_output)\n",
    "    return popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is very inportant for the upper function `run_dadi` to work. It creates global variables on all engines, which are called by the function (instead of supplied to the function, which is difficult to implement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set up global variables on engines required for run_dadi function call\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log # uses gradient based BFGS algorithm\n",
    "sfs = fs_ery # use ERY spectrum\n",
    "perturb = False\n",
    "fold = 1\n",
    "maxiter = 3 # run a maximum of 3 iterations\n",
    "verbose = 0\n",
    "full_output = True # need to have full output to get the warnflags (see below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what's in the namespace of the engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:1] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:2] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:3] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:4] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:5] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:6] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:7] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:8] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:9] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:10] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n",
      "[stdout:11] \n",
      "dadi\t dadi_opt_func\t fold\t fs_ery\t fs_par\t full_output\t func\t func_ex\t lower_bound\t \n",
      "maxiter\t np\t ns\t perturb\t pts_l\t sfs\t sys\t upper_bound\t verbose\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%px %who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product, izip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, 0.001, 0.0001)\n",
      "(0.001, 0.001, 0.00083255320740187322)\n",
      "(0.001, 0.001, 0.0069314484315514645)\n",
      "(0.001, 0.001, 0.057707996236288549)\n",
      "(0.001, 0.001, 0.48044977359257257)\n",
      "(0.001, 0.001, 4.0)\n",
      "(0.001, 0.015848931924611134, 0.0001)\n",
      "(0.001, 0.015848931924611134, 0.00083255320740187322)\n",
      "(0.001, 0.015848931924611134, 0.0069314484315514645)\n",
      "(0.001, 0.015848931924611134, 0.057707996236288549)\n",
      "(0.001, 0.015848931924611134, 0.48044977359257257)\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(product(p0_nuB, p0_nuF, p0_T)):\n",
    "    if i>10: break\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During these optimisations, there are usually a few that run much longer than the rest. I would like to be able to interrupt those runs. The following is taken from an [issue thread at the ipyparallel github repo](https://github.com/ipython/ipyparallel/issues/141):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine_pids = cl[:].apply(os.getpid).get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 64573,\n",
       " 1: 64576,\n",
       " 2: 64579,\n",
       " 3: 64582,\n",
       " 4: 64587,\n",
       " 5: 64592,\n",
       " 6: 64604,\n",
       " 7: 64616,\n",
       " 8: 64628,\n",
       " 9: 64645,\n",
       " 10: 64662,\n",
       " 11: 64674}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "# define function to interrupt an engine\n",
    "def signal_engine(engine_id, sig=signal.SIGINT):\n",
    "    \"\"\"send a signal to a local engine\"\"\"\n",
    "    pid = engine_pids[engine_id]\n",
    "    os.kill(pid, sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run optimnisations with all combinations of starting values\n",
    "\n",
    "# DO NOT RUN\n",
    "ar_ery = lbview.map(run_dadi, product(p0_nuB, p0_nuF, p0_T), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ID in cl.ids:\n",
    "    signal_engine(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has no effect. Engines keep running. The only way to stop them is by shutting down the whole ipcluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3725393"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total running time in minutes\n",
    "\n",
    "ar_ery.elapsed/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyse output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check warnflags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_flag_count(ar, NM=True):\n",
    "    \"\"\"\n",
    "    ar: asyncresult object from BFGS or Nelder-Mead optimisation\n",
    "    \"\"\"\n",
    "    if NM: # if ar from Nelder-Mead\n",
    "        i = 4 # the warnflag is reported at index position 4 in the output array\n",
    "    else: # ar from BFGS optimisation\n",
    "        i = 6\n",
    "    \n",
    "    warnflag = defaultdict(int)\n",
    "\n",
    "    for res in ar:\n",
    "        if res[i] == 1:\n",
    "            warnflag[1] +=1\n",
    "        elif res[i] == 2:\n",
    "            warnflag[2] += 1\n",
    "        elif res[i] == 0:\n",
    "            warnflag[0] += 1\n",
    "        else:\n",
    "            warnflag[999] +=1\n",
    "    if NM:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of function evaluations made.\", warnflag[1]\n",
    "        print \"Maximum number of iterations reached.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]\n",
    "    else:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of iterations exceeded.\", warnflag[1]\n",
    "        print \"Gradient and/or function calls not changing.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_flag_count(ar_ery, NM=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost no optimisation was successfull, mostly because of lacking gradient in the likelihood function. This calls for the other optimsation algorithm that is more robust to noise in the data: [Nelder-Mead](http://www.scipy-lectures.org/advanced/mathematical_optimization/index.html#gradient-less-methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# change optimsation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?dadi.Inference.optimize_log_fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log_fmin # uses Nelder-Mead algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rerun optimsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run optimnisations with all combinations of starting values\n",
    "\n",
    "ar_ery = lbview.map(run_dadi, product(p0_nuB, p0_nuF, p0_T), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_ery.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_ery.elapsed/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check warnflags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_flag_count(ar_ery, NM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl[0]['maxiter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to extend the maximum number of iterations allowed per optimisation in order to get any results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# increase `maxiter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "maxiter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl[:]['maxiter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rerun optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run optimnisations with all combinations of starting values\n",
    "\n",
    "# DO NOT RUN\n",
    "\n",
    "ar_ery = lbview.map(run_dadi, product(p0_nuB, p0_nuF, p0_T), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_ery.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_ery.elapsed/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs too long! Again, most of the time just on two cores. I cannot wait that long for exploratory analyses. Unfortunately, I cannot interrupt those long lasting jobs on the remote engines once they have started. If I shutdown the whole IPython cluster of engines, I cannot retrieve the information from the jobs that finished earlier (and did not get aborted). I think I need to be able to abort jobs that last too long but still have access to the results of the other jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only solution I can think of at the moment is to write a python script that takes initial starting values as input (like the function `run_dadi`), runs dadi optimisation with it and spits out the optimal parameter values to a separate file. Then I start this script in many subprocesses, thereby running in many instances in parallel on many initial parameter values and I would be able to interrupt the parent process (that initiates the subprocesses) without loosing the output from already completed subprocesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also look at these two `ipyparallel` forum entries: [1](https://github.com/ipython/ipyparallel/issues/141) and [2](https://github.com/ipython/ipyparallel/issues/229). However, `os.kill` does not seem to have an effect. Jobs just keep running. I don't know why it does not work and don't have the time (nor the nerves) to find out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    \"\"\"\n",
    "        Returns a list of flattened elements of every inner lists (or tuples)\n",
    "        ****RECURSIVE****\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for el in array:\n",
    "        if isinstance(el, (list, tuple)):\n",
    "            res.extend(flatten(el))\n",
    "            continue\n",
    "        res.append(el)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create parallel function with load balancing\n",
    "\n",
    "@lbview.parallel(block=True)\n",
    "def get_ll(p):\n",
    "    \"\"\"\n",
    "    p: parameter combination\n",
    "    \n",
    "    First, calculates the best-fit model SFS given paramter combination p.\n",
    "    Then returns the log likelihood of the expected SFS given the observed SFS.\n",
    "    \"\"\"\n",
    "    expected_sfs = func_ex(p, ns, pts_l)\n",
    "    return dadi.Inference.ll_multinom(expected_sfs, sfs)\n",
    "    # expected_sfs does not need to be folded, ll_multinom does that automatically\n",
    "    # make sure that sfs points to right spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# concurrent executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the issues with job control in the ipyparallel package, I am forced to use a more low-level parallel framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Do a kernel restart from the menu above in order to clear the namespace for a fresh restart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written a python script called `run_dadi.py`, which can take many command line arguments and in the following parallel framework is the replacement for the `run_dadi` function from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1560\r\n",
      "-rw-rw-r-- 1 claudius 591496 Apr 16 20:11 01_dadi_1D_exp_growth.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 249307 Apr 15 20:07 02_dadi_1D_two_epoch.ipynb\r\n",
      "-rw-rw-r-- 1 claudius  72091 Apr 18 18:38 03_1D_bottlegrowth.ipynb\r\n",
      "-rw-rw-r-- 1 claudius 444732 Apr 15 13:52 1D_models.ipynb\r\n",
      "-rw-rw-r-- 1 claudius  33125 Apr  8 18:15 1D_two_epoch_opt_res_ERY.dill\r\n",
      "-rw-rw-r-- 1 claudius  16613 Apr  8 19:18 1D_two_epoch_opt_res_PAR.dill\r\n",
      "drwxrwxr-x 4 claudius   4096 Mar 24 20:08 \u001b[0m\u001b[01;34mdadiExercises\u001b[0m/\r\n",
      "-rw-rw-r-- 1 claudius  36308 Apr  3 20:33 \u001b[01;35mery_fold_comp.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 claudius   3560 Mar 25 08:40 EryPar.FOLDED.2dsfs\r\n",
      "-rw-rw-r-- 1 claudius    433 Mar 24 20:15 ERY.unfolded.sfs\r\n",
      "-rw-rw-r-- 1 claudius    421 Mar 24 20:14 ERY.unfolded.sfs~\r\n",
      "-rw-rw-r-- 1 claudius  13913 Apr  6 15:03 exp_growth_optim_res_ERY.pickle\r\n",
      "-rw-rw-r-- 1 claudius  13913 Apr  6 19:21 exp_growth_optim_res_PAR.pickle\r\n",
      "drwxrwxr-x 2 claudius  20480 Apr 18 13:21 \u001b[01;34mOUT_run_dadi\u001b[0m/\r\n",
      "-rw-rw-r-- 1 claudius  37242 Apr  3 20:35 \u001b[01;35mpar_fold_comp.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 claudius    421 Mar 24 20:16 PAR.unfolded.sfs\r\n",
      "-rw-rw-r-- 1 claudius    409 Mar 24 20:15 PAR.unfolded.sfs~\r\n",
      "-rwxrwxr-x 1 claudius   2790 Apr 17 22:18 \u001b[01;32mrun_dadi.py\u001b[0m*\r\n",
      "-rwxrwxr-x 1 claudius   2790 Apr 17 22:05 \u001b[01;32mrun_dadi.py~\u001b[0m*\r\n",
      "-rw-rw-r-- 1 claudius   8654 Apr 16 20:51 test.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "% ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at `run_dadi.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%less run_dadi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_dadi.py [-h] [-p PATH_TO_SPECTRUM_FILE] [-m DADI_MODEL] [-u UPPER]\r\n",
      "                   [-l LOWER] [-i P_INIT] [-d DADI_OPT_FUNC] [-s STUB]\r\n",
      "                   [--maxiter MAXITER]\r\n",
      "\r\n",
      "runs dadi optimisation of parameters for given model\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -p PATH_TO_SPECTRUM_FILE, --path_to_spectrum_file PATH_TO_SPECTRUM_FILE\r\n",
      "                        file path to site frequency data\r\n",
      "  -m DADI_MODEL, --dadi_model DADI_MODEL\r\n",
      "                        model function to use\r\n",
      "  -u UPPER, --upper UPPER\r\n",
      "                        upper parameter bound\r\n",
      "  -l LOWER, --lower LOWER\r\n",
      "                        lower parameter bound\r\n",
      "  -i P_INIT, --p_init P_INIT\r\n",
      "                        initial parameter values\r\n",
      "  -d DADI_OPT_FUNC, --dadi_opt_func DADI_OPT_FUNC\r\n",
      "                        dadi optimisation function to use\r\n",
      "  -s STUB, --stub STUB  file name stub for output files\r\n",
      "  --maxiter MAXITER     maximum number of iterations allowed\r\n"
     ]
    }
   ],
   "source": [
    "! ./run_dadi.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import subprocess32 as subprocess\n",
    "import time, signal, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pdoc subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [readme of the subprocess32 module](https://github.com/google/python-subprocess32). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subprocess32'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 12 physical cores on huluvu (6 dual-core CPU's')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set lower and upper bounds to nuB, nuF and T\n",
    "upper_bound = [1e4, 1e4, 4]\n",
    "lower_bound = [1e-4, 1e-4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[10000.0, 10000.0, 4]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create range of starting values evenly distributed in log space\n",
    "p0_nuB = np.logspace(-3, 3, base=10.0, num=6)\n",
    "p0_nuF = np.logspace(-3, 3, base=10.0, num=6)\n",
    "p0_T = np.logspace(-4, np.log10(4), base=10, num=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, 0.001, 0.0001)\n",
      "(0.001, 0.001, 0.00083255320740187322)\n",
      "(0.001, 0.001, 0.0069314484315514645)\n",
      "(0.001, 0.001, 0.057707996236288549)\n",
      "(0.001, 0.001, 0.48044977359257257)\n",
      "(0.001, 0.001, 4.0)\n",
      "(0.001, 0.015848931924611134, 0.0001)\n",
      "(0.001, 0.015848931924611134, 0.00083255320740187322)\n",
      "(0.001, 0.015848931924611134, 0.0069314484315514645)\n",
      "(0.001, 0.015848931924611134, 0.057707996236288549)\n",
      "(0.001, 0.015848931924611134, 0.48044977359257257)\n",
      "(0.001, 0.015848931924611134, 4.0)\n"
     ]
    }
   ],
   "source": [
    "for i, comb in enumerate(product(p0_nuB, p0_nuF, p0_T)):\n",
    "    print comb\n",
    "    if i > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/claudius/Downloads/dadi')\n",
    "\n",
    "import dadi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variables will be passed as string values to `run_dadi.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_spectrum_file = \"dadiExercises/ERY.FOLDED.sfs.dadi_format\"\n",
    "dadi_model = \"dadi.Demographics1D.bottlegrowth\"\n",
    "upper = str(upper_bound)\n",
    "lower = str(lower_bound)\n",
    "dadi_opt_func = \"dadi.Inference.optimize_log_fmin\"\n",
    "stub = \"bottlegrowth_NM\"\n",
    "maxiter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 33676\r\n",
      "lrwxrwxrwx 1 claudius       53 Feb 17 15:37 \u001b[0m\u001b[01;36mERY.FOLDED.sfs\u001b[0m -> /data3/claudius/Big_Data/ANGSD/SFS/ERY/ERY.FOLDED.sfs\r\n",
      "-rw-rw-r-- 1 claudius      499 Mar 24 14:04 ERY.FOLDED.sfs.dadi_format\r\n",
      "-rw-rw-r-- 1 claudius      499 Mar 24 14:02 ERY.FOLDED.sfs.dadi_format~\r\n",
      "lrwxrwxrwx 1 claudius       37 Feb 18 17:46 \u001b[01;36mEryPar.unfolded.2dsfs\u001b[0m -> ../../ANGSD/FST/EryPar.unfolded.2dsfs\r\n",
      "-rw-rw-r-- 1 claudius    13051 Feb 18 19:00 EryPar.unfolded.2dsfs.dadi_format\r\n",
      "-rw-rw-r-- 1 claudius    13051 Feb 18 18:31 EryPar.unfolded.2dsfs.dadi_format~\r\n",
      "drwxrwxr-x 5 claudius     4096 Feb 17 13:45 \u001b[01;34mexamples\u001b[0m/\r\n",
      "-rw-rw-r-- 1 claudius   155251 Mar 22 12:37 example_YRI_CEU.ipynb\r\n",
      "-rw-rw-r-- 1 claudius   619518 Mar 21 11:09 First_Steps_with_dadi.ipynb\r\n",
      "-rw-rw-r-- 1 claudius     1012 Mar 16 09:54 new.bib\r\n",
      "lrwxrwxrwx 1 claudius       53 Feb 17 15:37 \u001b[01;36mPAR.FOLDED.sfs\u001b[0m -> /data3/claudius/Big_Data/ANGSD/SFS/PAR/PAR.FOLDED.sfs\r\n",
      "-rw-rw-r-- 1 claudius      486 Mar 24 20:08 PAR.FOLDED.sfs.dadi_format\r\n",
      "-rw-rw-r-- 1 claudius      450 Mar 24 20:08 PAR.FOLDED.sfs.dadi_format~\r\n",
      "-rw-rw-r-- 1 claudius       18 Mar 19 11:20 seedms\r\n",
      "-rw-rw-r-- 1 claudius 33643874 Mar 19 11:20 test.msout\r\n"
     ]
    }
   ],
   "source": [
    "% ll dadiExercises/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_dadi.py -p dadiExercises/ERY.FOLDED.sfs.dadi_format -m dadi.Demographics1D.bottlegrowth -u '[10000.0, 10000.0, 4]' -l '[0.0001, 0.0001, 0]' -d dadi.Inference.optimize_log_fmin -s bottlegrowth_NM --maxiter 100 -i '(0.001, 0.001, 0.0001)'\n"
     ]
    }
   ],
   "source": [
    "# check creation of command line\n",
    "\n",
    "for i, p_init in enumerate(product(p0_nuB, p0_nuF, p0_T)):\n",
    "    cmd = \"./run_dadi.py -p %s -m %s -u '%s' -l '%s' -d %s -s %s --maxiter %s -i '%s'\" \\\n",
    "                % (path_to_spectrum_file, dadi_model, upper, lower, dadi_opt_func, stub, str(maxiter), str(p_init))\n",
    "    print cmd\n",
    "    if i >= 0: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need to define an executor class. This is taken from Tiago Antao's Cookbook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class executor:\n",
    "    def __init__(self, limit):\n",
    "        self.limit = limit\n",
    "        self.ncores = multiprocessing.cpu_count()\n",
    "        self.running = []\n",
    "        self.finished = 0\n",
    "\n",
    "    def submit(self, cmd, p_init):\n",
    "        #self.progress()\n",
    "        self.wait()\n",
    "        if hasattr(self, 'out'):\n",
    "            out = self.out\n",
    "        else:\n",
    "            out = '/dev/null'\n",
    "        if hasattr(self, 'err'):\n",
    "            err = self.err\n",
    "        else:\n",
    "            err = '/dev/null'\n",
    "        if err == 'stderr':\n",
    "            errSt = ''\n",
    "        else:\n",
    "            errSt = '2> ' + err\n",
    "        proc = subprocess.Popen('%s > %s %s' % (cmd, out, errSt), shell=True)\n",
    "        self.running.append(proc)\n",
    "        #print \"started running optimsation with \" + str(p_init)\n",
    "        #print \"started subprocess with process id\" + str(proc.pid)\n",
    "        if hasattr(self, 'out'):\n",
    "            del self.out\n",
    "        if hasattr(self, 'err'):\n",
    "            del self.err\n",
    "            \n",
    "    def wait(self, for_all=False):\n",
    "        self.clean_done()\n",
    "        #numWaits = 0\n",
    "        if self.limit > 0 and type(self.limit) == int:\n",
    "            cond = 'len(self.running) >= self.ncores - self.limit'\n",
    "        elif self.limit < 0:\n",
    "            cond = 'len(self.running) >= - self.limit'\n",
    "        else:\n",
    "            cond = 'len(self.running) >= self.ncores * self.limit'\n",
    "        while eval(cond) or (for_all and len(self.running) > 0):\n",
    "            time.sleep(1)\n",
    "            self.clean_done() # updates self.running, removes finished jobs from the running queue\n",
    "            #numWaits += 1\n",
    "            \n",
    "    def clean_done(self):\n",
    "        terminated = []\n",
    "        for i, p in enumerate(self.running):\n",
    "            if p.poll() is not None: # None means it's still running\n",
    "                terminated.append(i)\n",
    "        for idx in reversed(terminated):\n",
    "            del self.running[idx]\n",
    "            self.finished += 1\n",
    "            \n",
    "    def progress(self):\n",
    "        self.clean_done()\n",
    "        #for p in self.running:\n",
    "        #    if p.poll() is not None:\n",
    "        #        print \"subprocess with process id %d reports that it has finished\" % (p.pid)\n",
    "        #    else:\n",
    "        #        print \"subprocess with process id %d reports that it is still running\" % (p.pid)\n",
    "        print self.finished\n",
    "        \n",
    "#    def kill_all(self):\n",
    "#        import os, signal\n",
    "#        self.clean_done()\n",
    "#        for p in self.running:\n",
    "#            os.kill(p.pid, signal.SIGINT)\n",
    "#        self.clean_done()\n",
    "# None of my attempts to kill the subprocesses has worked. \n",
    "# It seems they simply become disconnected, but still continue running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "15\n",
      "15\n",
      "17\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "23\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "57\n",
      "57\n",
      "59\n",
      "59\n",
      "61\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "84\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "139\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "E = executor(limit=-12) # leave 4 cores unused\n",
    "\n",
    "# this will block\n",
    "for i, p_init in enumerate(product(p0_nuB, p0_nuF, p0_T)):\n",
    "    cmd = \"./run_dadi.py -p %s -m %s -u '%s' -l '%s' -d %s -s %s --maxiter %s -i '%s'\" \\\n",
    "                % (path_to_spectrum_file, dadi_model, upper, lower, dadi_opt_func, stub, str(maxiter), str(p_init))\n",
    "    E.err = \"stderr\"\n",
    "    E.submit(cmd, p_init)\n",
    "    #if i >= 9: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "E.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 8 optimisations take an exceptionally long time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I want to kill all processes that are still running, I can execute the following command line in the shell:\n",
    "\n",
    "    sudo pgrep -f \"python ./run_dadi\" | xargs kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    }
   ],
   "source": [
    "E.progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\r\n"
     ]
    }
   ],
   "source": [
    "% ll OUT_run_dadi/*pickle | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of 216 initial parameter combinations, 208 produced optimisation output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parallel framework, albeit much more laborious to implement than using ipyparallel, has proven useful so far. It allows me to run many optimisations in parallel, save output of individual optimisation runs to file, abort the final long lasting runs from the command line and still be able to retrieve the information from the successful runs. This is something I could not do with ipyparallel, which forced me to always wait until all optimisation jobs had finished or else loose all the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script `run_dadi.py` has pickled the optimsation results to individual files for each initial parameter combination. They are located in the directory `OUT_run_dadi`. I now want to read these output files into a single data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OUT_run_dadi/bottlegrowth_NM_0.001000_0.015849_0.000100.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_0.001000_0.251189_0.480450.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_0.251189_0.001000_0.000100.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_0.251189_63_0.480450.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_1000_1000_4.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_1000_63_0.057708.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_3_1000_0.000100.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_63_0.015849_0.000833.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_63_0.015849_4.pickle',\n",
       " 'OUT_run_dadi/bottlegrowth_NM_63_63_0.000100.pickle']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "pickled = glob.glob('OUT_run_dadi/*pickle')\n",
    "sorted(pickled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_out = []\n",
    "for filename in glob.iglob('OUT_run_dadi/*pickle'):\n",
    "    opt_out.append( pickle.load(open(filename, \"r\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opt_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I killed the 8 last running processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.001, 0.25118864315095796, 0.48044977359257257),\n",
       " (array([ 0.69928844,  0.03905784,  1.63770723]),\n",
       "  2438.4426300145751,\n",
       "  100,\n",
       "  182,\n",
       "  2))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "opt_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## check warnflags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the flag count over these optimisations, I need to modify the previous function slightly, as it now handles slightly different input (list of tuples instead AsyncResult object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_flag_count(out, NM=True):\n",
    "    \"\"\"\n",
    "    out: list of tuples, each containing p_init and popt + additional info, including warnflags\n",
    "    as produced by run_dadi.py\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    if NM: # if ar from Nelder-Mead\n",
    "        i = 4 # the warnflag is reported at index position 4 in the output array\n",
    "    else: # ar from BFGS optimisation\n",
    "        i = 6\n",
    "    \n",
    "    warnflag = defaultdict(int)\n",
    "\n",
    "    for res in out:\n",
    "        if res[1][i] == 1: # notice the change in indexing\n",
    "            warnflag[1] +=1\n",
    "        elif res[1][i] == 2:\n",
    "            warnflag[2] += 1\n",
    "        elif res[1][i] == 0:\n",
    "            warnflag[0] += 1\n",
    "        else:\n",
    "            warnflag[999] +=1\n",
    "    if NM:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of function evaluations made.\", warnflag[1]\n",
    "        print \"Maximum number of iterations reached.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]\n",
    "    else:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of iterations exceeded.\", warnflag[1]\n",
    "        print \"Gradient and/or function calls not changing.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 27\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 181\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(opt_out, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 27 optimisations were successfull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have run each optimisation allowing for up to 100 iterations. This should be plenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dadi.Inference.optimize_log_fmin'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadi_opt_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have done the optimisations using the [Nelder-Mead optimisation algorithm](http://www.scipy-lectures.org/advanced/mathematical_optimization/index.html#gradient-less-methods) that should be more robust with noisy data than gradient based algorithms (like BFGS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(opt_out[0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add this type of object to list of objects to flatten in the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    \"\"\"\n",
    "        Returns a list of flattened elements of every inner lists (or tuples)\n",
    "        ****RECURSIVE****\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    res = []\n",
    "    for el in array:\n",
    "        if isinstance(el, (list, tuple, numpy.ndarray)):\n",
    "            res.extend(flatten(el))\n",
    "            continue\n",
    "        res.append(el)\n",
    "    return list( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ll(p):\n",
    "    \"\"\"\n",
    "    p: parameter combination\n",
    "    \n",
    "    First, calculates the best-fit model SFS given paramter combination p.\n",
    "    Then returns the log likelihood of the expected SFS given the observed SFS.\n",
    "    \"\"\"\n",
    "    expected_sfs = func_ex(p, ns, pts_l)\n",
    "    return dadi.Inference.ll_multinom(expected_sfs, sfs)\n",
    "    # expected_sfs does not need to be folded, ll_multinom does that automatically\n",
    "    # make sure that sfs points to right spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import 1D spectrum of ery on all engines:\n",
    "fs_ery = dadi.Spectrum.from_file('dadiExercises/ERY.FOLDED.sfs.dadi_format')\n",
    "\n",
    "# create link to function that specifies the model\n",
    "func = dadi.Demographics1D.bottlegrowth\n",
    "\n",
    "# create extrapolating version of the model function\n",
    "func_ex = dadi.Numerics.make_extrap_log_func(func)\n",
    "\n",
    "ns = fs_ery.sample_sizes # both populations have the same sample size\n",
    "\n",
    "fs_ery.pop_ids = ['ery']\n",
    "\n",
    "# setting the smallest grid size slightly larger than the largest population sample size (36)\n",
    "pts_l = [50, 60, 70]\n",
    "\n",
    "sfs = fs_ery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2438.5125398433665"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check get_ll works\n",
    "\n",
    "ll = get_ll(opt_out[0][1][0])\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001,\n",
       " 0.25118864315095796,\n",
       " 0.48044977359257257,\n",
       " 0.6992884442845132,\n",
       " 0.039057837813898537,\n",
       " 1.6377072306882821,\n",
       " 'aaaaa']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check addition of logL to list of parameters\n",
    "\n",
    "flatten(opt_out[0])[:6] + ['aaaaa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "successfull_popt = [flatten(out)[:6]  + [get_ll(out[1][0])] for out in opt_out if out[1][4] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1000.0,\n",
       "  1000.0,\n",
       "  0.0069314484315514645,\n",
       "  0.00027865170517505516,\n",
       "  5024.6013219799443,\n",
       "  5.8777224111832795e-17,\n",
       "  -2460.8445858070409],\n",
       " [63.0957344480193,\n",
       "  63.0957344480193,\n",
       "  0.0008325532074018732,\n",
       "  0.0006456542290346419,\n",
       "  127.83997194630471,\n",
       "  3.2438899193407309e-19,\n",
       "  -2460.8445858070304],\n",
       " [0.25118864315095796,\n",
       "  0.015848931924611134,\n",
       "  0.0008325532074018732,\n",
       "  10.043880786869554,\n",
       "  0.0001000005033951187,\n",
       "  2.2206138673989186e-06,\n",
       "  -2093.5558805233868]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successfull_popt[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=successfull_popt, columns=['nuB_0', 'nuF_0', 'T_0', 'nuB_opt', 'nuF_opt', 'T_opt', 'logL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.480450</td>\n",
       "      <td>39.786289</td>\n",
       "      <td>0.450821</td>\n",
       "      <td>3.735020e-01</td>\n",
       "      <td>-1904.760371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>39.785964</td>\n",
       "      <td>0.450815</td>\n",
       "      <td>3.734852e-01</td>\n",
       "      <td>-1904.760378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.193510</td>\n",
       "      <td>2.001793e-05</td>\n",
       "      <td>-2037.570988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.872775</td>\n",
       "      <td>2.606203e-05</td>\n",
       "      <td>-2037.715135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015849</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.176169</td>\n",
       "      <td>2.819672e-05</td>\n",
       "      <td>-2037.756305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>9.056516</td>\n",
       "      <td>3.025300e-05</td>\n",
       "      <td>-2037.795278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>0.440523</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.220640e-06</td>\n",
       "      <td>-2093.555878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>10.043881</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.220614e-06</td>\n",
       "      <td>-2093.555881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.099563</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.220614e-06</td>\n",
       "      <td>-2093.555881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>410.579843</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>1.955725e+00</td>\n",
       "      <td>-2438.509856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>0.656036</td>\n",
       "      <td>0.056265</td>\n",
       "      <td>2.006928e+00</td>\n",
       "      <td>-2438.511380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.998190</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>2.287617e+00</td>\n",
       "      <td>-2438.515130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.480450</td>\n",
       "      <td>86.359699</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>4.463697e-01</td>\n",
       "      <td>-2438.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.480450</td>\n",
       "      <td>3.439516</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>5.330860e-01</td>\n",
       "      <td>-2438.526670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.480450</td>\n",
       "      <td>4.310195</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>4.316040e-01</td>\n",
       "      <td>-2438.531433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>127.839972</td>\n",
       "      <td>3.243890e-19</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.153927</td>\n",
       "      <td>7090.771523</td>\n",
       "      <td>1.049413e-18</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>7090.771523</td>\n",
       "      <td>1.049413e-18</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>78.272843</td>\n",
       "      <td>4.562194e-17</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>5024.601322</td>\n",
       "      <td>5.877722e-17</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>3414.548874</td>\n",
       "      <td>1.198143e-18</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.251189</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>9.134577</td>\n",
       "      <td>1177.933205</td>\n",
       "      <td>3.456262e-21</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.061652</td>\n",
       "      <td>1177.933205</td>\n",
       "      <td>3.456262e-21</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.050073</td>\n",
       "      <td>78.581870</td>\n",
       "      <td>1.080020e-21</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.251189</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>19.970908</td>\n",
       "      <td>78.581870</td>\n",
       "      <td>1.080020e-21</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>2750.986817</td>\n",
       "      <td>1.032222e-16</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>7976.344847</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>-2485.534801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          nuB_0        nuF_0       T_0      nuB_opt      nuF_opt  \\\n",
       "8     63.095734     0.251189  0.480450    39.786289     0.450821   \n",
       "17     3.981072     0.251189  0.057708    39.785964     0.450815   \n",
       "24     0.001000     0.251189  0.000100     0.000100     0.193510   \n",
       "9      0.001000     3.981072  0.000100     0.000100     1.872775   \n",
       "4      0.015849     3.981072  0.000833     0.000100     4.176169   \n",
       "20     0.001000    63.095734  0.000100     0.000100     9.056516   \n",
       "7      3.981072    63.095734  0.057708     0.440523     0.000100   \n",
       "2      0.251189     0.015849  0.000833    10.043881     0.000100   \n",
       "23     3.981072     0.015849  0.000833     0.099563     0.000100   \n",
       "22    63.095734     0.001000  4.000000   410.579843     0.013006   \n",
       "10     0.015849     0.251189  0.057708     0.656036     0.056265   \n",
       "18     3.981072     0.001000  4.000000     7.998190     0.027791   \n",
       "5     63.095734     0.001000  0.480450    86.359699     0.002987   \n",
       "15     3.981072     0.015849  0.480450     3.439516     0.005712   \n",
       "11     3.981072     0.001000  0.480450     4.310195     0.004274   \n",
       "1     63.095734    63.095734  0.000833     0.000646   127.839972   \n",
       "12     3.981072  1000.000000  0.006931     0.153927  7090.771523   \n",
       "16    63.095734  1000.000000  0.006931     0.003647  7090.771523   \n",
       "3   1000.000000    63.095734  0.000833     0.001057    78.272843   \n",
       "0   1000.000000  1000.000000  0.006931     0.000279  5024.601322   \n",
       "26    63.095734  1000.000000  0.000833     0.001109  3414.548874   \n",
       "19     0.251189  1000.000000  0.000833     9.134577  1177.933205   \n",
       "6      3.981072  1000.000000  0.000833     0.061652  1177.933205   \n",
       "21     3.981072    63.095734  0.000833     0.050073    78.581870   \n",
       "13     0.251189    63.095734  0.000833    19.970908    78.581870   \n",
       "25  1000.000000  1000.000000  0.000833     0.000122  2750.986817   \n",
       "14  1000.000000     0.001000  0.057708  7976.344847     0.000195   \n",
       "\n",
       "           T_opt         logL  \n",
       "8   3.735020e-01 -1904.760371  \n",
       "17  3.734852e-01 -1904.760378  \n",
       "24  2.001793e-05 -2037.570988  \n",
       "9   2.606203e-05 -2037.715135  \n",
       "4   2.819672e-05 -2037.756305  \n",
       "20  3.025300e-05 -2037.795278  \n",
       "7   2.220640e-06 -2093.555878  \n",
       "2   2.220614e-06 -2093.555881  \n",
       "23  2.220614e-06 -2093.555881  \n",
       "22  1.955725e+00 -2438.509856  \n",
       "10  2.006928e+00 -2438.511380  \n",
       "18  2.287617e+00 -2438.515130  \n",
       "5   4.463697e-01 -2438.517857  \n",
       "15  5.330860e-01 -2438.526670  \n",
       "11  4.316040e-01 -2438.531433  \n",
       "1   3.243890e-19 -2460.844586  \n",
       "12  1.049413e-18 -2460.844586  \n",
       "16  1.049413e-18 -2460.844586  \n",
       "3   4.562194e-17 -2460.844586  \n",
       "0   5.877722e-17 -2460.844586  \n",
       "26  1.198143e-18 -2460.844586  \n",
       "19  3.456262e-21 -2460.844586  \n",
       "6   3.456262e-21 -2460.844586  \n",
       "21  1.080020e-21 -2460.844586  \n",
       "13  1.080020e-21 -2460.844586  \n",
       "25  1.032222e-16 -2460.844586  \n",
       "14  4.000000e+00 -2485.534801  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='logL', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nuB_opt    39.786289\n",
       "nuF_opt     0.450821\n",
       "T_opt       0.373502\n",
       "Name: 8, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_opt = df.sort_values(by='logL', ascending=False).iloc[0,3:6]\n",
    "p_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks promising that the best parameter combination was found twice from quite different starting values. The best parameter combination is more than 100 logL units more likely than the second best parameter combination. This result should be verified by running a few more optimisations with starting values in the vicinity of these optimal parameter values (via `perturb`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These optimal parameter values seem to suggest that the ancient population size first underwent a 40 fold increase at $0.37 \\times 2N_{ref}$ generations ago. It then underwent exponential population decline (note, the exponential nature is assumed by the model, but may not be very realistic) to 45% of the ancient population size $N_{ref}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt. with perturbed nearly optimal p. values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I am going to try and use ipyparallel again for the optimisations with perturbed initial parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "cl = Client()\n",
    "\n",
    "cl.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# run whole cell on all engines a well as in the local IPython session\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/claudius/Downloads/dadi')\n",
    "\n",
    "import dadi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, in the following analysis, I am going to use a slightly different spectrum: unfolded from ANGSD, then folded in dadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_ery = dadi.Spectrum.from_file('ERY.unfolded.sfs').fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "ns = fs_ery.sample_sizes # both populations have the same sample size\n",
    "\n",
    "fs_ery.pop_ids = ['ery']\n",
    "\n",
    "# setting the smallest grid size slightly larger than the largest population sample size (36)\n",
    "pts_l = [50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# create link to function that specifies the model\n",
    "func = dadi.Demographics1D.bottlegrowth\n",
    "\n",
    "# create extrapolating version of the model function\n",
    "func_ex = dadi.Numerics.make_extrap_log_func(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set lower and upper bounds to nuB, nuF and T\n",
    "upper_bound = [1e4, 1e4, 4]\n",
    "lower_bound = [1e-4, 1e-4, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dadi(p_init): # for the function to be called with map, it needs to have one input variable\n",
    "    \"\"\"\n",
    "    p_init: initial parameter values to run optimisation from\n",
    "    \"\"\"\n",
    "    if perturb == True:\n",
    "        p_init = dadi.Misc.perturb_params(p_init, fold=fold, \n",
    "                                      upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "        # note upper_bound and lower_bound variables are expected to be in the namespace of each engine\n",
    "    # run optimisation of paramters\n",
    "    popt = dadi_opt_func(p0=p_init, data=sfs, model_func=func_ex, pts=pts_l, \\\n",
    "                                   lower_bound=lower_bound, upper_bound=upper_bound, \\\n",
    "                                   verbose=verbose, maxiter=maxiter, full_output=full_output)\n",
    "    return p_init, popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create load balanced view of engines\n",
    "\n",
    "lbview = cl.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# set up global variables on engines required for run_dadi function call\n",
    "\n",
    "dadi_opt_func = dadi.Inference.optimize_log_fmin # use Nelder-Mead algorithm\n",
    "sfs = fs_ery # use ERY spectrum\n",
    "perturb = True\n",
    "fold = 1.5\n",
    "maxiter = 100 # run a maximum of 3 iterations\n",
    "verbose = 0\n",
    "full_output = True # need to have full output to get the warnflags (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_opt = [39.786289160859184, 0.45082070925507933, 0.37350201677769701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run optimnisations with perturbed optimal parameter values as starting values\n",
    "# repeat this 20 times\n",
    "\n",
    "ar_ery = lbview.map(run_dadi, repeat(list(p_opt), 20), block=False, order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.257099"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery.wall_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just takes 9 seconds to complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 47.2166873 ,   0.18749083,   0.43592681]),\n",
       " (array([ 39.20041883,   0.45760582,   0.36795039]),\n",
       "  1649.9713077093563,\n",
       "  80,\n",
       "  141,\n",
       "  0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_ery.get()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_flag_count(out, NM=True):\n",
    "    \"\"\"\n",
    "    out: list of tuples, each containing p_init and popt + additional info, including warnflags\n",
    "    as produced by run_dadi.py\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    if NM: # if ar from Nelder-Mead\n",
    "        i = 4 # the warnflag is reported at index position 4 in the output array\n",
    "    else: # ar from BFGS optimisation\n",
    "        i = 6\n",
    "    \n",
    "    warnflag = defaultdict(int)\n",
    "\n",
    "    for res in out:\n",
    "        if res[1][i] == 1: # notice the change in indexing\n",
    "            warnflag[1] +=1\n",
    "        elif res[1][i] == 2:\n",
    "            warnflag[2] += 1\n",
    "        elif res[1][i] == 0:\n",
    "            warnflag[0] += 1\n",
    "        else:\n",
    "            warnflag[999] +=1\n",
    "    if NM:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of function evaluations made.\", warnflag[1]\n",
    "        print \"Maximum number of iterations reached.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]\n",
    "    else:\n",
    "        print \"success\", warnflag[0]\n",
    "        print \"Maximum number of iterations exceeded.\", warnflag[1]\n",
    "        print \"Gradient and/or function calls not changing.\", warnflag[2]\n",
    "        print \"unknown flag\", warnflag[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 13\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 7\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(ar_ery, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 of 20 optimisations were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(array):\n",
    "    \"\"\"\n",
    "        Returns a list of flattened elements of every inner lists (or tuples)\n",
    "        ****RECURSIVE****\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    res = []\n",
    "    for el in array:\n",
    "        if isinstance(el, (list, tuple, numpy.ndarray)):\n",
    "            res.extend(flatten(el))\n",
    "            continue\n",
    "        res.append(el)\n",
    "    return list( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "successfull_popt = [flatten(out)[:7] for out in ar_ery if out[1][4] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=successfull_popt, columns=['nuB_0', 'nuF_0', 'T_0', 'nuB_opt', 'nuF_opt', 'T_opt', '-logL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>-logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.414656</td>\n",
       "      <td>0.210739</td>\n",
       "      <td>0.462369</td>\n",
       "      <td>39.201407</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.367940</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57.883309</td>\n",
       "      <td>0.529949</td>\n",
       "      <td>0.622005</td>\n",
       "      <td>39.200694</td>\n",
       "      <td>0.457599</td>\n",
       "      <td>0.367948</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>94.196807</td>\n",
       "      <td>0.468070</td>\n",
       "      <td>0.791146</td>\n",
       "      <td>39.198693</td>\n",
       "      <td>0.457602</td>\n",
       "      <td>0.367938</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87.446500</td>\n",
       "      <td>0.433059</td>\n",
       "      <td>0.404938</td>\n",
       "      <td>39.200026</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.367938</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.826734</td>\n",
       "      <td>0.392610</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>39.199184</td>\n",
       "      <td>0.457598</td>\n",
       "      <td>0.367939</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.409909</td>\n",
       "      <td>0.205299</td>\n",
       "      <td>0.388550</td>\n",
       "      <td>39.200632</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.367954</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.640592</td>\n",
       "      <td>0.431983</td>\n",
       "      <td>0.578988</td>\n",
       "      <td>39.202016</td>\n",
       "      <td>0.457603</td>\n",
       "      <td>0.367948</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.216687</td>\n",
       "      <td>0.187491</td>\n",
       "      <td>0.435927</td>\n",
       "      <td>39.200419</td>\n",
       "      <td>0.457606</td>\n",
       "      <td>0.367950</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.995217</td>\n",
       "      <td>0.219187</td>\n",
       "      <td>0.151084</td>\n",
       "      <td>39.200011</td>\n",
       "      <td>0.457600</td>\n",
       "      <td>0.367943</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.143955</td>\n",
       "      <td>0.349659</td>\n",
       "      <td>0.461401</td>\n",
       "      <td>39.202789</td>\n",
       "      <td>0.457604</td>\n",
       "      <td>0.367953</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.071761</td>\n",
       "      <td>0.202917</td>\n",
       "      <td>0.740089</td>\n",
       "      <td>39.200109</td>\n",
       "      <td>0.457601</td>\n",
       "      <td>0.367945</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.107587</td>\n",
       "      <td>0.413951</td>\n",
       "      <td>0.580664</td>\n",
       "      <td>39.200635</td>\n",
       "      <td>0.457605</td>\n",
       "      <td>0.367949</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.843908</td>\n",
       "      <td>0.240474</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>39.200723</td>\n",
       "      <td>0.457602</td>\n",
       "      <td>0.367947</td>\n",
       "      <td>1649.971308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nuB_0     nuF_0       T_0    nuB_opt   nuF_opt     T_opt        -logL\n",
       "2   21.414656  0.210739  0.462369  39.201407  0.457600  0.367940  1649.971308\n",
       "11  57.883309  0.529949  0.622005  39.200694  0.457599  0.367948  1649.971308\n",
       "5   94.196807  0.468070  0.791146  39.198693  0.457602  0.367938  1649.971308\n",
       "8   87.446500  0.433059  0.404938  39.200026  0.457600  0.367938  1649.971308\n",
       "3   17.826734  0.392610  0.263240  39.199184  0.457598  0.367939  1649.971308\n",
       "6   17.409909  0.205299  0.388550  39.200632  0.457606  0.367954  1649.971308\n",
       "10  18.640592  0.431983  0.578988  39.202016  0.457603  0.367948  1649.971308\n",
       "0   47.216687  0.187491  0.435927  39.200419  0.457606  0.367950  1649.971308\n",
       "7   21.995217  0.219187  0.151084  39.200011  0.457600  0.367943  1649.971308\n",
       "1   34.143955  0.349659  0.461401  39.202789  0.457604  0.367953  1649.971308\n",
       "9   20.071761  0.202917  0.740089  39.200109  0.457601  0.367945  1649.971308\n",
       "4   72.107587  0.413951  0.580664  39.200635  0.457605  0.367949  1649.971308\n",
       "12  18.843908  0.240474  0.187678  39.200723  0.457602  0.367947  1649.971308"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='-logL', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those optimisations that were successful all return the same optimal parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "dill.dump(list(ar_ery.get()), open(\"OUT_bottlegrowth/ERY_perturb_ar_ery.dill\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the initial parameter values for unsuccessful optimisations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48.22704245   0.23116665   0.14104111]\n",
      "[ 21.08068036   0.16387019   0.8128186 ]\n",
      "[ 30.41258844   0.98662646   1.00768444]\n",
      "[ 49.32897749   0.90683456   0.28126702]\n",
      "[ 44.37634318   0.18164686   0.66956876]\n",
      "[ 103.9665818     0.22647632    1.01340968]\n",
      "[ 84.71196391   1.12237167   0.40601414]\n",
      "[ 51.71940747   0.36247505   0.83053599]\n",
      "[ 52.10863319   0.46450981   1.04614116]\n",
      "[ 40.52348386   0.44643182   0.98917329]\n",
      "[ 15.77841656   0.84214071   0.81465301]\n",
      "[ 28.56890704   1.07801646   0.1418661 ]\n",
      "[ 17.19171428   0.88793227   0.21114888]\n"
     ]
    }
   ],
   "source": [
    "for out in ar_ery:\n",
    "    if out[1][4] == 0: \n",
    "        continue\n",
    "    print out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worrying that the optimisation from these starting values does not converge within 100 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parallelus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 33676\r\n",
      "lrwxrwxrwx 1 claudius       53 Feb 17 15:37 \u001b[0m\u001b[01;36mERY.FOLDED.sfs\u001b[0m -> /data3/claudius/Big_Data/ANGSD/SFS/ERY/ERY.FOLDED.sfs\r\n",
      "-rw-rw-r-- 1 claudius      499 Mar 24 14:04 ERY.FOLDED.sfs.dadi_format\r\n",
      "-rw-rw-r-- 1 claudius      499 Mar 24 14:02 ERY.FOLDED.sfs.dadi_format~\r\n",
      "lrwxrwxrwx 1 claudius       37 Feb 18 17:46 \u001b[01;36mEryPar.unfolded.2dsfs\u001b[0m -> ../../ANGSD/FST/EryPar.unfolded.2dsfs\r\n",
      "-rw-rw-r-- 1 claudius    13051 Feb 18 19:00 EryPar.unfolded.2dsfs.dadi_format\r\n",
      "-rw-rw-r-- 1 claudius    13051 Feb 18 18:31 EryPar.unfolded.2dsfs.dadi_format~\r\n",
      "drwxrwxr-x 5 claudius     4096 Feb 17 13:45 \u001b[01;34mexamples\u001b[0m/\r\n",
      "-rw-rw-r-- 1 claudius   155251 Mar 22 12:37 example_YRI_CEU.ipynb\r\n",
      "-rw-rw-r-- 1 claudius   619518 Mar 21 11:09 First_Steps_with_dadi.ipynb\r\n",
      "-rw-rw-r-- 1 claudius     1012 Mar 16 09:54 new.bib\r\n",
      "lrwxrwxrwx 1 claudius       53 Feb 17 15:37 \u001b[01;36mPAR.FOLDED.sfs\u001b[0m -> /data3/claudius/Big_Data/ANGSD/SFS/PAR/PAR.FOLDED.sfs\r\n",
      "-rw-rw-r-- 1 claudius      486 Mar 24 20:08 PAR.FOLDED.sfs.dadi_format\r\n",
      "-rw-rw-r-- 1 claudius      450 Mar 24 20:08 PAR.FOLDED.sfs.dadi_format~\r\n",
      "-rw-rw-r-- 1 claudius       18 Mar 19 11:20 seedms\r\n",
      "-rw-rw-r-- 1 claudius 33643874 Mar 19 11:20 test.msout\r\n"
     ]
    }
   ],
   "source": [
    "% ll dadiExercises/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_spectrum_file = \"dadiExercises/PAR.FOLDED.sfs.dadi_format\"\n",
    "dadi_model = \"dadi.Demographics1D.bottlegrowth\"\n",
    "upper = str(upper_bound)\n",
    "lower = str(lower_bound)\n",
    "dadi_opt_func = \"dadi.Inference.optimize_log_fmin\"\n",
    "stub = \"PAR_bottlegrowth_NM\"\n",
    "maxiter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_dadi.py -p dadiExercises/PAR.FOLDED.sfs.dadi_format -m dadi.Demographics1D.bottlegrowth -u '[10000.0, 10000.0, 4]' -l '[0.0001, 0.0001, 0]' -d dadi.Inference.optimize_log_fmin -s PAR_bottlegrowth_NM --maxiter 100 -i '(0.001, 0.001, 0.0001)'\n"
     ]
    }
   ],
   "source": [
    "# check creation of command line\n",
    "\n",
    "for i, p_init in enumerate(product(p0_nuB, p0_nuF, p0_T)):\n",
    "    cmd = \"./run_dadi.py -p %s -m %s -u '%s' -l '%s' -d %s -s %s --maxiter %s -i '%s'\" \\\n",
    "                % (path_to_spectrum_file, dadi_model, upper, lower, dadi_opt_func, stub, str(maxiter), str(p_init))\n",
    "    print cmd\n",
    "    if i >= 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E = executor(limit=4) # leave 4 cores unused\n",
    "\n",
    "# this will block\n",
    "for i, p_init in enumerate(product(p0_nuB, p0_nuF, p0_T)):\n",
    "    cmd = \"./run_dadi.py -p %s -m %s -u '%s' -l '%s' -d %s -s %s --maxiter %s -i '%s'\" \\\n",
    "                % (path_to_spectrum_file, dadi_model, upper, lower, dadi_opt_func, stub, str(maxiter), str(p_init))\n",
    "    E.err = \"stderr\"\n",
    "    E.submit(cmd, p_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This runs a very long time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Several optimisation runs take more than two hours. I have terminated those runs from the terminal with several executions of the following command:\n",
    "\n",
    "    pgrep -of \"python ./run_dadi.py\" | xargs kill\n",
    "    \n",
    "This will kill the longest running command that has a matching command line and thereby freeing slots for new optimisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    }
   ],
   "source": [
    "E.progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I needed to kill 26 optimisation runs because they could not finish with 1 hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OUT_run_dadi/PAR_bottlegrowth_NM_0.001000_0.015849_0.480450.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_0.001000_3_0.006931.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_0.001000_63_0.006931.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_0.015849_1000_0.000100.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_1000_0.001000_4.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_1000_0.251189_4.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_1000_63_0.000100.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_3_0.015849_0.000833.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_3_63_0.057708.pickle',\n",
       " 'OUT_run_dadi/PAR_bottlegrowth_NM_63_0.251189_0.000100.pickle']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled = glob.glob('OUT_run_dadi/PAR*pickle')\n",
    "sorted(pickled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_out = []\n",
    "for filename in glob.glob('OUT_run_dadi/PAR*pickle'):\n",
    "    opt_out.append( pickle.load(open(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63.0957344480193, 0.25118864315095796, 0.0001),\n",
       " (array([  5.34600148e-03,   1.00010441e-04,   5.87763609e-07]),\n",
       "  9724.1371177135079,\n",
       "  100,\n",
       "  188,\n",
       "  2))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check warnflags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success 59\n",
      "Maximum number of function evaluations made. 0\n",
      "Maximum number of iterations reached. 131\n",
      "unknown flag 0\n"
     ]
    }
   ],
   "source": [
    "get_flag_count(opt_out, NM=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of optimisations could not converge to an optimum within the 100 allowed iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is very important for the correct calculation of likelihoods\n",
    "\n",
    "# import 1D spectrum of ery on all engines:\n",
    "fs_par = dadi.Spectrum.from_file('dadiExercises/PAR.FOLDED.sfs.dadi_format')\n",
    "\n",
    "sfs = fs_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this takes too long\n",
    "# DO NOT RUN\n",
    "#successfull_popt = [flatten(out[:6]) + [get_ll(out[1][0])] for out in opt_out if out[1][4] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create parallel function with load balancing\n",
    "\n",
    "@lbview.parallel(block=True)\n",
    "def get_ll(p):\n",
    "    \"\"\"\n",
    "    p: parameter combination\n",
    "    \n",
    "    First, calculates the best-fit model SFS given paramter combination p.\n",
    "    Then returns the log likelihood of the expected SFS given the observed SFS.\n",
    "    \"\"\"\n",
    "    expected_sfs = func_ex(p, ns, pts_l)\n",
    "    return dadi.Inference.ll_multinom(expected_sfs, sfs)\n",
    "    # expected_sfs does not need to be folded, ll_multinom does that automatically\n",
    "    # make sure that sfs points to right spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this takes less than 1 minute running on the virtual 20 cores in parallel\n",
    "ll = get_ll.map([out[1][0] for out in opt_out if out[1][4] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "successfull_popt = [flatten(out)[:6] for out in opt_out if out[1][4] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1000.0,\n",
       "  0.001,\n",
       "  4.0,\n",
       "  5527.8480326389508,\n",
       "  4.7304302794030004,\n",
       "  3.9939569937001136],\n",
       " [0.001,\n",
       "  0.015848931924611134,\n",
       "  0.48044977359257257,\n",
       "  0.0001934721051520449,\n",
       "  0.080217850935046325,\n",
       "  0.4441817952921791],\n",
       " [0.25118864315095796,\n",
       "  1000.0,\n",
       "  0.05770799623628855,\n",
       "  0.15904075244236851,\n",
       "  0.00010000054911344888,\n",
       "  5.8764887277769201e-07]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successfull_popt[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print len(successfull_popt)\n",
    "print len(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import izip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000.0, 0.001, 4.0, 5527.8480326389508, 4.7304302794030004, 3.9939569937001136, -3962.1699571561167]\n",
      "[0.001, 0.015848931924611134, 0.48044977359257257, 0.0001934721051520449, 0.080217850935046325, 0.4441817952921791, -3851.7987143299106]\n",
      "[0.25118864315095796, 1000.0, 0.05770799623628855, 0.15904075244236851, 0.00010000054911344888, 5.8764887277769201e-07, -2247.8965038632414]\n",
      "[0.001, 1000.0, 0.0008325532074018732, 0.00010000041364529501, 54.149554006325246, 1.5166029232483476e-05, -2184.5319459156526]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for row in izip(successfull_popt, ll):\n",
    "    print flatten(row)\n",
    "    i+=1\n",
    "    if i > 3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_opt = [flatten(row) for row in izip(successfull_popt, ll)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=p_opt, columns=['nuB_0', 'nuF_0', 'T_0', 'nuB_opt', 'nuF_opt', 'T_opt', 'logL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuB_0</th>\n",
       "      <th>nuF_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>nuB_opt</th>\n",
       "      <th>nuF_opt</th>\n",
       "      <th>T_opt</th>\n",
       "      <th>logL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.015849</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.561802</td>\n",
       "      <td>9.917237e-06</td>\n",
       "      <td>-2184.073252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.558184</td>\n",
       "      <td>1.108981e-05</td>\n",
       "      <td>-2184.259232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.068024</td>\n",
       "      <td>1.219137e-05</td>\n",
       "      <td>-2184.384626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>47.899593</td>\n",
       "      <td>1.502786e-05</td>\n",
       "      <td>-2184.482606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>161.634763</td>\n",
       "      <td>1.642882e-05</td>\n",
       "      <td>-2184.492843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>54.149554</td>\n",
       "      <td>1.516603e-05</td>\n",
       "      <td>-2184.531946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.251189</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>0.159041</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.876489e-07</td>\n",
       "      <td>-2247.896504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>0.259153</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.876489e-07</td>\n",
       "      <td>-2247.896504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.238356</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.876118e-07</td>\n",
       "      <td>-2247.905591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.912246</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.876118e-07</td>\n",
       "      <td>-2247.905591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.899052</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.876118e-07</td>\n",
       "      <td>-2247.905591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.251189</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.249736</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.876118e-07</td>\n",
       "      <td>-2247.905591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>74.494775</td>\n",
       "      <td>3.048268e-17</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>3305.897010</td>\n",
       "      <td>4.386851e-19</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>187.762744</td>\n",
       "      <td>3.069009e-29</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.251189</td>\n",
       "      <td>63.095734</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>149.714643</td>\n",
       "      <td>187.762744</td>\n",
       "      <td>3.069009e-29</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>63.095734</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>4625.490042</td>\n",
       "      <td>5.416103e-19</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.981072</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.131364</td>\n",
       "      <td>4625.490042</td>\n",
       "      <td>5.416103e-19</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>4891.434542</td>\n",
       "      <td>7.322390e-17</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>2361.181017</td>\n",
       "      <td>6.798446e-17</td>\n",
       "      <td>-2460.844586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          nuB_0        nuF_0       T_0     nuB_opt      nuF_opt         T_opt  \\\n",
       "57     0.015849     3.981072  0.000833    0.000100     0.561802  9.917237e-06   \n",
       "31     0.001000     3.981072  0.000833    0.000100     1.558184  1.108981e-05   \n",
       "20     0.001000     3.981072  0.000100    0.000100     4.068024  1.219137e-05   \n",
       "53     0.001000  1000.000000  0.000100    0.000100    47.899593  1.502786e-05   \n",
       "16     0.001000    63.095734  0.000833    0.000100   161.634763  1.642882e-05   \n",
       "3      0.001000  1000.000000  0.000833    0.000100    54.149554  1.516603e-05   \n",
       "2      0.251189  1000.000000  0.057708    0.159041     0.000100  5.876489e-07   \n",
       "4      3.981072  1000.000000  0.057708    0.259153     0.000100  5.876489e-07   \n",
       "55     3.981072     0.001000  0.000100    1.238356     0.000100  5.876118e-07   \n",
       "45  1000.000000     0.001000  0.000100    2.912246     0.000100  5.876118e-07   \n",
       "8     63.095734     0.001000  0.000100    1.899052     0.000100  5.876118e-07   \n",
       "47     0.251189     0.001000  0.000100    0.249736     0.000100  5.876118e-07   \n",
       "17  1000.000000    63.095734  0.000833    0.000921    74.494775  3.048268e-17   \n",
       "37    63.095734  1000.000000  0.000833    0.000724  3305.897010  4.386851e-19   \n",
       "23     3.981072    63.095734  0.000833    0.006679   187.762744  3.069009e-29   \n",
       "52     0.251189    63.095734  0.000833  149.714643   187.762744  3.069009e-29   \n",
       "36    63.095734  1000.000000  0.006931    0.002267  4625.490042  5.416103e-19   \n",
       "27     3.981072  1000.000000  0.006931    0.131364  4625.490042  5.416103e-19   \n",
       "14  1000.000000  1000.000000  0.006931    0.000289  4891.434542  7.322390e-17   \n",
       "26  1000.000000  1000.000000  0.000833    0.000102  2361.181017  6.798446e-17   \n",
       "\n",
       "           logL  \n",
       "57 -2184.073252  \n",
       "31 -2184.259232  \n",
       "20 -2184.384626  \n",
       "53 -2184.482606  \n",
       "16 -2184.492843  \n",
       "3  -2184.531946  \n",
       "2  -2247.896504  \n",
       "4  -2247.896504  \n",
       "55 -2247.905591  \n",
       "45 -2247.905591  \n",
       "8  -2247.905591  \n",
       "47 -2247.905591  \n",
       "17 -2460.844586  \n",
       "37 -2460.844586  \n",
       "23 -2460.844586  \n",
       "52 -2460.844586  \n",
       "36 -2460.844586  \n",
       "27 -2460.844586  \n",
       "14 -2460.844586  \n",
       "26 -2460.844586  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='logL', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no convergence on a set of optimal parameter values. Fitting the `bottlegrowth` model to the 1D SFS of _parallelus_ must be considered as failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd1d005e290>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAJPCAYAAABYeZNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1c9dce550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12.0, 10.0]\n",
    "\n",
    "plt.plot(fs_par[:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the first and second frequency classes show counts that are inconsistent with any demographic history. It might therefore be worthwhile to mask them out. I think masking out just one of the first two frequency classes will lead to highly biased inferences. Masking both frequency classes will reduce a lot of the power to infer the demographic history. I therefore think that at least for this SFS, masking will most likely not lead to better estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a3b56da14915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs_ery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(fs_ery[:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the same assessment needs to be made for the SFS of ery. Again, masking out just one of the first two frequency classes"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "625px",
    "left": "0px",
    "right": "1141px",
    "top": "107px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
